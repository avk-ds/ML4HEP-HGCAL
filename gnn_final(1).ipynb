{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN with all connected nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "\n",
    "# Replace 'file.csv' with your file path\n",
    "df = pd.read_csv('hgcal_electron_data_50000.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "#print(df.head())\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "#print(column_names)\n",
    "\n",
    "columns_to_drop = ['nhits_total','xMean_layer0', 'xMean_layer1', 'xMean_layer2', 'xMean_layer3', 'xMean_layer4', 'xMean_layer5', 'xMean_layer6', 'xMean_layer7', 'xMean_layer8', 'xMean_layer9', 'xMean_layer10', 'xMean_layer11', 'xMean_layer12', 'xMean_layer13', 'xMean_layer14', 'xMean_layer15', 'xMean_layer16', 'xMean_layer17', 'xMean_layer18', 'xMean_layer19', 'xMean_layer20', 'xMean_layer21', 'xMean_layer22', 'xMean_layer23', 'xMean_layer24', 'xMean_layer25', 'xMean_layer26', 'xMean_layer27', 'xStd_layer0', 'xStd_layer1', 'xStd_layer2', 'xStd_layer3', 'xStd_layer4', 'xStd_layer5', 'xStd_layer6', 'xStd_layer7', 'xStd_layer8', 'xStd_layer9', 'xStd_layer10', 'xStd_layer11', 'xStd_layer12', 'xStd_layer13', 'xStd_layer14', 'xStd_layer15', 'xStd_layer16', 'xStd_layer17', 'xStd_layer18', 'xStd_layer19', 'xStd_layer20', 'xStd_layer21', 'xStd_layer22', 'xStd_layer23', 'xStd_layer24', 'xStd_layer25', 'xStd_layer26', 'xStd_layer27', 'yMean_layer0', 'yMean_layer1', 'yMean_layer2', 'yMean_layer3', 'yMean_layer4', 'yMean_layer5', 'yMean_layer6', 'yMean_layer7', 'yMean_layer8', 'yMean_layer9', 'yMean_layer10', 'yMean_layer11', 'yMean_layer12', 'yMean_layer13', 'yMean_layer14', 'yMean_layer15', 'yMean_layer16', 'yMean_layer17', 'yMean_layer18', 'yMean_layer19', 'yMean_layer20', 'yMean_layer21', 'yMean_layer22', 'yMean_layer23', 'yMean_layer24', 'yMean_layer25', 'yMean_layer26', 'yMean_layer27', 'yStd_layer0', 'yStd_layer1', 'yStd_layer2', 'yStd_layer3', 'yStd_layer4', 'yStd_layer5', 'yStd_layer6', 'yStd_layer7', 'yStd_layer8', 'yStd_layer9', 'yStd_layer10', 'yStd_layer11', 'yStd_layer12', 'yStd_layer13', 'yStd_layer14', 'yStd_layer15', 'yStd_layer16', 'yStd_layer17', 'yStd_layer18', 'yStd_layer19', 'yStd_layer20', 'yStd_layer21', 'yStd_layer22', 'yStd_layer23', 'yStd_layer24', 'yStd_layer25', 'yStd_layer26', 'yStd_layer27']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "#print(\"After dropping\")\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "labels = df['target_energy'].values  # Assuming there's a 'label' column for graph labels\n",
    "\n",
    "# Drop the label column to get the feature data\n",
    "feature_data = df.drop(columns=['target_energy']).values\n",
    "\n",
    "# Number of graphs\n",
    "num_graphs = feature_data.shape[0]\n",
    "\n",
    "# Number of nodes\n",
    "num_nodes = 28\n",
    "\n",
    "# Number of features per node\n",
    "num_features_per_node = 4  # nhits, rMean, rStd, energySum, etc.\n",
    "\n",
    "# Reshape the data to (num_graphs, num_nodes, num_features_per_node)\n",
    "energySum_data = df[[f'energySum_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rMean_data = df[[f'rMean_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rStd_data = df[[f'rStd_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "nhits_data = df[[f'nhits_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "\n",
    "# Concatenate features along the last dimension\n",
    "feature_data = np.concatenate([energySum_data, rMean_data, rStd_data, nhits_data], axis=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_indices, test_indices = train_test_split(np.arange(num_graphs), test_size=0.2, random_state=42)\n",
    "\n",
    "train_features = feature_data[train_indices]\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "test_features = feature_data[test_indices]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "import torch_geometric.utils\n",
    "\n",
    "# Create edge index for a fully connected graph with 28 nodes\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.ones((num_nodes, num_nodes)))[0]\n",
    "\n",
    "def create_data_list(features, labels):\n",
    "    data_list = []\n",
    "    for i in range(features.shape[0]):\n",
    "        x = torch.tensor(features[i], dtype=torch.float)\n",
    "        y = torch.tensor([labels[i]], dtype=torch.float)  # Ensure labels are float for regression\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "train_data_list = create_data_list(train_features, train_labels)\n",
    "test_data_list = create_data_list(test_features, test_labels)\n",
    "\n",
    "class GraphDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        super(GraphDataset, self).__init__('.', transform)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "# Instantiate the datasets\n",
    "train_dataset = GraphDataset(train_data_list)\n",
    "test_dataset = GraphDataset(test_data_list)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "        self.conv3 = GCNConv(16, 2)\n",
    "        self.regressor = Linear(2, 1)  # Single output for regression\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.relu()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply global pooling to aggregate node features\n",
    "        h = global_mean_pool(h, batch)  # Aggregated features for each graph\n",
    "        \n",
    "        # Apply a final (linear) regressor.\n",
    "        out = self.regressor(h).squeeze()  # Ensure output is [batch_size]\n",
    "\n",
    "        return out\n",
    "\n",
    "num_features = feature_data.shape[2]  # Number of features per node\n",
    "\n",
    "model = GCN(num_features=num_features)\n",
    "print(model)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = F.mse_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train()\n",
    "    test_loss = test(test_loader)\n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN with unidirectional edges with subsequent layers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "\n",
    "# Replace 'file.csv' with your file path\n",
    "df = pd.read_csv('hgcal_electron_data_50000.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "#print(df.head())\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "#print(column_names)\n",
    "\n",
    "columns_to_drop = ['nhits_total','xMean_layer0', 'xMean_layer1', 'xMean_layer2', 'xMean_layer3', 'xMean_layer4', 'xMean_layer5', 'xMean_layer6', 'xMean_layer7', 'xMean_layer8', 'xMean_layer9', 'xMean_layer10', 'xMean_layer11', 'xMean_layer12', 'xMean_layer13', 'xMean_layer14', 'xMean_layer15', 'xMean_layer16', 'xMean_layer17', 'xMean_layer18', 'xMean_layer19', 'xMean_layer20', 'xMean_layer21', 'xMean_layer22', 'xMean_layer23', 'xMean_layer24', 'xMean_layer25', 'xMean_layer26', 'xMean_layer27', 'xStd_layer0', 'xStd_layer1', 'xStd_layer2', 'xStd_layer3', 'xStd_layer4', 'xStd_layer5', 'xStd_layer6', 'xStd_layer7', 'xStd_layer8', 'xStd_layer9', 'xStd_layer10', 'xStd_layer11', 'xStd_layer12', 'xStd_layer13', 'xStd_layer14', 'xStd_layer15', 'xStd_layer16', 'xStd_layer17', 'xStd_layer18', 'xStd_layer19', 'xStd_layer20', 'xStd_layer21', 'xStd_layer22', 'xStd_layer23', 'xStd_layer24', 'xStd_layer25', 'xStd_layer26', 'xStd_layer27', 'yMean_layer0', 'yMean_layer1', 'yMean_layer2', 'yMean_layer3', 'yMean_layer4', 'yMean_layer5', 'yMean_layer6', 'yMean_layer7', 'yMean_layer8', 'yMean_layer9', 'yMean_layer10', 'yMean_layer11', 'yMean_layer12', 'yMean_layer13', 'yMean_layer14', 'yMean_layer15', 'yMean_layer16', 'yMean_layer17', 'yMean_layer18', 'yMean_layer19', 'yMean_layer20', 'yMean_layer21', 'yMean_layer22', 'yMean_layer23', 'yMean_layer24', 'yMean_layer25', 'yMean_layer26', 'yMean_layer27', 'yStd_layer0', 'yStd_layer1', 'yStd_layer2', 'yStd_layer3', 'yStd_layer4', 'yStd_layer5', 'yStd_layer6', 'yStd_layer7', 'yStd_layer8', 'yStd_layer9', 'yStd_layer10', 'yStd_layer11', 'yStd_layer12', 'yStd_layer13', 'yStd_layer14', 'yStd_layer15', 'yStd_layer16', 'yStd_layer17', 'yStd_layer18', 'yStd_layer19', 'yStd_layer20', 'yStd_layer21', 'yStd_layer22', 'yStd_layer23', 'yStd_layer24', 'yStd_layer25', 'yStd_layer26', 'yStd_layer27']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "#print(\"After dropping\")\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "labels = df['target_energy'].values  # Assuming there's a 'label' column for graph labels\n",
    "\n",
    "# Drop the label column to get the feature data\n",
    "feature_data = df.drop(columns=['target_energy']).values\n",
    "\n",
    "# Number of graphs\n",
    "num_graphs = feature_data.shape[0]\n",
    "\n",
    "# Number of nodes\n",
    "num_nodes = 28\n",
    "\n",
    "# Number of features per node\n",
    "num_features_per_node = 4  # nhits, rMean, rStd, energySum, etc.\n",
    "\n",
    "# Reshape the data to (num_graphs, num_nodes, num_features_per_node)\n",
    "energySum_data = df[[f'energySum_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rMean_data = df[[f'rMean_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rStd_data = df[[f'rStd_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "nhits_data = df[[f'nhits_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "\n",
    "# Concatenate features along the last dimension\n",
    "feature_data = np.concatenate([energySum_data, rMean_data, rStd_data, nhits_data], axis=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_indices, test_indices = train_test_split(np.arange(num_graphs), test_size=0.2, random_state=42)\n",
    "\n",
    "train_features = feature_data[train_indices]\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "test_features = feature_data[test_indices]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "# Create directed edge index for a chain graph where each node i is connected to node i+1\n",
    "edge_index = torch.tensor([list(range(num_nodes - 1)), list(range(1, num_nodes))], dtype=torch.long)\n",
    "\n",
    "# Verify the edge index\n",
    "print(edge_index)\n",
    "\n",
    "def create_data_list(features, labels, edge_index):\n",
    "    data_list = []\n",
    "    for i in range(features.shape[0]):\n",
    "        x = torch.tensor(features[i], dtype=torch.float)\n",
    "        y = torch.tensor([labels[i]], dtype=torch.float)  # Ensure labels are float for regression\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "train_data_list = create_data_list(train_features, train_labels, edge_index)\n",
    "test_data_list = create_data_list(test_features, test_labels, edge_index)\n",
    "\n",
    "class GraphDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        super(GraphDataset, self).__init__('.', transform)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "# Instantiate the datasets\n",
    "train_dataset = GraphDataset(train_data_list)\n",
    "test_dataset = GraphDataset(test_data_list)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "        self.conv3 = GCNConv(16, 2)\n",
    "        self.regressor = Linear(2, 1)  # Single output for regression\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.relu()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply global pooling to aggregate node features\n",
    "        h = global_mean_pool(h, batch)  # Aggregated features for each graph\n",
    "        \n",
    "        # Apply a final (linear) regressor.\n",
    "        out = self.regressor(h).squeeze()  # Ensure output is [batch_size]\n",
    "\n",
    "        return out\n",
    "\n",
    "num_features = feature_data.shape[2]  # Number of features per node\n",
    "\n",
    "model = GCN(num_features=num_features)\n",
    "print(model)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = F.mse_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train()\n",
    "    test_loss = test(test_loader)\n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN with nodes connected to all subsequesnt layers (Working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n",
      "          5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "          5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "          6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "          7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "          8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "          9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "         10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "         11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "         12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14,\n",
      "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
      "         15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "         19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21,\n",
      "         21, 21, 21, 22, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 25, 25, 26],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "         19, 20, 21, 22, 23, 24, 25, 26, 27,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
      "         11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,  3,\n",
      "          4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
      "         22, 23, 24, 25, 26, 27,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
      "         16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,  5,  6,  7,  8,  9, 10,\n",
      "         11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,  6,\n",
      "          7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
      "         25, 26, 27,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
      "         22, 23, 24, 25, 26, 27,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "         20, 21, 22, 23, 24, 25, 26, 27,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "         19, 20, 21, 22, 23, 24, 25, 26, 27, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "         19, 20, 21, 22, 23, 24, 25, 26, 27, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "         20, 21, 22, 23, 24, 25, 26, 27, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
      "         22, 23, 24, 25, 26, 27, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
      "         25, 26, 27, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 15,\n",
      "         16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 16, 17, 18, 19, 20, 21,\n",
      "         22, 23, 24, 25, 26, 27, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 18,\n",
      "         19, 20, 21, 22, 23, 24, 25, 26, 27, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
      "         20, 21, 22, 23, 24, 25, 26, 27, 21, 22, 23, 24, 25, 26, 27, 22, 23, 24,\n",
      "         25, 26, 27, 23, 24, 25, 26, 27, 24, 25, 26, 27, 25, 26, 27, 26, 27, 27]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(4, 16)\n",
      "  (conv2): GCNConv(16, 16)\n",
      "  (conv3): GCNConv(16, 2)\n",
      "  (regressor): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 1, Train Loss: 171.5770, Test Loss: 169.6535\n",
      "Epoch 2, Train Loss: 168.4470, Test Loss: 166.5234\n",
      "Epoch 3, Train Loss: 165.3169, Test Loss: 163.3935\n",
      "Epoch 4, Train Loss: 162.2020, Test Loss: 160.3122\n",
      "Epoch 5, Train Loss: 159.1727, Test Loss: 157.3321\n",
      "Epoch 6, Train Loss: 156.2374, Test Loss: 154.4447\n",
      "Epoch 7, Train Loss: 153.3887, Test Loss: 151.6335\n",
      "Epoch 8, Train Loss: 150.6155, Test Loss: 148.8930\n",
      "Epoch 9, Train Loss: 147.9101, Test Loss: 146.2223\n",
      "Epoch 10, Train Loss: 145.2726, Test Loss: 143.6191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 171\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m--> 171\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m test(test_loader)\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[69], line 144\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    143\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    145\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    146\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/loader/dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/collate.py:109\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m value, slices, incs \u001b[38;5;241m=\u001b[39m \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# If parts of the data are already on GPU, make sure that auxiliary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# data like `batch` or `ptr` are also created on GPU:\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_cuda:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/collate.py:169\u001b[0m, in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    167\u001b[0m slices \u001b[38;5;241m=\u001b[39m cumsum(sizes)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m increment:\n\u001b[0;32m--> 169\u001b[0m     incs \u001b[38;5;241m=\u001b[39m \u001b[43mget_incs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(incs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    171\u001b[0m         values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    172\u001b[0m             value \u001b[38;5;241m+\u001b[39m inc\u001b[38;5;241m.\u001b[39mto(value\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value, inc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, incs)\n\u001b[1;32m    174\u001b[0m         ]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/collate.py:321\u001b[0m, in \u001b[0;36mget_incs\u001b[0;34m(key, values, data_list, stores)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_incs\u001b[39m(key, values: List[Any], data_list: List[BaseData],\n\u001b[1;32m    320\u001b[0m              stores: List[BaseStorage]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 321\u001b[0m     repeats \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    322\u001b[0m         data\u001b[38;5;241m.\u001b[39m__inc__(key, value, store)\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m value, data, store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, data_list, stores)\n\u001b[1;32m    324\u001b[0m     ]\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repeats[\u001b[38;5;241m0\u001b[39m], Tensor):\n\u001b[1;32m    326\u001b[0m         repeats \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(repeats, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/collate.py:322\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_incs\u001b[39m(key, values: List[Any], data_list: List[BaseData],\n\u001b[1;32m    320\u001b[0m              stores: List[BaseStorage]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    321\u001b[0m     repeats \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 322\u001b[0m         \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m value, data, store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, data_list, stores)\n\u001b[1;32m    324\u001b[0m     ]\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repeats[\u001b[38;5;241m0\u001b[39m], Tensor):\n\u001b[1;32m    326\u001b[0m         repeats \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(repeats, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/data.py:658\u001b[0m, in \u001b[0;36mData.__inc__\u001b[0;34m(self, key, value, *args, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(value\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/data.py:614\u001b[0m, in \u001b[0;36mData.num_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnum_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/data.py:185\u001b[0m, in \u001b[0;36mBaseData.num_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of nodes in the graph.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m.. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    You will be given a warning that requests you to do so.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([v\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_stores])\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/data.py:185\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of nodes in the graph.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m.. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    You will be given a warning that requests you to do so.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_stores])\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/storage.py:425\u001b[0m, in \u001b[0;36mNodeStorage.num_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m N_KEYS:\n\u001b[0;32m--> 425\u001b[0m         cat_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__cat_dim__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39msize(cat_dim)\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m N_KEYS:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/data/data.py:647\u001b[0m, in \u001b[0;36mData.__cat_dim__\u001b[0;34m(self, key, value, *args, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__cat_dim__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m, value: Any, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madj\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/utils/sparse.py:140\u001b[0m, in \u001b[0;36mis_sparse\u001b[0;34m(src)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_sparse\u001b[39m(src: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns :obj:`True` if the input :obj:`src` is of type\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    :class:`torch.sparse.Tensor` (in any sparse layout) or of type\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    :class:`torch_sparse.SparseTensor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m        src (Any): The input object to be checked.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mis_torch_sparse_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(src, SparseTensor)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/utils/sparse.py:124\u001b[0m, in \u001b[0;36mis_torch_sparse_tensor\u001b[0;34m(src)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_coo:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_csr:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (torch_geometric\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mWITH_PT112\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m src\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_csc):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "\n",
    "def log_cosh_loss(output, target):\n",
    "    return torch.mean(torch.log(torch.cosh(output - target)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Replace 'file.csv' with your file path\n",
    "df = pd.read_csv('hgcal_electron_data_50000.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "#print(df.head())\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "#print(column_names)\n",
    "\n",
    "columns_to_drop = ['nhits_total','xMean_layer0', 'xMean_layer1', 'xMean_layer2', 'xMean_layer3', 'xMean_layer4', 'xMean_layer5', 'xMean_layer6', 'xMean_layer7', 'xMean_layer8', 'xMean_layer9', 'xMean_layer10', 'xMean_layer11', 'xMean_layer12', 'xMean_layer13', 'xMean_layer14', 'xMean_layer15', 'xMean_layer16', 'xMean_layer17', 'xMean_layer18', 'xMean_layer19', 'xMean_layer20', 'xMean_layer21', 'xMean_layer22', 'xMean_layer23', 'xMean_layer24', 'xMean_layer25', 'xMean_layer26', 'xMean_layer27', 'xStd_layer0', 'xStd_layer1', 'xStd_layer2', 'xStd_layer3', 'xStd_layer4', 'xStd_layer5', 'xStd_layer6', 'xStd_layer7', 'xStd_layer8', 'xStd_layer9', 'xStd_layer10', 'xStd_layer11', 'xStd_layer12', 'xStd_layer13', 'xStd_layer14', 'xStd_layer15', 'xStd_layer16', 'xStd_layer17', 'xStd_layer18', 'xStd_layer19', 'xStd_layer20', 'xStd_layer21', 'xStd_layer22', 'xStd_layer23', 'xStd_layer24', 'xStd_layer25', 'xStd_layer26', 'xStd_layer27', 'yMean_layer0', 'yMean_layer1', 'yMean_layer2', 'yMean_layer3', 'yMean_layer4', 'yMean_layer5', 'yMean_layer6', 'yMean_layer7', 'yMean_layer8', 'yMean_layer9', 'yMean_layer10', 'yMean_layer11', 'yMean_layer12', 'yMean_layer13', 'yMean_layer14', 'yMean_layer15', 'yMean_layer16', 'yMean_layer17', 'yMean_layer18', 'yMean_layer19', 'yMean_layer20', 'yMean_layer21', 'yMean_layer22', 'yMean_layer23', 'yMean_layer24', 'yMean_layer25', 'yMean_layer26', 'yMean_layer27', 'yStd_layer0', 'yStd_layer1', 'yStd_layer2', 'yStd_layer3', 'yStd_layer4', 'yStd_layer5', 'yStd_layer6', 'yStd_layer7', 'yStd_layer8', 'yStd_layer9', 'yStd_layer10', 'yStd_layer11', 'yStd_layer12', 'yStd_layer13', 'yStd_layer14', 'yStd_layer15', 'yStd_layer16', 'yStd_layer17', 'yStd_layer18', 'yStd_layer19', 'yStd_layer20', 'yStd_layer21', 'yStd_layer22', 'yStd_layer23', 'yStd_layer24', 'yStd_layer25', 'yStd_layer26', 'yStd_layer27']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "#print(\"After dropping\")\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "labels = df['target_energy'].values  # Assuming there's a 'label' column for graph labels\n",
    "\n",
    "# Drop the label column to get the feature data\n",
    "feature_data = df.drop(columns=['target_energy']).values\n",
    "\n",
    "# Number of graphs\n",
    "num_graphs = feature_data.shape[0]\n",
    "\n",
    "# Number of nodes\n",
    "num_nodes = 28\n",
    "\n",
    "# Number of features per node\n",
    "num_features_per_node = 4  # nhits, rMean, rStd, energySum, etc.\n",
    "\n",
    "# Reshape the data to (num_graphs, num_nodes, num_features_per_node)\n",
    "energySum_data = df[[f'energySum_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rMean_data = df[[f'rMean_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rStd_data = df[[f'rStd_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "nhits_data = df[[f'nhits_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "\n",
    "# Concatenate features along the last dimension\n",
    "feature_data = np.concatenate([energySum_data, rMean_data, rStd_data, nhits_data], axis=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_indices, test_indices = train_test_split(np.arange(num_graphs), test_size=0.2, random_state=42)\n",
    "\n",
    "train_features = feature_data[train_indices]\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "test_features = feature_data[test_indices]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "# Create directed edge index for each node i connected to all nodes j where j > i\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "\n",
    "for i in range(num_nodes - 1):\n",
    "    for j in range(i + 1, num_nodes):\n",
    "        source_nodes.append(i)\n",
    "        target_nodes.append(j)\n",
    "\n",
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Verify the edge index\n",
    "print(edge_index)\n",
    "\n",
    "def create_data_list(features, labels, edge_index):\n",
    "    data_list = []\n",
    "    for i in range(features.shape[0]):\n",
    "        x = torch.tensor(features[i], dtype=torch.float)\n",
    "        y = torch.tensor([labels[i]], dtype=torch.float)  # Ensure labels are float for regression\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "train_data_list = create_data_list(train_features, train_labels, edge_index)\n",
    "test_data_list = create_data_list(test_features, test_labels, edge_index)\n",
    "\n",
    "class GraphDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        super(GraphDataset, self).__init__('.', transform)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "# Instantiate the datasets\n",
    "train_dataset = GraphDataset(train_data_list)\n",
    "test_dataset = GraphDataset(test_data_list)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "        self.conv3 = GCNConv(16, 2)\n",
    "        self.regressor = Linear(2, 1)  # Single output for regression\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.relu()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply global pooling to aggregate node features\n",
    "        h = global_mean_pool(h, batch)  # Aggregated features for each graph\n",
    "        \n",
    "        # Apply a final (linear) regressor.\n",
    "        out = self.regressor(h).squeeze()  # Ensure output is [batch_size]\n",
    "\n",
    "        return out\n",
    "\n",
    "num_features = feature_data.shape[2]  # Number of features per node\n",
    "\n",
    "model = GCN(num_features=num_features)\n",
    "print(model)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.l1_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            #loss = F.smooth_l1_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "            loss = F.l1_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train()\n",
    "    test_loss = test(test_loader)\n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN with Bidirectional edges with nearest neibhours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  1,  0,  1,  2,  2,  1,  2,  3,  3,  2,  3,  4,  4,  3,  4,  5,\n",
      "          5,  4,  5,  6,  6,  5,  6,  7,  7,  6,  7,  8,  8,  7,  8,  9,  9,  8,\n",
      "          9, 10, 10,  9, 10, 11, 11, 10, 11, 12, 12, 11, 12, 13, 13, 12, 13, 14,\n",
      "         14, 13, 14, 15, 15, 14, 15, 16, 16, 15, 16, 17, 17, 16, 17, 18, 18, 17,\n",
      "         18, 19, 19, 18, 19, 20, 20, 19, 20, 21, 21, 20, 21, 22, 22, 21, 22, 23,\n",
      "         23, 22, 23, 24, 24, 23, 24, 25, 25, 24, 25, 26, 26, 25, 26, 27, 27, 26],\n",
      "        [ 1,  0,  0,  1,  2,  1,  1,  2,  3,  2,  2,  3,  4,  3,  3,  4,  5,  4,\n",
      "          4,  5,  6,  5,  5,  6,  7,  6,  6,  7,  8,  7,  7,  8,  9,  8,  8,  9,\n",
      "         10,  9,  9, 10, 11, 10, 10, 11, 12, 11, 11, 12, 13, 12, 12, 13, 14, 13,\n",
      "         13, 14, 15, 14, 14, 15, 16, 15, 15, 16, 17, 16, 16, 17, 18, 17, 17, 18,\n",
      "         19, 18, 18, 19, 20, 19, 19, 20, 21, 20, 20, 21, 22, 21, 21, 22, 23, 22,\n",
      "         22, 23, 24, 23, 23, 24, 25, 24, 24, 25, 26, 25, 25, 26, 27, 26, 26, 27]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(4, 28)\n",
      "  (conv2): GCNConv(28, 28)\n",
      "  (conv3): GCNConv(28, 2)\n",
      "  (regressor): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 1, Train Loss: 12.9604, Test Loss: 2.4162\n",
      "Epoch 2, Train Loss: 2.6227, Test Loss: 2.2914\n",
      "Epoch 3, Train Loss: 2.4962, Test Loss: 3.2106\n",
      "Epoch 4, Train Loss: 2.6358, Test Loss: 2.9021\n",
      "Epoch 5, Train Loss: 2.4288, Test Loss: 2.7591\n",
      "Epoch 6, Train Loss: 2.4644, Test Loss: 2.2693\n",
      "Epoch 7, Train Loss: 2.4587, Test Loss: 3.0662\n",
      "Epoch 8, Train Loss: 2.4422, Test Loss: 2.5412\n",
      "Epoch 9, Train Loss: 2.4670, Test Loss: 2.2671\n",
      "Epoch 10, Train Loss: 2.4833, Test Loss: 2.2313\n",
      "Epoch 11, Train Loss: 2.4367, Test Loss: 2.3117\n",
      "Epoch 12, Train Loss: 2.4010, Test Loss: 2.4872\n",
      "Epoch 13, Train Loss: 2.4389, Test Loss: 2.8672\n",
      "Epoch 14, Train Loss: 2.4605, Test Loss: 2.4642\n",
      "Epoch 15, Train Loss: 2.4143, Test Loss: 2.6864\n",
      "Epoch 16, Train Loss: 2.3619, Test Loss: 2.3704\n",
      "Epoch 17, Train Loss: 2.4101, Test Loss: 2.5519\n",
      "Epoch 18, Train Loss: 2.4503, Test Loss: 2.2614\n",
      "Epoch 19, Train Loss: 2.4262, Test Loss: 3.2317\n",
      "Epoch 20, Train Loss: 2.5468, Test Loss: 3.2858\n",
      "Epoch 21, Train Loss: 2.4641, Test Loss: 2.3210\n",
      "Epoch 22, Train Loss: 2.3784, Test Loss: 2.6989\n",
      "Epoch 23, Train Loss: 2.4484, Test Loss: 2.4638\n",
      "Epoch 24, Train Loss: 2.3788, Test Loss: 2.8856\n",
      "Epoch 25, Train Loss: 2.4463, Test Loss: 3.3623\n",
      "Epoch 26, Train Loss: 2.4303, Test Loss: 2.7222\n",
      "Epoch 27, Train Loss: 2.4101, Test Loss: 3.7880\n",
      "Epoch 28, Train Loss: 2.5006, Test Loss: 2.3308\n",
      "Epoch 29, Train Loss: 2.4589, Test Loss: 2.2280\n",
      "Epoch 30, Train Loss: 2.4773, Test Loss: 3.2013\n",
      "Epoch 31, Train Loss: 2.4067, Test Loss: 2.7725\n",
      "Epoch 32, Train Loss: 2.4483, Test Loss: 2.9509\n",
      "Epoch 33, Train Loss: 2.4282, Test Loss: 2.7867\n",
      "Epoch 34, Train Loss: 2.4596, Test Loss: 2.2224\n",
      "Epoch 35, Train Loss: 2.3849, Test Loss: 2.7949\n",
      "Epoch 36, Train Loss: 2.4823, Test Loss: 3.6428\n",
      "Epoch 37, Train Loss: 2.3719, Test Loss: 2.3196\n",
      "Epoch 38, Train Loss: 2.4715, Test Loss: 2.2211\n",
      "Epoch 39, Train Loss: 2.5192, Test Loss: 3.6289\n",
      "Epoch 40, Train Loss: 2.4124, Test Loss: 2.3230\n",
      "Epoch 41, Train Loss: 2.4514, Test Loss: 2.2500\n",
      "Epoch 42, Train Loss: 2.3825, Test Loss: 2.2851\n",
      "Epoch 43, Train Loss: 2.4671, Test Loss: 3.2397\n",
      "Epoch 44, Train Loss: 2.4370, Test Loss: 3.1232\n",
      "Epoch 45, Train Loss: 2.4278, Test Loss: 2.7390\n",
      "Epoch 46, Train Loss: 2.3756, Test Loss: 2.5927\n",
      "Epoch 47, Train Loss: 2.3597, Test Loss: 2.2235\n",
      "Epoch 48, Train Loss: 2.3739, Test Loss: 2.2359\n",
      "Epoch 49, Train Loss: 2.4306, Test Loss: 2.2493\n",
      "Epoch 50, Train Loss: 2.3383, Test Loss: 3.0751\n",
      "Epoch 51, Train Loss: 2.4025, Test Loss: 2.2822\n",
      "Epoch 52, Train Loss: 2.3996, Test Loss: 2.7975\n",
      "Epoch 53, Train Loss: 2.4023, Test Loss: 3.7908\n",
      "Epoch 54, Train Loss: 2.3998, Test Loss: 2.2197\n",
      "Epoch 55, Train Loss: 2.4121, Test Loss: 2.2099\n",
      "Epoch 56, Train Loss: 2.3753, Test Loss: 2.5811\n",
      "Epoch 57, Train Loss: 2.4168, Test Loss: 2.2146\n",
      "Epoch 58, Train Loss: 2.3107, Test Loss: 2.4264\n",
      "Epoch 59, Train Loss: 2.3884, Test Loss: 2.2531\n",
      "Epoch 60, Train Loss: 2.4031, Test Loss: 2.4989\n",
      "Epoch 61, Train Loss: 2.3794, Test Loss: 2.2480\n",
      "Epoch 62, Train Loss: 2.3796, Test Loss: 2.8966\n",
      "Epoch 63, Train Loss: 2.3105, Test Loss: 2.2172\n",
      "Epoch 64, Train Loss: 2.4047, Test Loss: 2.5181\n",
      "Epoch 65, Train Loss: 2.3914, Test Loss: 2.2127\n",
      "Epoch 66, Train Loss: 2.4052, Test Loss: 2.3812\n",
      "Epoch 67, Train Loss: 2.3153, Test Loss: 2.4557\n",
      "Epoch 68, Train Loss: 2.3820, Test Loss: 2.2090\n",
      "Epoch 69, Train Loss: 2.3173, Test Loss: 2.3013\n",
      "Epoch 70, Train Loss: 2.3885, Test Loss: 2.2067\n",
      "Epoch 71, Train Loss: 2.3842, Test Loss: 2.2003\n",
      "Epoch 72, Train Loss: 2.4201, Test Loss: 2.2363\n",
      "Epoch 73, Train Loss: 2.3628, Test Loss: 2.3717\n",
      "Epoch 74, Train Loss: 2.3281, Test Loss: 2.2814\n",
      "Epoch 75, Train Loss: 2.4167, Test Loss: 2.4383\n",
      "Epoch 76, Train Loss: 2.3570, Test Loss: 2.8829\n",
      "Epoch 77, Train Loss: 2.3737, Test Loss: 2.2057\n",
      "Epoch 78, Train Loss: 2.3758, Test Loss: 2.6715\n",
      "Epoch 79, Train Loss: 2.3880, Test Loss: 2.2823\n",
      "Epoch 80, Train Loss: 2.3756, Test Loss: 2.6206\n",
      "Epoch 81, Train Loss: 2.3845, Test Loss: 2.2046\n",
      "Epoch 82, Train Loss: 2.3609, Test Loss: 2.2052\n",
      "Epoch 83, Train Loss: 2.3529, Test Loss: 2.2111\n",
      "Epoch 84, Train Loss: 2.3620, Test Loss: 2.2031\n",
      "Epoch 85, Train Loss: 2.3739, Test Loss: 2.4724\n",
      "Epoch 86, Train Loss: 2.3728, Test Loss: 2.3925\n",
      "Epoch 87, Train Loss: 2.3226, Test Loss: 2.9518\n",
      "Epoch 88, Train Loss: 2.3205, Test Loss: 2.2615\n",
      "Epoch 89, Train Loss: 2.3876, Test Loss: 2.2154\n",
      "Epoch 90, Train Loss: 2.3052, Test Loss: 2.4332\n",
      "Epoch 91, Train Loss: 2.4046, Test Loss: 2.4451\n",
      "Epoch 92, Train Loss: 2.3864, Test Loss: 2.7878\n",
      "Epoch 93, Train Loss: 2.3567, Test Loss: 2.4705\n",
      "Epoch 94, Train Loss: 2.3229, Test Loss: 2.3559\n",
      "Epoch 95, Train Loss: 2.2952, Test Loss: 2.3241\n",
      "Epoch 96, Train Loss: 2.3518, Test Loss: 2.2373\n",
      "Epoch 97, Train Loss: 2.3718, Test Loss: 3.2347\n",
      "Epoch 98, Train Loss: 2.3965, Test Loss: 2.4578\n",
      "Epoch 99, Train Loss: 2.5201, Test Loss: 2.2560\n",
      "Epoch 100, Train Loss: 2.3471, Test Loss: 2.2207\n"
     ]
    }
   ],
   "source": [
    "###################Bidirectional############\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "\n",
    "def log_cosh_loss(output, target):\n",
    "    return torch.mean(torch.log(torch.cosh(output - target)))\n",
    "\n",
    "# Replace 'file.csv' with your file path\n",
    "df = pd.read_csv('hgcal_electron_data_50000.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "#print(df.head())\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "#print(column_names)\n",
    "\n",
    "columns_to_drop = ['nhits_total','xMean_layer0', 'xMean_layer1', 'xMean_layer2', 'xMean_layer3', 'xMean_layer4', 'xMean_layer5', 'xMean_layer6', 'xMean_layer7', 'xMean_layer8', 'xMean_layer9', 'xMean_layer10', 'xMean_layer11', 'xMean_layer12', 'xMean_layer13', 'xMean_layer14', 'xMean_layer15', 'xMean_layer16', 'xMean_layer17', 'xMean_layer18', 'xMean_layer19', 'xMean_layer20', 'xMean_layer21', 'xMean_layer22', 'xMean_layer23', 'xMean_layer24', 'xMean_layer25', 'xMean_layer26', 'xMean_layer27', 'xStd_layer0', 'xStd_layer1', 'xStd_layer2', 'xStd_layer3', 'xStd_layer4', 'xStd_layer5', 'xStd_layer6', 'xStd_layer7', 'xStd_layer8', 'xStd_layer9', 'xStd_layer10', 'xStd_layer11', 'xStd_layer12', 'xStd_layer13', 'xStd_layer14', 'xStd_layer15', 'xStd_layer16', 'xStd_layer17', 'xStd_layer18', 'xStd_layer19', 'xStd_layer20', 'xStd_layer21', 'xStd_layer22', 'xStd_layer23', 'xStd_layer24', 'xStd_layer25', 'xStd_layer26', 'xStd_layer27', 'yMean_layer0', 'yMean_layer1', 'yMean_layer2', 'yMean_layer3', 'yMean_layer4', 'yMean_layer5', 'yMean_layer6', 'yMean_layer7', 'yMean_layer8', 'yMean_layer9', 'yMean_layer10', 'yMean_layer11', 'yMean_layer12', 'yMean_layer13', 'yMean_layer14', 'yMean_layer15', 'yMean_layer16', 'yMean_layer17', 'yMean_layer18', 'yMean_layer19', 'yMean_layer20', 'yMean_layer21', 'yMean_layer22', 'yMean_layer23', 'yMean_layer24', 'yMean_layer25', 'yMean_layer26', 'yMean_layer27', 'yStd_layer0', 'yStd_layer1', 'yStd_layer2', 'yStd_layer3', 'yStd_layer4', 'yStd_layer5', 'yStd_layer6', 'yStd_layer7', 'yStd_layer8', 'yStd_layer9', 'yStd_layer10', 'yStd_layer11', 'yStd_layer12', 'yStd_layer13', 'yStd_layer14', 'yStd_layer15', 'yStd_layer16', 'yStd_layer17', 'yStd_layer18', 'yStd_layer19', 'yStd_layer20', 'yStd_layer21', 'yStd_layer22', 'yStd_layer23', 'yStd_layer24', 'yStd_layer25', 'yStd_layer26', 'yStd_layer27']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "#print(\"After dropping\")\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "labels = df['target_energy'].values  # Assuming there's a 'label' column for graph labels\n",
    "\n",
    "# Drop the label column to get the feature data\n",
    "feature_data = df.drop(columns=['target_energy']).values\n",
    "\n",
    "# Number of graphs\n",
    "num_graphs = feature_data.shape[0]\n",
    "\n",
    "# Number of nodes\n",
    "num_nodes = 28\n",
    "\n",
    "# Number of features per node\n",
    "num_features_per_node = 4  # nhits, rMean, rStd, energySum, etc.\n",
    "\n",
    "# Reshape the data to (num_graphs, num_nodes, num_features_per_node)\n",
    "energySum_data = df[[f'energySum_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rMean_data = df[[f'rMean_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rStd_data = df[[f'rStd_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "nhits_data = df[[f'nhits_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "\n",
    "# Concatenate features along the last dimension\n",
    "feature_data = np.concatenate([energySum_data, rMean_data, rStd_data, nhits_data], axis=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_indices, test_indices = train_test_split(np.arange(num_graphs), test_size=0.2, random_state=42)\n",
    "\n",
    "train_features = feature_data[train_indices]\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "test_features = feature_data[test_indices]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "# Create bidirectional edge index for each node i connected to nodes i-1 and i+1\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "\n",
    "for i in range(num_nodes):\n",
    "    if i > 0:  # Connect to the previous node\n",
    "        source_nodes.append(i)\n",
    "        target_nodes.append(i - 1)\n",
    "        source_nodes.append(i - 1)\n",
    "        target_nodes.append(i)\n",
    "    if i < num_nodes - 1:  # Connect to the next node\n",
    "        source_nodes.append(i)\n",
    "        target_nodes.append(i + 1)\n",
    "        source_nodes.append(i + 1)\n",
    "        target_nodes.append(i)\n",
    "\n",
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Verify the edge index\n",
    "print(edge_index)\n",
    "\n",
    "def create_data_list(features, labels, edge_index):\n",
    "    data_list = []\n",
    "    for i in range(features.shape[0]):\n",
    "        x = torch.tensor(features[i], dtype=torch.float)\n",
    "        y = torch.tensor([labels[i]], dtype=torch.float)  # Ensure labels are float for regression\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "train_data_list = create_data_list(train_features, train_labels, edge_index)\n",
    "test_data_list = create_data_list(test_features, test_labels, edge_index)\n",
    "\n",
    "class GraphDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        super(GraphDataset, self).__init__('.', transform)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "# Instantiate the datasets\n",
    "train_dataset = GraphDataset(train_data_list)\n",
    "test_dataset = GraphDataset(test_data_list)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 28)\n",
    "        self.conv2 = GCNConv(28, 28)\n",
    "        self.conv3 = GCNConv(28, 2)\n",
    "        self.regressor = Linear(2, 1)  # Single output for regression\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.relu()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply global pooling to aggregate node features\n",
    "        h = global_mean_pool(h, batch)  # Aggregated features for each graph\n",
    "        \n",
    "        # Apply a final (linear) regressor.\n",
    "        out = self.regressor(h).squeeze()  # Ensure output is [batch_size]\n",
    "\n",
    "        return out\n",
    "\n",
    "num_features = feature_data.shape[2]  # Number of features per node\n",
    "\n",
    "model = GCN(num_features=num_features)\n",
    "print(model)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.l1_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = F.l1_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train()\n",
    "    test_loss = test(test_loader)\n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 4)\n"
     ]
    }
   ],
   "source": [
    "print(feature_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_model.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = 'trained_model.pth'\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 2.2131, Train MSE: 8.6911, Train R2: 0.9991\n",
      "Test MAE: 2.2207, Test MSE: 9.3202, Test R2: 0.9990\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'trained_model.pth'  # Replace with your actual model path\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def evaluate_model(loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            y_true.append(data.y.cpu().numpy())\n",
    "            y_pred.append(out.cpu().numpy())\n",
    "    \n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return mae, mse, r2\n",
    "\n",
    "# Create DataLoaders for training and test datasets\n",
    "train_loader = DataLoader(GraphDataset(train_data_list), batch_size=128, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(GraphDataset(test_data_list), batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "train_mae, train_mse, train_r2 = evaluate_model(train_loader)\n",
    "print(f'Train MAE: {train_mae:.4f}, Train MSE: {train_mse:.4f}, Train R2: {train_r2:.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_mae, test_mse, test_r2 = evaluate_model(test_loader)\n",
    "print(f'Test MAE: {test_mae:.4f}, Test MSE: {test_mse:.4f}, Test R2: {test_r2:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAIjCAYAAAAJLyrXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAADKPUlEQVR4nOzdeXxU1f3/8dedfbJN9oUQtgSQ1QVUEEUEBdfWinWt+1Kt+rW1da22dam22tr21++32mq1aqV1q611Q0VwY1FR2bdEICzZIMskM5n13t8fMQMR1Ewy7O/n45FHmXPv3HtuTGHeOed8jmFZloWIiIiIiIh0m21Pd0BERERERGRfoyAlIiIiIiKSJAUpERERERGRJClIiYiIiIiIJElBSkREREREJEkKUiIiIiIiIklSkBIREREREUmSgpSIiIiIiEiSFKRERERERESSpCAlIiIHtL/97W8YhsG6desSbZMmTWLSpEl7rE9ftrM+7g5z5szBMAzmzJmzW+8rIrIvUJASEdlDDMPo1tf+/iF2wIABXZ63sLCQY445hhdffHFPdy0pwWCQX/ziF3vsv9fo0aPp168flmV95TkTJkygqKiIWCy2G3smIrJ/cuzpDoiIHKieeuqpLq+ffPJJ3nzzzR3ahw0btju7tUcccsgh/PjHPwZg8+bN/PnPf+aMM87goYce4qqrrtrt/XnjjTeSfk8wGOTOO+8E2COjWeeffz633HIL7733HhMnTtzh+Lp165g3bx7XXnstDof++RcR6S39TSoisod873vf6/J6/vz5vPnmmzu0f1kwGCQtLW1Xdm23Ky0t7fLcF154IRUVFfzud7/7yiAVi8UwTROXy5Xy/uyKa+5q5513HrfeeiszZszYaZD6xz/+gWVZnH/++XugdyIi+x9N7RMR2YtNmjSJkSNHsnDhQiZOnEhaWhq33XYb0DE18Be/+MUO7xkwYAAXX3xxl7bm5mZ++MMfUlZWhtvtpqKigl//+teYpvm19z/11FMZNGjQTo+NHz+esWPHJl6/+eabHH300WRnZ5ORkcHQoUMTfU1WcXExw4YNY+3atUDHaIphGPzmN7/h97//PeXl5bjdbpYvXw7AypUrOfPMM8nNzcXj8TB27FheeumlHa67bNkyJk+ejNfrpW/fvtxzzz07/R7sbI1UKBTiF7/4BUOGDMHj8VBSUsIZZ5xBVVUV69ato6CgAIA777wzMU1x+/8+qe7jl5WVlTFx4kSef/55otHoDsdnzJhBeXk5Rx55JOvXr+cHP/gBQ4cOxev1kpeXx3e/+91urcHa2c8X7Px7Fg6H+fnPf05FRQVut5uysjJuuukmwuFwl/NS+bMjIrK7aERKRGQvt3XrVk466STOOeccvve971FUVJTU+4PBIMceeyybNm3i+9//Pv369WPu3Lnceuut1NTU8Pvf//4r33v22Wdz4YUX8tFHH3H44Ycn2tevX8/8+fN54IEHgI4P/6eeeiqjR4/mrrvuwu12U1lZyQcffNCjZ45Go2zYsIG8vLwu7Y8//jihUIgrr7wSt9tNbm4uy5YtY8KECZSWlnLLLbeQnp7Os88+y+mnn84LL7zAd77zHQBqa2s57rjjiMViifP+8pe/4PV6v7E/8XicU089lVmzZnHOOedw/fXX09rayptvvsnSpUs5/vjjeeihh7j66qv5zne+wxlnnAF0rFvq/P7s6j5Cx/S+K6+8kpkzZ3Lqqacm2pcsWcLSpUv52c9+BsBHH33E3LlzOeecc+jbty/r1q3joYceYtKkSSxfvjwlI56mafKtb32L999/nyuvvJJhw4axZMkSfve737F69Wr+/e9/J743qfzZERHZbSwREdkrXHPNNdaX/1o+9thjLcB6+OGHdzgfsH7+85/v0N6/f3/roosuSry+++67rfT0dGv16tVdzrvlllssu91uVVdXf2WfWlpaLLfbbf34xz/u0n7//fdbhmFY69evtyzLsn73u99ZgNXQ0PBNj7nT/k6dOtVqaGiwGhoarEWLFlnnnHOOBVjXXXedZVmWtXbtWguwsrKyrPr6+i7vnzJlijVq1CgrFAol2kzTtI466ihr8ODBibYf/vCHFmAtWLAg0VZfX2/5fD4LsNauXZtoP/bYY61jjz028fqxxx6zAOvBBx/cof+maVqWZVkNDQ1f+d9kV/RxZxobGy23222de+65XdpvueUWC7BWrVplWZZlBYPBHd47b948C7CefPLJRNvs2bMtwJo9e3ai7cs/X52+/D176qmnLJvNZr333ntdznv44YctwPrggw8sy+rdz46IyJ6kqX0iIns5t9vNJZdc0uP3P/fccxxzzDHk5OSwZcuWxNfxxx9PPB7n3Xff/cr3ZmVlcdJJJ/Hss892qQb3zDPPMG7cOPr16wdAdnY2AP/5z3+6NQ3ty9544w0KCgooKCjg4IMP5rnnnuOCCy7g17/+dZfzpk+fnphCB9DY2Mjbb7/NWWedRWtra+LZtm7dyrRp01izZg2bNm0C4NVXX2XcuHEcccQRifcXFBR0a83QCy+8QH5+Ptddd90OxwzD+Nr37q4+AuTk5HDyySfz0ksvEQgEALAsi3/+85+MHTuWIUOGAHQZ4YpGo2zdupWKigqys7P55JNPunWvb/Lcc88xbNgwDjrooC4/d5MnTwZg9uzZQO9/dkRE9hQFKRGRvVxpaWmvih+sWbOG119/PRFUOr+OP/54AOrr67/2/WeffTYbNmxg3rx5AFRVVbFw4ULOPvvsLudMmDCByy+/nKKiIs455xyeffbZbn8wPvLII3nzzTd56623mDt3Llu2bOHJJ5/cYUrbwIEDu7yurKzEsizuuOOOHZ7v5z//eZfnW79+PYMHD97h3kOHDv3G/lVVVTF06NAeVbvbXX3sdP755xMIBPjPf/4DwNy5c1m3bl2XMNbe3s7PfvazxJq5/Px8CgoKaG5upqWlJeln3Jk1a9awbNmyHZ65M8x1PnNvf3ZERPYUrZESEdnLdXd9TKd4PN7ltWmanHDCCdx00007Pb/zg+1XOe2000hLS+PZZ5/lqKOO4tlnn8Vms/Hd7363Sx/fffddZs+ezSuvvMLrr7/OM888w+TJk3njjTew2+1fe4/8/PxEsPs6X/5edH7Y/slPfsK0adN2+p6KiopvvO6utLv7eOqpp+Lz+ZgxYwbnnXceM2bMwG63c8455yTOue6663j88cf54Q9/yPjx4/H5fBiGwTnnnPONAearRuDi8XiX/86maTJq1CgefPDBnZ5fVlYG9P5nR0RkT1GQEhHZR+Xk5NDc3NylLRKJUFNT06WtvLyctra2bgWVnUlPT+fUU0/lueee48EHH+SZZ57hmGOOoU+fPl3Os9lsTJkyhSlTpvDggw9y77338tOf/pTZs2f3+N7fpLOioNPp/MZ79O/fnzVr1uzQvmrVqm+8T3l5OQsWLCAajeJ0Ond6zlcFjN3Vx05ut5szzzyTJ598krq6Op577jkmT55McXFx4pznn3+eiy66iN/+9reJtlAotMPP087s7OcOOkbTtq/wWF5ezqJFi5gyZco3Tn/cEz87IiK9pal9IiL7qPLy8h3WN/3lL3/ZYUTqrLPOYt68ecycOXOHazQ3NxOLxb7xXmeffTabN2/m0UcfZdGiRV2m9UHHOqAvO+SQQwB2KHWdSoWFhUyaNIk///nPOwRIgIaGhsSfTz75ZObPn8+HH37Y5fjTTz/9jfeZPn06W7Zs4X//9393ONa5dqyz0t2XQ8bu6uP2zj//fKLRKN///vdpaGjYYY2V3W7vsuYN4I9//OMOPzs7U15ezvz584lEIom2l19+mQ0bNnQ576yzzmLTpk088sgjO1yjvb09sYZrT/3siIj0lkakRET2UZdffjlXXXUV06dP54QTTmDRokXMnDmT/Pz8LufdeOONvPTSS5x66qlcfPHFjBkzhkAgwJIlS3j++edZt27dDu/5spNPPpnMzEx+8pOfYLfbmT59epfjd911F++++y6nnHIK/fv3p76+nj/96U/07duXo48+OuXPvr3/+7//4+ijj2bUqFFcccUVDBo0iLq6OubNm8fGjRtZtGgRADfddBNPPfUUJ554Itdff32itHj//v1ZvHjx197jwgsv5Mknn+SGG27gww8/5JhjjiEQCPDWW2/xgx/8gG9/+9t4vV6GDx/OM888w5AhQ8jNzWXkyJGMHDlyt/Rxe8ceeyx9+/blP//5D16vN1GOvdOpp57KU089hc/nY/jw4cybN4+33nprh3LzO3P55Zfz/PPPc+KJJ3LWWWdRVVXF3//+d8rLy7ucd8EFF/Dss89y1VVXMXv2bCZMmEA8HmflypU8++yzzJw5k7Fjx+7Rnx0RkV7ZkyUDRURkm68qfz5ixIidnh+Px62bb77Zys/Pt9LS0qxp06ZZlZWVOy1P3draat16661WRUWF5XK5rPz8fOuoo46yfvOb31iRSKRb/Tv//PMtwDr++ON3ODZr1izr29/+ttWnTx/L5XJZffr0sc4999wdSq7vTP/+/a1TTjnla8/pLH/+wAMP7PR4VVWVdeGFF1rFxcWW0+m0SktLrVNPPdV6/vnnu5y3ePFi69hjj7U8Ho9VWlpq3X333dZf//rXbyx/blkdJcN/+tOfWgMHDrScTqdVXFxsnXnmmVZVVVXinLlz51pjxoyxXC7XDqXQU93Hb3LjjTdagHXWWWftcKypqcm65JJLrPz8fCsjI8OaNm2atXLlyh1+dnZW/tyyLOu3v/2tVVpaarndbmvChAnWxx9/vNPvWSQSsX79619bI0aMsNxut5WTk2ONGTPGuvPOO62WlhbLsnr3syMisicZlvWlsX0RERERERH5WlojJSIiIiIikiQFKRERERERkSQpSImIiIiIiCRJQUpERERERCRJClIiIiIiIiJJUpASERERERFJkjbkBUzTZPPmzWRmZmIYxp7ujoiIiIiI7CGWZdHa2kqfPn2w2b563ElBCti8eTNlZWV7uhsiIiIiIrKX2LBhA3379v3K4wpSQGZmJtDxzcrKytrDvRERERERkT3F7/dTVlaWyAhfRUEKEtP5srKyFKREREREROQbl/yo2ISIiIiIiEiSFKRERERERESSpCAlIiIiIiKSJAUpERERERGRJClIiYiIiIiIJElBSkREREREJEkKUiIiIiIiIklSkBIREREREUmSgpSIiIiIiEiSFKRERERERESSpCAlIiIiIiKSJAUpERERERGRJClIiYiIiIiIJMmxpzsgIiIiIiIHDtO02NgU5PMtAQAG5qdTlpOGzWbs4Z4lR0FKRERERER2i8r6VmYsqGb+51vZ2hbBxCLb6+ToinzOH9efisLMPd3FblOQEhERERGRXa6yvpXfv7WGj9c1EorEiVsWJhZtoRj/+mQTn28JcMepw/eZMKU1UiIiIiIiskuZpsXrS2tZsrGZlmCEYDROOGYSi1vE4iaBcIyP1jXy9/nrME1rT3e3WxSkRERERERkl4lE4jw1fy3PL9zAxqZ2QjGLmNnxFY1ZxC2IWxCMmPzrk828v2bLnu5yt2hqn4iIiIiIpJRpWmxqbueZj6p58ZNN1LeFiMa3O8Ha9j+GBZ1lJtpCMR57/3P65Hj2+il+ClIiIiIiItJjnaEpEImR7nLQHo3x5rJ6Zi6rYdlmP/HtglIn60t/trb786aWdt5YVseg/Iy9upKfgpSIiIiIiPRIZX0rM5fWUdXQRigWJxIzaWgNYwNW1rYS327kqbtaghE+qW5iU3M7Zblpu6LbKbFH10g99NBDjB49mqysLLKyshg/fjyvvfZa4vikSZMwDKPL11VXXdXlGtXV1ZxyyimkpaVRWFjIjTfeSCwW292PIiIiIiJyQKmsb+XxD9axZFMLdhvYDVi3JcD6rUFW1LYSifesaERze5TK+jZaQ9EU9zi19uiIVN++ffnVr37F4MGDsSyLJ554gm9/+9t8+umnjBgxAoArrriCu+66K/GetLRtqTQej3PKKadQXFzM3Llzqamp4cILL8TpdHLvvffu9ucRERERETkQmKbFzKV1VDcG8QcjfNwSIhiJ0R4xkxp92plIHOr9IQWpr3Paaad1ef3LX/6Shx56iPnz5yeCVFpaGsXFxTt9/xtvvMHy5ct56623KCoq4pBDDuHuu+/m5ptv5he/+AUul2uXP4OIiIiIyIFmU3M7n25oYkNjkMZABNOyiMetXoeoTu1RE/9eHqT2mvLn8Xicf/7znwQCAcaPH59of/rpp8nPz2fkyJHceuutBIPBxLF58+YxatQoioqKEm3Tpk3D7/ezbNmyr7xXOBzG7/d3+RIRERERkZ0zTYsNjUFW1vrZ0BjEH4xSvTVAUyBM3LSIxEzCPZjK52tv5YFXfo83EurSbgFr6ttS1PtdY48Xm1iyZAnjx48nFAqRkZHBiy++yPDhwwE477zz6N+/P3369GHx4sXcfPPNrFq1in/9618A1NbWdglRQOJ1bW3tV97zvvvu484779xFTyQiIiIism/6cgW+0mwvn29p61JQwuOw0x6JsaGpnUjMxLLA7OH9Wt1pjKyr5MoP/8Ufjj6vy7HapuBXvGvvsMeD1NChQ/nss89oaWnh+eef56KLLuKdd95h+PDhXHnllYnzRo0aRUlJCVOmTKGqqory8vIe3/PWW2/lhhtuSLz2+/2UlZX16jlERERERPZlX67A53HY8XkdrNsawB+KkZvmJMPlZFNTgMWbWmiPJj8CZVgmlrFtUpxps3P35Mu5+82H+N+jziZusyeObWgK7ewSe409HqRcLhcVFRUAjBkzho8++og//OEP/PnPf97h3COPPBKAyspKysvLKS4u5sMPP+xyTl1dHcBXrqsCcLvduN3uVD2CiIiIiMg+rbMCX2MgQonPQ5rLy6amIC9+uom2cBybAZZldYw+WcmVM+907OcLuW32X/nJyT9iScngRPvcAYdw0iX/2yVEAXid9i9fYq+y16yR6mSaJuFweKfHPvvsMwBKSkoAGD9+PEuWLKG+vj5xzptvvklWVlZieqCIiIiIiHy1zgp8jYEIgwszyPQ4aWmP8OG6RlraY8RMi0jcImpC7ItpfMkEqfItG3j8uZ/zxHM/Z+iWau54+xGwul4h4nDu8L78zL27cNweHZG69dZbOemkk+jXrx+tra3MmDGDOXPmMHPmTKqqqpgxYwYnn3wyeXl5LF68mB/96EdMnDiR0aNHAzB16lSGDx/OBRdcwP33309tbS23334711xzjUacRERERES+Rud6qKqGNhZvaqaPz4thGFiWxafrm6hpDvWqCl92u5/rP/gHF3zyCg5r2yoqhxnHF2qjxZv5te8vy/X04u673h4NUvX19Vx44YXU1NTg8/kYPXo0M2fO5IQTTmDDhg289dZb/P73vycQCFBWVsb06dO5/fbbE++32+28/PLLXH311YwfP5709HQuuuiiLvtOiYiIiIhIV9uvh6pvC7G2PkBLMEpFUQYfr21kZV3PK+Y54jEu+PQVrv/gH2SHtl1nU2YBv5p0Mf8dNhEM4xuv0xSI97gPu4NhWVaqyr3vs/x+Pz6fj5aWFrKysvZ0d0REREREdpkvr4eKxkzeWdNAeyROS3uESE/zi2Vx3Ocfc/vbf6W8cWOiOeh086dx3+XRw08n5Oz+KNMvTh3GxUcP6mFneq672WCPF5sQEREREZFd48vlzEuyPF3WQzUFo6ypb8MfitEc7P0GuNd/8I8uIer5kVN4YOIF1GXmJ3UdmwF5mXv3Uh0FKRERERGR/dCXy5m77TbcTjtrG9rIz3BT1dBGZX0b0bhJvAeb6e7AMLhryhX86+838lHpcO6ecjmLS4b06FJZHgeD8jJ636ddSEFKRERERGQ/8+Xpe6GojVW1razd0rEnlNMGlmFgwwArTjCW3PWd8SgXLnyZRX2G8HHfEYn2T0qHccb5D/BJ6UHdWge1Mx6HwbCSLLLSdqzktzdRkBIRERER2Y98uZx5UzDC4o0tNAYiRGJxTMsibkE83vG/SbEsjq/8kJ/OfpSBTTUsLSrnWxc+iLndHlCf9B3W477bgIrCTI4ZXEBptrfH19kdFKRERERERPYjnSXNS3wdhR2WbGxhc3M7wUicmGmCRY8KShxUv5bb336Uo9cvSrQNr/ucMZtW8FHZyJT03eO0UV6QwdQRRdhsPRvR2l0UpERERERE9iOBSIz2aJyMuIOlm1tY88U6qFjcwiK5zXQB8gLN3PD+3zln0RvYt9sPakHZSO6afDnLiitS1vfcdBenHFxCReHX7zG1N1CQEhERERHZR21flc/rtGMAn1Q3UVnXyqpaP/WtYYKReI821nXFoly08L9cN/efZEWCifZqXxH3Hncprw85qsfroHYmy+1gbP8chhXvG9sRKUiJiIiIiOyDtq/K19AaptbfTnskTigaJxwzwYBQD0MUwH0z/8j0pW8nXre6vPzf+LN5fOy3CDtcqXmI7RT73Awpztrr10Z1UpASEREREdnHbF+VLxqPs6qulbZQlEi8Y+pdustBIBIj1ouq5n8dezrfWTobgH8ePJUHj/keW9JzUtH9HThtMKZ/7j6xNqqTgpSIiIiIyD4kFjN59qONrNsSwOuEBWubCMVMPHZ7x0w7s2OdVMz8xksl5AeaKGxrYnnRoETb8qJB3D3lcub3G8WKwkFf8+7eO3ZoIZcdM3CfWBvVSUFKRERERGQfUVnfyrMfbeClRZtpbY8QiG4bcorGtyvF182RKHcswqUf/4cfzHuW2sx8Trrkj8Ts2yLC42O/naqu75TTgAsnDOCnJw/fZ0aiOilIiYiIiIjsJbYvHpHuclCa7U0EjMr6Vh57fx2LNjazpS2c1IjTDiyLk1Z9wG1zHqespQ6AzK0bOHfR6zx12KkpeJId2Q1wOwy8LgfFWR4cDhtThhZy7eTB+1yIAgUpEREREZG9wvbFI0KxOB6HnfKCDKaNLGJQfgZPz1/PB5UNbG5u71WIGllbyR2zHuHIjcsSbXHDxj8PnsqrQ49OwZPsyADSXXYGFqRTXpBBe9QkN93FyaNL9skQBQpSIiIiIiJ73PbFI0p8HtJcXgLhGB+u28qymhZKfB6eX7iJtnCsx1X4CtoaufHdJzlzySxs213l/f4Hc/eUK1hVMCAlz7LDfTNcDC7KJMPtwGEzAINRpT6mjijap9ZEfZmClIiIiIjIHmSaFq8vqWVjU5DSbC+WBc3BMJ83BNnS2k6Nv2MvqHgvKvCduOoDfvvK70iPhhJtn+f04ZeTL2NW+REp3Q9qe0WZLh6/+AgOKsn6yimL+yoFKRERERGRPeiDqi28urSWcCzOpqZ24pbVEZziJsFonGCkN4uhOqwqGIArHgWgxZ3OHyacx1OHnUzU7uz1tXfGboDHaeeHJwxheKkPgLLctF1yrz1FQUpEREREZA+prG/lHx9W0xgIU5TlwWk32NgUojEQJhbvdvG9HaRF2gm6tm1suza3lMfGfhtPLMzvJ5xHU5ovNQ+wEx47ZHhcTBxSwNlj++2y++xpClIiIiIiIntA535Qdf4QaS47YBGLQzASJRr/xrfvVFHrFm5690nGblzO1Mv+RNjhShy7b9IlKZ3C57JBzOy45ID8NPpkebHbDUJRk0H56Vx6zMB9fvre11GQEhERERHZzTr3g3ptaS12w6AlFGVrWwS304Y/lHyK8kRDXPHhi1y94HnSomEALvn4JR4ed+a2k1IYotJdNlwOO6ZpYbcZuB12Mr1OPE47FYUZ+3whie5QkBIRERER2Y06K/St2xIgEosTiZsEwzHCcSD0jW/vyrL41op3uGXO3+jTuiXR3OzJoNmTkdJ+Q0cZ85w0J3HLIm5aFGV5GNknk2DE5KzDyygvyNgvCkl0h4KUiIiIiMhuYpoWM5fWUd0YoHprgLrWSI+vdeimldzx9iMctnlVoi1m2HjqsFP4/YTzaPHumhGhSCyOx+Wgb46XUaXZZHkdrNsSoNjn2e8KSnwdBSkRERERkd1kU3M771c2sGKzn+ZQrEfXKGhr5LbZj/Gd5XO6tL89aCy/PO4yqvLLUtDTnXPaDYqyvIwqzaJfXjqGYdAaiuJ22El3HVjR4sB6WhERERGRXcw0rcSeSR6HjZqWEJX1bXicdtqjMT7b0Ex7tOclzV3xGCev+iDxenVeP+6ZfBnvDhqTiu5/JYcBXqeNSNykakuATK+TnDQXNS0hRpX6KM32fvNF9iMKUiIiIiIiPbR9aEp3OWiPxHlzeR1VDW1UNwaoaggQDMexsLAZEDctepGhANjkK+QvR5zB+Z+9xoNHn88/DjmRuM2emgf6Gi6njbgFGW4HwXCM5TV+CjI85GW4mDqi6IBYF7U9w7KsXuyRvH/w+/34fD5aWlrIysra090RERERkX1AZX0rM5d2hKZQLE4kZtLQGibL68TtMPhwbROBcMf0PbvNwGGHYCS5j96HbVzB1Que4/rTbuyyL5Q3EsJpxvDvgoIS2zMAuw0sC3LTXXicdtJcdsIxk7hpcdKoYs4aW7ZfVejrbjbQiJSIiIiISJI6K+81BiKU+Dx4nR7mf76VWn+IaCxOYzBKezRO5yBNzLSIJFHVvLSlnlvmPM5pK98D4PsLXuB3x3wvcbzd5aE9lQ+0HYfNwGGDWNzCYTeImxY2m0FuuovDB+TitNtoj8ao84c4/dDS/SpEJUNBSkREREQkCZ2V9xoDEQYXZmAYBv72KIFInJIsD3X+dra0RrAsMIFkxqDSIu1cPf95rvjoRTyxbRX9jl37Cb8/+jwsw5by59mew4CSLDcR06IxECEWt8CAvIyOEJWX4QY6tqTKSXOT6Xbu0v7szRSkRERERESSsKm5naqGNkp8HowvNrmNxE1icZOmSIyG1gixJBfPGJbJ9KVvc9M7T1AYaEq0b/Vm8duJF/DM6Km7LEQZQLbXgWUY2ACXw4bTsmh32onGTYqyPBxdkZ8IUZZlHbAFJranICUiIiIikoRAJEYoFidtuzVLgVCUTU1B2pNNUMDhG5bys1mPMKquKtEWsTl4fOy3+L/xZ6VsHZSNjtGx7XvotIHXaae8MINin5eCDBebW0IEI3FKcizaQjGyPE5cDhsx06Q9EqemJURu+oFZYGJ7ClIiIiIiItv5ciW+0mxvl8CQ7nLgcdgJRmKku+x8vK6RzzY20d6DbaEywwEef/5OMiLbVjzNHDyOe4+7lPU5fVLxOEDHqJPLYRC3+GLUyU4sbuJx2SnO8nDc0EKmjSxmUH5G1yqE0RhvLqunqqGNOn8It8POqFIfU0cUHbBrozopSImIiIiIfOHLlfg8DjvlBRmcMKIQr9NBIBIjzWlnUH46s1fVs35LgC3BaI/v1+pO50/jvstN7z7J8sKB3D35Cub1H52y53E5DNx2G6GoSTRu4XLYKPV5iJoWhmEwvCSTc4/sz4Ty/ERYLMtN63KNioLMrw2WByoFKRERERERdqzEl+byEozEmP/5Vt5YXktBphuXw4bHYccfirB0cwvhJKby2cw405e+zcwh47tM1/vr4adTl5HHiyMmYaZoPyiPw2D8wDzWbg3QFomT5rZjo6MMe1skjtfpYPJBBZx7ZL9vHFmy2YwdwpUoSImIiIiI7LQSn2VZNAWi1LS0szUQIRyNc1BxJv72MO+t2UI4iXLm46oXc8esRxlR/zlDG9Zxz5QrEsfCDhcvjJrS62dw2QDDoCDTxUHFWfz8tBGsbwwya0UdNS0hbIaBaVmU+DxMGVbUZRRKkqcgJSIiIiIHvC9X4tvaFmbZ5hYq69toj8axLGgORqlqaCNmdr+keb+mGm6b8xgnrp6XaLvwk1f4yxFnUJ+Zl7L+O20d1fZy0t30z0tjTP9c+uak0S8vnQnl+ZqatwsoSImIiIjIAc00Laoa2mhoC5HhdvB5Qxsfrm2kuT2yw9S9qNm9a2aGA1wz9xkuWfgS7vi2KhRLi8q5e/LlKQ1RDhvkprtJdzvok+2lf15al4p6mpq3ayhIiYiIiMgBq7O4xOKNzVQ1BFjbEGBrIEIkZhJPvpI5NjPOOYvf4Ib3/k5+sCXRXp+ewwMTL+CFkVNStg6qk8tuIzvNSVluGof1y1FFvd1EQUpEREREDkjbF5fok+2hKRBmyeYW2qM9SFAAlsXfn7mDo6oXJ5rCdiePHPEdHjryTALu1I8Kled5KM3J4OKjBzC4MFPT9nYjBSkREREROeB0FpfY2hamKNPN+q1B1m8N9DxEARgGM4eMTwSplw86hl9NupiNvqIU9Xq7WwEep8HoslwicZM+2V5N39vNFKRERERE5ICzqbmdT6obqd4a5IPKLbSF490uINEpK9SGYVm0eLdNo3v6kJM4bNNKnjrsZD7uOyK1nf6CwwCnw0ZBphuf14E/FCfdpY/1u5u+4yIiIiKy3zNNq0vlurdW1rJgbRPBSAwzyQRlN+Ocu2gmP3rv78wcchS3nXht4ljM7uD6b92Y4t5v4zDAYTfwuhwc3DebutYIo0p9lGZ7d9k9ZecUpERERERkv/DlsNS5XqizoERVQ0cp85b2CMs3t9IWjn3zRb/kmLWfcPvbjzJ0SzUAZy9+g6cOO5kVhYNS/TgJNqCzWKBhQH6Gm4NKMomZFrnpri4V+mT3UZASERERkX3e9mEpFIvjcdgpL8jgoJJMZq2oZ1NzEIfNxta2MJ83BPAnGaIGbd3IT2f/lSlVH3Vpf/mgY2j27JoKeWlOGxMq8sjPdLOxMcTGpiBt4RjlBelkeVxUFGaoQt8epCAlIiIiIvu07avvlfg8pLm8BCMxlmxq4aVFmwhFTQzDorEtQtS0iHR3MyjA197K9R/8gws+fQWnGU+0f1YyhLsmX8EnfYel7DkMOkacPA6DdI+LioJ0hpX4MAyDwkwvo/r6WFHj56zDyxjZx6cKfXuYgpSIiIiI7LM6q+81BiIMLszAMDqCRabHiccZZkNjO067AVgEI3FiSayHOmPpLO6Y9Sg5odZEW01GHr+adDEvDT8Wy7Cl5BkMIMvjYHSpj6otbTjtdrK8TioKMxPPAxCKxslJczGyj08V+vYCClIiIiIiss/a1NxOVUMbJT5Pl9BhmiaratuImnEiMZIKUJ3sZjwRotodbh4+cjp/OeIM2l2elPTdYYDNBl6nk+F9Msn0OslOcxEzLQ7u6yM33ZU417IsalpCKiyxF1GQEhEREZF9ViASIxSLk+baFi4aAxGWbW5h/dYA0fjXvPnLLKtjbt0XXhg5hQs/eYU1+f24f+JF1Gblp7Dn4HbaGFaSxfePLeeg4iwCkRhbWsO8uqSGrYEILocNr8tOeyROTUtIhSX2MgpSIiIiIrJPMU2LDU1BPm9oY3V9K41tYSzTxOWw4w9FWdvQRkt7nGA310LlBFv44QczSI+E+MkpP9p2H5udM8+/n7DT3es+O22Q4XYQicWJmdA318ud3x7BuAH5OBzbTREshmKfJ1E4o84fwu2wM6rUp8ISexkFKRERERHZa325pHl7JM4/P6zmnTUN1PtDhGMm0biV9Ga6AM54lAs+eZXrP5iBLxwAOjbU/bT0oMQ5qQhRLjukux3E4hYmBsU+D7edPJyjKwp3en5FYSaDJmXstJS77D1Ss0Kuhx566CFGjx5NVlYWWVlZjB8/ntdeey1xPBQKcc0115CXl0dGRgbTp0+nrq6uyzWqq6s55ZRTSEtLo7CwkBtvvJFYLPk9AURERERk71JZ38pDc6r43Zur+X+z1nDnf5dx3T8+4aXFm6n3h4ibJjGzByHKsphc+SGvP3YtP3v7kUSICjg9DGjanJK+Dy/JpDjTjcsOhmHQHjGxGQbD+2Txs9OGM2VY0de+32YzKMtN46DiLMpy0xSi9kJ7dESqb9++/OpXv2Lw4MFYlsUTTzzBt7/9bT799FNGjBjBj370I1555RWee+45fD4f1157LWeccQYffPABAPF4nFNOOYXi4mLmzp1LTU0NF154IU6nk3vvvXdPPpqIiIiI9EJlfSuPvb+WTc3t5KS5yEtzsXRzMxubgkTiFlgWMZOkQ9SQhnXc/vZfmbju0y7tz408ngcmXkB9Zl6v++52GIwuzaK5PU7fHDdDi7MIRU2GFGUwpl9u16l8ss8yLMvqyUjoLpObm8sDDzzAmWeeSUFBATNmzODMM88EYOXKlQwbNox58+Yxbtw4XnvtNU499VQ2b95MUVFHqn/44Ye5+eabaWhowOVyfd2tEvx+Pz6fj5aWFrKysnbZs4mIiIjI1zNNi+qtAX75ynIWb2rBYTOwGWBh0BSMEI6ZxLq/DVRCbrCFH73/NOd99jp2a9sFPuw7nLsnX8GSksEp6b8B5KY7GVnqo29OGpdMGKB1TfuY7maDvWaNVDwe57nnniMQCDB+/HgWLlxINBrl+OOPT5xz0EEH0a9fv0SQmjdvHqNGjUqEKIBp06Zx9dVXs2zZMg499NCd3iscDhMOhxOv/X7/rnswEREREeniy+ueOtf/VNa38vT89by8uIaGtkjifBsdASWZAnxfdtT6RVzw6auJ1xuzCrn3uEt5deiELpX6esMAHDbITXNxxIA8po1UcYj92R4PUkuWLGH8+PGEQiEyMjJ48cUXGT58OJ999hkul4vs7Owu5xcVFVFbWwtAbW1tlxDVebzz2Fe57777uPPOO1P7ICIiIiLyjSrrWxMV6UKxOB6HnfKCDIYWZ/LIe1Us2diyQ7W9HgxA7eDlg47h4oX/5aCGdfxp3Hf56+GnE3Z0b/bSN3EYkOlxYLMZ5Ge4+ekpwzi6okDrmvZzezxIDR06lM8++4yWlhaef/55LrroIt55551des9bb72VG264IfHa7/dTVla2S+8pIiIicqCrrG/l8Q/W0RiIUOLz4HV6aGgN89aKWh59/3NaQ9EeTdv7soPq1zJ1zXz+34RztzUaBjee/EPaXF4aMnJ7f5MvMWwGZTlpXDdlMBOH7Lwan+xf9niQcrlcVFRUADBmzBg++ugj/vCHP3D22WcTiURobm7uMipVV1dHcXExAMXFxXz44YddrtdZ1a/znJ1xu9243b0vZSkiIiIi3WOaFjOX1tEYiDC4MIOmYISVNa3U+NupbQ7SnoKiy3mBZn783t85e/Eb2C2Tj0uHMXfAIYnja3NLe3+TL0lz2nA77VQUZHDXt0ZyUB+ttz9Q7HUlQ0zTJBwOM2bMGJxOJ7NmzUocW7VqFdXV1YwfPx6A8ePHs2TJEurr6xPnvPnmm2RlZTF8+PDd3ncRERER2blNze1U1reS7rKzdFML761pYENTAH8wQrQ3i58AVyzKlQteYPZfruS8RduKSVyy8L8p6PnO2YD8DBfHDy/i+GGFlGZ7Sffs8TEK2Y326H/tW2+9lZNOOol+/frR2trKjBkzmDNnDjNnzsTn83HZZZdxww03kJubS1ZWFtdddx3jx49n3LhxAEydOpXhw4dzwQUXcP/991NbW8vtt9/ONddcoxEnERERkb2EaVq8t6aB+Wu3EgjHCUZimCbYbRDtzVQ+y2LamnncNvsx+jdvWx/f6vLyv0edzd/GfKv3nf8Sg47y5jlpLgYWZDAgL524ZbFuS4BARHuZHkj2aJCqr6/nwgsvpKamBp/Px+jRo5k5cyYnnHACAL/73e+w2WxMnz6dcDjMtGnT+NOf/pR4v91u5+WXX+bqq69m/PjxpKenc9FFF3HXXXftqUcSERERke1U1rcyY341/1m8mca2SJd9n8xehKjhdZ9zx9uPML56ybbrYfDPg6fy4DHfY0t6Ts8v/iWd2z657QZpbicep53sNBflBRkdm+2GY7gddtJdGpE6kOx1+0jtCdpHSkRERKR3dlbS/PMtbTz2/lo+WLOFGn+oYyPdFBjasI7XHrsO23axbF6/Udw9+QqWFw1KyT0AXHY4ZnAhOelOPlnfjD8UJS/dRV6Gm/KCDHLTXViWxZr6NkaV+rjq2HJV6tsP7HP7SImIiIjIvmlnJc0H5afTGIywsakdfzhG3LQwgFREqVX5/Xl/wCFMXPcp67JLuPe4S3lj8LiU7QcFUJGfzhXHDuK7YzoqO8+t2sKMD6sJhGMMyk8nze2gNRSlpiVEbrqLqSOKFKIOMApSIiIiItJjOytpXt8aYvbqeupaQpTleGmPxOnxYJRlMb56MfP6jd4WlAyDuydfzqTPF/LEmNOIOJwpeRbji6/BhRn89uyDGVmanTh29OACin2eRGCsbw3jdtgZVepj6ghtvHsgUpASERERkR7ZsaR5lBU1zTQFIwTCMRraIoRiJtF4zxZDjayt5I5Zj3DkxmVcNv0OZlUcmTi2pqA/awr6p+pRSHca2G027HYb/fPT8Xl33Ky3ojCTQZMydpjCqJGoA5OClIiIiIgkzTQtPl7fyML1jXicNirrW1lZ20o0bpHhspPmsmM3LBrbIiQbowpbt3Lju08xfemsxDqon779V94ZOIaYPfUfXw3Abuu4k8/j5OC+2ZRme3d6rs1mUJablvI+yL5HQUpEREREktK5Juq9ygaWbmohbpqEYxamBfYvzjEMiCU5nc8dDXPFRy9y9fznSY+GEu1VuaX88rjLiNnsX/PunnPYwDAM0lx2Rvb1MW2k1jvJN1OQEhEREZFu61wTVd0YpN4fIhqLE4lvKyKR2Fs3mRBlWZy24l1ufudv9PU3JJpb3On8YcJ5PHXYyUTtqVkHBZDmsmGZFtG4hc1mkOlxUJTlYdygPM47sp/WO0m3KEiJiIiIyDcyTYuNTUH+Pq+a6q0BWtujtIWiRM3eVeLzREP8/Zk7GLtpRaItZth4+tCT+P2E82hK8/W+84D9iwGmdJediqIM8tPd9MvzMqgwkz4+L4Py0+mbk6aRKOk2BSkRERER+VqdU/kWb2rmk/VNhKJxAuF40mufdibk9LAlPTvx+p2Bh3H35MupzO+Xgqt3rH/yuGy4HXYynDYGFWZy6dEDKS/IUKEI6RUFKRERERH5StuXN28JRmlpjxI1rR6PQrmjYcIOV5c9n+6ddCn9mmu5f+JFzCkfm5qOf8FhM8hyO3A57Hhddo4cmMvEwQUKUNJrtj3dARERERHZO8ViJs98tIGVtX7aI1GWb24hGrewepCiDMvk28tmM/uR73Paine7HKvOKeHki/9fykOUHXA7bNi/CG1DijKZNrJYIUpSQiNSIiIiIrKDyvpWHn6niteX1hKNd1Tl66lDN63kZ7Me4dCaVQDcMudvvDF4HGGne9tJRurCTeeVLAMsLHxpLo4qz+NcFZKQFFKQEhEREZEuVte2csd/lrJoQzOhWM9XQpX4G7j5nb9x+vJ3urSvKuhPVjhIw/ZBKkXsBmS47LhdDgwDLhjXn9MO7kOZCklIiilIiYiIiEjC6jo/t7ywmEWb/MTNno1CeSMhrlrwAld++C+8sfC2a+f1457Jl/HuoDGp6m4XTptBmttObpoLp8PGMRX5/GBShQKU7BIKUiIiIiIHMNO02NTcTiASo6E1zD/mr2PJphbiPRyIOn3ZbG6Z8zjFbY2JtkZvFg8efT7/OORE4inYVNdugNNukJPmJPLFmq0hRRmU+LyYlkVze5TSbC/nHtlPIUp2GQUpERERkQNUZ1nzqoY22qMxPl3fTF1ruFf7Qk1c+0kiREVtdv425jT+eNQ5+D0Zve6vATjsBk6bgS/NyYg+PvrnpmEBzcEo4Vgct8POkQPzmDqiSOuhZJdSkBIRERE5AMRiJp9saGJrIEJeuossr4On5lWzpTWE3WawuraV2tbwN1/oG9w/8SJOWjWX9wccwr3HXcra3NIU9B6cNijIdDMgL50RpVkcPjCPYcVZlGZ7ARKjaukuh/aHkt1CQUpERERkPzdrRR1/+2Ad67YGiMZNnHYbNsPAYYNI3GRrW4RgNLm5fGmRdq6e/zzrcvrwwqgpifbarHyOv/whNvkKU9J3hw2KM91cf/xQRvTNItPt3GlQKstNS8n9RLpLQUpERERkPzZrRR33vbaS1lCUvDQXYLGlLUJDWwTomC6XTIQyLJPpS9/mpneeoDDQRENaNjOHjKfNvS3IpCpEGUBpTho/O3U4U4YVpeSaIqmiICUiIiKyn4rFTP72wTpaQ1EKMlzUNIdoCUXZvqJ5MuuhjtiwlDtmPcKouqpEmy/UxtiNy5hTfnjK+u20GaR7HOSnu/jZacOZOCQ1wUwklRSkRERERPZTC6sbqWxoxWUzWLslQDBi9qiQRN/mWm6d8zinrPqgS/vMweO497hLWZ/TJyX9NYAsr4PRpT5sNoMjBuRxdEVBSq4tkmoKUiIiIiL7sC8XkTisLAeHw8bq2lYefW8tW9sixOJWUtP3OmWEg/xg/rNc9tG/ccdjifblhQO5e/IVzOs/OnUPAngcEItbLK9pZdygXKaNLFLRCNlrKUiJiIiI7GM69356e2UdLy+qoaalnZhp4bAZlPi8VBSm8+HaJmpb2onEe17M/H8++AdXfvRi4nVDWja/mXgBz406HjMF+0F9md1mx24ziMTitEfjKb++SCopSImIiIjsQzr3fnq/soHFG1uIxk3S3Q4y3Q7ao3E+29DER+ubUnKvh8edyTmLZuKOR3hs7On83/izuhSVSBWHAXa7QZrbTlGWh/ZInEjM5I1ldQzKz9ColOyVFKRERERE9hGV9a08/sE6traGqaxvIxSNYzPA3x6lpT2K3TC6FJJIRr+mGsobNzJ7u6IRjWk+fnTaj1md358N2cUpeoquDMDltOF12ombEI9bOOw2SnweKuvb2NTcrtLmsldSkBIRERHZB5imxcyldWxti1DfGmJLWwQLMK1tlfdMK/lpfJnhANfMfYZLFr5EyOHm2O8/QrM3K3F8VsWRqXmAr5DmspPuduCwGQQjMVrDMcpy0yjIdLN+a5BAJPbNFxHZAxSkRERERPYBm5rb+bS6idV1rWxoak+Ep56ugLKZcc5Z/AY3vPd38oMtALjjMa5a8AK/mnRJSvoMHSNOBh39tBngshsYhkEkbmE3wOu0JTYGjpsWaS4H5QUZhKImboeddJc+rsreST+ZIiIiInupzqISgUiM15fWMv/zrbRFel+E4ah1n3HH248yrGFdoi1sd/LIEd/hoSPP7PX1t2cBTrtB3xwvWR4HWwNRMtx22iNxwnGT1lCMuGkRNS1y010cPiCHnDQna+rbGFXqozTbm9L+iKSKgpSIiIjIXqizqERVQxv1re18Vt1MW6SHC6C+MKBxEz+d/RgnVC7o0v7fg47h15MuZqOvqFfX79Q5AmX/okaE027DbrPRLy+DmNlGQ1uYvjleBhdk8OG6RprboxSmuzliYA4uh4019W3kpruYOkLlz2XvpSAlIiIispfpLCrRGIjgcdioqmvrdYiaUrmAh168D5e5bc3RouLB3D3lcj7uO6K3Xe7CaTcwLatjWp9hUJTl/mJ0LUh2mhO7zSAnzUVrOMagggzCURO300ZrKEYkZjGq1MfUEUVUFGamtF8iqaQgJSIiIrIX2VZUIozHaePT6ia2BiO9vu5HfUfQ6k4jr91PXUYuvz72Il4ccRyWYUtBrzvYALsN3HYbXrcdu2HgsBk47TbCsTj1/jAnjyph+phSvE4HgUiMdJeDkiwPNf5Q4nVptlcjUbLXU5ASERER2Ytsam7nk+pG6vxhNjQGCYRjxHpQUaKPv57NWYWJ135PBr8+9mJK/fX8+cjpBF2pX3vUUVDCwOmw4XHa8XldHNzXh9Nuoz0ap84f4tuH9GFIUdYO71WJc9nXKEiJiIiI7CVM0+KFhRtYsLaRaNwk3IMEVb51A7fNfoxx1UuYdOVfaMjITRx79uCpqezuDgzA5bDhS3NS4vNSXpBBbrqr45gBOWkuMj3OXdoHkd1FQUpERERkD9i+Il+6y0F7NMY/5lfzwicbaQsnX5nP197KDz+Ywfc+fRWn2fH+n7z7FDeffH2qu75TB5dm0cfnwR+OMbgwkyyvE8PomJ5nWRY1LSFV4ZP9ioKUiIiIyG7WWZGvsr6VpmCEpmCEupYQbaEIbdHkruWIxzj/s9f40ftPkx1qS7TXZOTxwYCDU9zz7e5rQNwCmw1GlPh44LsHY7PB4x+so641jM1m4HV1lDmvaQmpCp/sdxSkRERERHaRzlGn1lCUtnCMDI+DrW0RXl1cw5r6VjY3h9jSFqKnW0NNqvqY299+lIrGjYm2oNPNn4+Yzl+OOIN2lydFT9KVAZhAmsvG+PJ8bjnpoESFvUsmDEiUba/zh3A77KrCJ/slBSkRERGRXaBz1OnTDY1U1Qdoj8bxOG3E4hZbAxHaoz0vZ17YupX7X/t/TFq7sEv7CyOO44GJF1Gbld/b7u/AALLcBrkZHoqyvEw6qICpw4oYkJ/RZZSpojCTQZMyukxbVBU+2R8pSImIiIikWOc+UCtr/azfEqQ92rF309aARTTegxJ8X9LqTueghrWJ1wv7HMRdU65gUZ+hvb72zjgMGJCfzrjyPFx2G83BKKeM6vOVlfZsNkNV+GS/pyAlIiIikkKd+0BVbw2yYWuQQCSGzTCIxuL0eBDKsjrK3n2h3eXh18dezI/fe4pfTbqElw86psvxVHHaweOwU1GYztEVBdhsNmKmSd0Xez6JHMhStwObiIiIiLCpuZ019a3Ut7bjD0WJx00i0R6GKMviuKqPePVv/0Pflrouh/49YhJTLn+Yl4dN3CUhygBsho2iLA8jS3Ow2To+NrZH4rgddtJd+n28HNgUpERERERSaEWNn0Ubmlm/NUgoZhExIWp1bFabjCEN63jy2Z/x+PN3Mrx+LbfM+VuX45ZhI+x0p6zfnRzGF182A6+zo1BE515QnWXMKwozVMZcDnj6VYKIiIhIL2y/H1SdP8SzH29gayDSo810AXKDLfzo/ac577PXsVvbhrEK27bijoZ3SXiyG+Bx2MjPdFNekAmGRfXWIK2hKBYQM02VMRf5EgUpERERkR7qrMxX1dBGfWuIFTV+2iNxIjEz6REoZzzKhQtf5vq5/yQrHEi0b8wq5L5Jl/DKQUfvkil8AOkuO4MKMxhVmp0Yfcr2OllZ20Z7NM66LQGVMRf5EgUpERERkR7orMzXGIgQicZYvLGFtnAMM9kEZVmcULmA22b/lYFNNYnmNpeXP437Ln89/HTCDldK+965mS50BKbTRheTne7G+CKoWZZFe9TklFHFnHZwH4LRuMqYi3yJgpSIiIjIN9h++l66y0FRhptnP9rIui0B2kJRlm7209Oq5k4zxu1vP0r/5tqOe2Hw3Kjj+c3EC2jIyE3hU3QUkAAwDAOHYZHpcTKy1EdDIIrDYcfrsneZwjdtZDH98tJT2geR/YWClIiIiMh2tg9NXqed9VuCvLWijpW1fqJxE5vNwADWbQkQjMQJ9mJjXYCo3cm9x13Kn1+8lwVlI7lryhUsKypPzcN8wW6Ay2HDNC3iloXdBrnpboaX+Lh4wgAWbWihqqGNOn9IU/hEuklBSkREROQL26952tIWZlNzO7UtIcKxOFZn5b0vtnTqyQiUKxblkoX/4a3yI6nKL0u0zxw8nnPP+SXz+o1O2TooG2DSEaJ8Xgdup51w1CQUjVOU5aZvbhqH9c/hqPJ8jirP7zLipil8It9MQUpERESErmuevE4bW9si1LaECETiO57cg3VQ01bP47Y5j9G/uZYjq5dy6Xd/se24YTCv/8G96X4XDhs47TZsX4SyUMwibsaImRbZaU765qbRLze9S/W9sty0lN1f5ECgICUiIiIHPNO0mLm0jq1tEYoyXXy2sYWGtq8IUUkaUVfFHbMeYdyGpYm2Y9d+QsWWairz+/X6+p0MwGEHj8OO9cXrwiw34ahFIBIDwOe2M7wki8P652jqnkgvKUiJiIjIAW9TczufbmiiKRBhdV0rtS3thHq59qmgrYkfv/cUZy1+E9t2Q1hz+43m7imXpzREpTltmFgYGORluMhOc4EFoZiJQZy4aaMsN43LjhnI8BKfpu6JpIBtT978vvvu4/DDDyczM5PCwkJOP/10Vq1a1eWcSZMmYRhGl6+rrrqqyznV1dWccsoppKWlUVhYyI033kgsFtudjyIiIiL7sBU1flbXttIcjGCaJqGYSU9jlDsW4er5zzH7kSs5Z/EbiRC1LruEK864nfPO+SUrCgelpN82wOexc1hZNmU56RxVns9xQ4uYOLiAiUMKGD8ojyMH5XP04AJKs70ML/FRlpumECWSAnt0ROqdd97hmmuu4fDDDycWi3HbbbcxdepUli9fTnr6tlKbV1xxBXfddVfidVratjm88XicU045heLiYubOnUtNTQ0XXnghTqeTe++9d7c+j4iIiOwbtq/Ml+a089HaRmKmicNmp8YfSn4vqO386d/3MaXqo8RrvyuN/zfhHJ487DQiDmcKet+hj8/DmP45NLdHmDq8mLlVWykvyMC+XUjK8nbcL2aarNsSSEzxE5He26NB6vXXX+/y+m9/+xuFhYUsXLiQiRMnJtrT0tIoLi7e6TXeeOMNli9fzltvvUVRURGHHHIId999NzfffDO/+MUvcLl23MAuHA4TDocTr/1+f4qeSERERPZ221fmC8XixE2LNXWttIVj1LSEk64j8WVPHHYqU6o+Im7Y+MfB03jwmO/RmOZLSd87DSlM48hBBTjtBk67jaHFmXxa3UwwEiPTs2NYa4/EcTvspLu0qkMkVfbo1L4va2lpASA3t+vmc08//TT5+fmMHDmSW2+9lWAwmDg2b948Ro0aRVFRUaJt2rRp+P1+li1bttP73Hffffh8vsRXWVnZTs8TERGR/YdpWry3poEH31zNh+u24vM6GZSfQUswwvqtQfyheNIhqrB1K/2bNndpe3fQGP5w1LmcfMn/4/Zp16Q8RA0rzuTEkX3ISXNS0xKiojCDw8pyKC/IoKYlhGV1fQrLshLnlWZ7U9oXkQPZXvNrCdM0+eEPf8iECRMYOXJkov28886jf//+9OnTh8WLF3PzzTezatUq/vWvfwFQW1vbJUQBide1tbU7vdett97KDTfckHjt9/sVpkRERPZjlfWtvL6klleX1FDfFibdZWdrW4TcDCfLa/xJ7wnljoa54qMXuXr+8ywpruCcc+/rsv/T7445P8VP0LEfVP+8NI47qPCL0bMQuekupo4owuGwMW1kEZtb2llT30aJz4PXZac9Eu9yntZGiaTOXhOkrrnmGpYuXcr777/fpf3KK69M/HnUqFGUlJQwZcoUqqqqKC/v2a7fbrcbt9vdq/6KiIjIvqFzf6jVta3U+kNETZPWUJSNTe1YkNx6KMvitBXvcvM7f6OvvwGAcRuWMm3NPGYOOSql/TYAu80gy+MgL8OJ1+mgMMvD+q0B3A47o0p9XUqYVxRmcsmEAYlpi3X+0E7PE5HU2CuC1LXXXsvLL7/Mu+++S9++fb/23COPPBKAyspKysvLKS4u5sMPP+xyTl1dHcBXrqsSERGRA0Pn/lDVW4M0BSO0R+OYpoWFhc2AZCqcH7x5FXe8/ShjN61ItMUMG38/9GQWlI38mncmz/nFflB5GS4qCjM5rF8Oxw8vxOt0EIjESHc5dlrCvKIwk0GTMhKFNL7qPBHpvT0apCzL4rrrruPFF19kzpw5DBw48Bvf89lnnwFQUlICwPjx4/nlL39JfX09hYWFALz55ptkZWUxfPjwXdZ3ERER2fuYpsWGpiBrtwQAcDtsfFbdyJa2MO2RGKZpEU5yHl+xfws3vvsE05fN7tI+Z+AY7pl8WUr3g8pLc3Lekf04rH8OXpedLK+TTLczqTBksxmU5aZ984ki0it7NEhdc801zJgxg//85z9kZmYm1jT5fD68Xi9VVVXMmDGDk08+mby8PBYvXsyPfvQjJk6cyOjRowGYOnUqw4cP54ILLuD++++ntraW22+/nWuuuUbT90RERA4gq2tbeeS9KhaubyIQjmOaJuG4RSgWw4ZBOGYlXUzizCVvcdebD5EW3VbttzK3L/dMvpw55WNT1nenHXLTXIws9XHW4f0UhET2AXs0SD300ENAx6a723v88ce5+OKLcblcvPXWW/z+978nEAhQVlbG9OnTuf322xPn2u12Xn75Za6++mrGjx9Peno6F110UZd9p0RERGT/sP3+T9tPW5u1oo77X1/JhqZ2sDqm7oWj1nab6vasqPm6nJJEiGryZPK7o89jxiEnEbOn5iOUy27QN8dLbpqLDc3tROMWJVmelFxbRHYtw/pyjcwDkN/vx+fz0dLSQlZW1p7ujoiIiOzEl/d/8jjslBdkUF6Yzv2vrWBDUzsGHZEpmbVP23PHIoQdXfeg/N1/f0OTN4s/TDiXFm/qCjbkpjnok+3FYbfRFopht9soy/Hy89NGaERKZA/qbjbYK4pNiIiIiHydzsp7jYEIJT4PaS4vwUiMt1fV8se3/YRivfu9cIm/gZvf+RsDmmr4zgW/wTK2bbX5o1N/3KW0eW/ZAa/bTnaai1DMxGFCYZaH/nlp+NujBCKxlN1LRHYdBSkRERHZq3VW3msMRBhcmIHxRahpaAuzYnNrr0JUWqSd7y94gSs/fBFvrGMK3+nL5vDiyMnbTkpBiLIBXpeBZRlkep1kuGyM7JtNhtuBy24j0+OgLRwjHDVJd+njmci+QP9PFRERkb3apuZ2qhraKM5y42+P0hSM0tIeYf7nWwj1cPDGsEy+s2w2N73zBMVtjYn2Rm8WVgpHnwDcDoMMl4Nw3MTrsmM3DBx2O7lpLrK8TqCjknFNS4hRpT5Ks70pvb+I7BoKUiIiIrJXC0RibGkLU9XQ1lFoIhyjvaeLoIAxG5fzs1mPcHDtmkRb1Gbnb2NO449HnYPfk5GKbgMdm+q6HXYwOkqxDy/JYu2WAB0r1C1ipkl7JE5NS4jcdBdTRxRpzyeRfYSClIiIiOzVGlo7QlRTIEr8i5LmPdHHX89tsx/n1JXvdWl/s+JI7j3uUtbmlqaiuwkGkJPmpCDTjWFAJGZiGHBwWTaFmW6ag1HqW8O4HXZGlfqYOqKIisLUFbMQkV1LQUpERET2KtuXOPc67Sxc20RrKEZ7NN6r6+YG/Zy88v3E65X5/bl7yhV8MOCQXva4KweAAaU5Hvpkp9EUiNAcjJKX7uKIAXlMG1nEoPyMnZZxF5F9h4KUiIiI7DW+XOK8JRhlRY2ftlCshztBbbO0uILnR01hctVHPHjM93hm9FTiNntK+g0dI1AANhu4nXZGl+WQn+7i8y0BBhVmcN4R/TiqPD8RmFTiXGTfpn2k0D5SIiIie4MvlzgPhmPMXlVPfWsk6RB1xIalnPfZa/z4lBu6hKXsdj9xm51Wd3pqOw/YbZDmtONy2MhOczG0KAOP00FFYYam7YnsQ7SPlIiIiOwzti9xXlGQzvKaFuZVNRJMsqhE3+Zabp3zOKes+gCAj/qO4OlDT04cb/am/hemTht4nDYyPU765qRRUZDBSaNLKMh0a9qeyH5MQUpERET2uE3N7VTWtxKPm/zrk43UtIRJJkJlhINcM+9ZLv3437jj22qin7hqbpcglSoG4PM6cDtsGECW10m/vHQO65ej0SeRA4SClIiIiOw2pmmxoSnI2i0BAAblp9M3J40VtX4WrN1KvT9MMvvr2sw4313yFj959ykKgs2J9oa0bB6YeCHPj5qS4icAj8PgqknlfOfQvgQiMdpCMTLcDjI9To0+iRxAFKRERERkt6isb2XG/Grmr22kuT0CFqS7HPTL87KxKcjmlnBS1xu/fjF3vP0Iw+vXJtrCdgd/Pfx0/jTuLNrcqSvmYDfAaTcoyHRzx6kjmDqiOGXXFpF9k4KUiIiI7HKV9a38/q01LNrQjGVZuGwGbeEYTcEwn29pI9mtoYr9W3jqmdtxWNsmAL4ydAL3TbqEjdmpDTkZLhtDijIZOyCXM8f2ZUiRClOJiIKUiIiI7GKmafH6klqWbGzGH4oSi8UJxy0si6QDVKfarHz+fujJXPzJyywpKufuKVfwYdnI1HYcyHLbOWFEMf8zZTBlOWmaticiCQpSIiIikhLbb6S7fbW6Tc3tvLWils0tIeJxK6kiEgB2M87py+bw32ETiTicifbfH30eS4sreGHkZCzDltJnMeioxpfhcTJtRDH981JfLl1E9m0KUiIiItJrlfWtHaNOm1oIRGOkOx2MKvVx4qhi3l1dz9JN/qSKSHSasO4zbn/7UYY1rCM32MIjR56RONbszeL5Ucen8Ck6dKyHspGb7mR4SRbDSjSVT0R2pCAlIiIivbK6zs+vXltJZV0rMdPCZhjYDINVda28umwz6xoCSYeogY2buG32Xzmh8sNE23XznmHGIScSSGERCegYfQJIc9nxeR3YDIM0l50in4fD+udQmu1N6f1EZP+gICUiIiJJMU2LjU1BPt8SYFNTOzMWrKeqIUDcssCyOoKJYWBZEDWTS1BZoTb+54N/cNEnL+M044n2z0oGc/fkK1Iaojqn7gUicUzTIsPtIMPjJNPjIM3loF9uGlNHFGldlIjslIKUiIiIdFtlfSszFlQzv2orda0hWkMxIl9UjHDawGazEY2bWKZFMhHKbsY597PXueH9p8lt9yfaazNy+fWxF/PvEZNSug7KBuRluDhiYB6bm9uBjk11LQuyvU4GF2VqY10R+VoKUiIiItItnSXMP17XSCgSpz0aJ7pd2b2oCTbTTLqYhM2M8+8nb2BUXVWiLeRw8ecjpvPwkdNpd3lS9ARf3A8wgUjMIhw1GVqcxUVH9cfrdOxQKENE5KsoSImIiMg3Mk2L15fWsmRjC4FwDAOw6CjMsP36p2RDFIBps/P+gEMTQerfw4/l/mMvYnNWYSq63oXdgM7ZhhYwID+d747tq5EnEUlar4OU3+/n7bffZujQoQwbNiwVfRIREZG9zKbmdhZvbMEfinbs/4RFNJ7c9L1OvvZWwg4nIee2kab/G38Wg7es50/jz+KT0tR/njAAhw0cNhtxy8LtsDG0KJNvH9JHIUpEeiTpycZnnXUW//u//wtAe3s7Y8eO5ayzzmL06NG88MILKe+giIiI7DmmabGhMcjSzS3UtrQTisaImRaRmJl0iHLEY1y08L+885cr+P6Cf3U51uZO4/Izf97rEOVxGPTP9ZDmNDDoGIHyOGzkpDnJ8jpxOgw8TjtluWmU+DxkepzfeE0RkZ1JekTq3Xff5ac//SkAL774IpZl0dzczBNPPME999zD9OnTU95JERER2f0q61uZubSOyvpWNre0s7ahjfaoBT0Yh5pU9TG3v/0oFY0bAbhqwQs8M3oqtVn5KetvutNG/7x0wnGTDLcTmxEnEjdx2g0sLCzLwGGzkZvuIi/DzeCiTJU2F5EeSzpItbS0kJubC8Drr7/O9OnTSUtL45RTTuHGG29MeQdFRERk1zJNi03N7V0KLXy+pY3HP1hHdWOQra1h1m9tIxBNPkBVbKnm9rf/yqS1C7u0vzr0KOI2e6oegUy3g5F9shjTP5slm/0MGlzA0OJMZixYT60/jMMGHqednDQXaW6VNheR3ks6SJWVlTFv3jxyc3N5/fXX+ec//wlAU1MTHk9qq+qIiIjIrtU56lTV0EYoFsfjsDMoP52tgTCra/1saAzQEIgST7KKRE6whR9+MIPzP30Nh7XtzQv7HMRdU65gUZ+hKXsGlw2KfG5Ksj1UbQnSNyeN88f1o6Iwk8P65fD8wg1UNbRhqrS5iKRQ0kHqhz/8Ieeffz4ZGRn069ePSZMmAR1T/kaNGpXq/omIiMguUlnfyuMfrGNrW4Qsj4MsjxPTtJizuoFVta2EojGiPSjDd/6nr3LTO0/gCwcSbRuzCvjVpEt4+aBjwEjdKJDdgL45afTxeQGDUaW+LiFpSHEmt5w0bIcRN41EiUhvJR2kfvCDH3DEEUewYcMGTjjhBGy2jnoVgwYN4p577kl5B0VERCT1TNNi5tI6qhuDxGIm67a0EYzGaI+Y+ENRwrGe1OPrkBtsSYSogNPDn8Z9l0cPP52w052q7gOQk+bkxmlDmFBRQHs0/pUhyWYzKMtNS+m9RUQMy7J69DdlJBJh7dq1lJeX43Ds29tR+f1+fD4fLS0tZGVl7enuiIiI7HIbGoPc+d9lbGwKEgzHCUZiNAej9Cg/WVaXUSZPNMRbj/6Auf1H85tjLqA+My91HQdcdhjZJ4trJg9hyrCilF5bRKS72SDpBBQMBrnuuut44oknAFi9ejWDBg3iuuuuo7S0lFtuuaXnvRYREZFdqrOwxOJNzVTVtxGNm/hDMVpDsaRr8eUGW/jR+0/T6k7j/mMvTrSHnB6mXvZ/BF2pqYhn0JHTnHaDg/tmc84R/fjW6D44HEnv4iIikjJJB6lbb72VRYsWMWfOHE488cRE+/HHH88vfvELBSkREZG91Ora1kThha2BCLX+ELGYSbLF+JzxKBct/C//M/cZssIBIjYHz4yeyvqcPolzUhmi8tIclOWlcfYR/TlrTJnWN4nIXiHpIPXvf/+bZ555hnHjxmFsN4w/YsQIqqqqUto5ERERSY1ZK+r4f7PW0NAaxuUwsEyLaMxMbiqfZXFC5QJum/1XBjbVJJojDicHNazrEqR6y2EzcDtsnHZwH844rJTDynI0AiUie5Wkg1RDQwOFhYU7tAcCgS7BSkRERPYOq+v8/OGt1WxqbifL48BmGGxtjyQVoobVf84dsx7lqOrFiTYTg2dHn8Bvj7mAhoyclPXXYYO+OV4uO3ogF4wfkLLrioikUtJBauzYsbzyyitcd911AInw9OijjzJ+/PjU9k5ERER6xTQtHnl3LWvqW4nFLbYGokm9Pz/QxA3v/Z1zFr2BbbtVVPPLRnL3lCtYVlSesr467dA/N50Lxvfj3LH9cblSt2GviEiqJR2k7r33Xk466SSWL19OLBbjD3/4A8uXL2fu3Lm88847u6KPIiIi0k2xmMnH1Y2sqWvD47QDFq8tqaE92YVQXzhtxbuct2hm4vX67GLunXQpM4eMT9l+UAaQ43UwsDCDKQcVccG4gVoHJSJ7vaSD1NFHH81nn33Gr371K0aNGsUbb7zBYYcdxrx587Qhr4iIyB40a0Udf5pdyZr6NkLRGKZJz8qZb+fvh57MBZ+8QkGgiT8edQ5/G/MtIg5najoMeBwGZTleirO99MtNZ+qIIoUoEdkn9Hgfqf2J9pESEZF93awVdfzipWXUt4awLItYHMwkrzGirooxG5fz5JjTdmivy8hlS3rq1kEBFGe56ZebRmm2l8FFmUwdUURFYWZK7yEikqxdto9UdXX11x7v169fspcUERGRXojFTP7v7TUd5czjVtL7QRW0NfGTd5/ku0vewjIM5vcbxeqCAYnjqVwHBWA3YPLQAn56ynBCcZN0l4PSbK9GokRkn5J0kBowYMDXVueLx+O96pCIiIh01bmJbiASI93loCTLQ40/RGsoSls4xoLPt7KsppVoPLkI5Y5FuOyjf/OD+c+REWnvaLQsLvvoP9x88vUpfQab0bGkyu2wM3ZADjefPIwBBRkpvYeIyO6UdJD69NNPu7yORqN8+umnPPjgg/zyl79MWcdEREQEKutbeX1pLYs3ttAUjBCLm9htBg6bQWMgij8UoSkYJZzMYijL4uRVH3DrnMcpa6lLNPvd6fzhqHN4csypKX0GA3A5DIoyPUw5qIjzxvXTFD4R2eclHaQOPvjgHdrGjh1Lnz59eOCBBzjjjDNS0jEREZEDXWV9K79/aw1LNrbgD0UJRWNEYhaW1THC47CDaUIkicVQo2rWcMfbj3DExuWJtrhh4+lDTuL3R59HY5ovZf33eez4vE48Tgej+vq4dnIF/XPTNYVPRPYLSQeprzJ06FA++uijVF1ORETkgGaaFn+ft565lVsIRmLYbQZYHaM7ccC0IBZL7prj1y/mH/+8rUvbuwMO5Z7Jl3VZE9UbHQXXwe20MbyPj4rCDJx2G83BKA6bTSFKRPYbSQcpv9/f5bVlWdTU1PCLX/yCwYMHp6xjIiIiB7JnPq7mmY+rt9v/qfdFdheUjWBFwQCGNayjKreUeyZfzuxBY1O2H1Smy0bMAqfdxuEDcxlRkoVhGMRMkzp/iEAkyeQnIrIXSzpIZWdn71BswrIsysrK+Oc//5myjomIiBxIti8o8dmGZn77xuoeb6ILgGVx2OaVfFI6bNs9bHbuPP5KhtWv5e+HnkzUnrr9oAw69qwqyHRzSFk2A/O3FZJoj8RxO+yku1I2EUZEZI9L+m+02bNnd3lts9koKCigoqICh0N/QYqIiCRrdZ2f5z/eRFVDG5FolE+rWwhEk90FapuDN6/iZ7MeYczmlXzrwgdZXDIkcWx+v9HM7ze61322AU67gctho6IogwZ/mPwMN0dX5GO32xLnWZZFTUuIUaU+SrO9vb6viMjeIunkc+yxx+6KfoiIiByQZq2o4//NWkNDa5iYadIcjBJJsox5p2L/Fm569wnOWLbtl54/m/UIZ55/f8qm7wH0z/Xicdqx2wzicZMsj5NDy3IIReNUbQlQ4vPgddlpj8SpaQmRm+5i6ogirY8Skf1Kt4LUSy+91O0Lfutb3+pxZ0RERA4UpmnxXmUDv359JQ2tYbxOO42BCLEeDER5oiG+v+BfXLXgBbyxcKK9Mrcv/zv+7JSFKIfNoCDDRU66C4fNoKE1jNthp292Gucd2Q+AmUvrqGpoo84fwu2wM6rUx9QRRSp3LiL7nW4FqdNPP71bFzMMQxvyioiIfIPK+lZeX1LLsx9Xs6k5hGVBE9Gkr2NYJt9a/g43v/MEfVq3JNqbPJn87ujzmHHIScTsvZ92bzPAaTMYUZqF025jS1uEQDiG12nn6MH5nHfktn2hBk3K6LJ5cGm2VyNRIrJfsn3zKWCaZre+kg1R9913H4cffjiZmZkUFhZy+umns2rVqi7nhEIhrrnmGvLy8sjIyGD69OnU1dV1Oae6uppTTjmFtLQ0CgsLufHGG4klWxNWRERkN1hd5+ePb1fy7083sbklRNyCnqyGyg228K+nbuQPL/82EaKiNjuPjfkWk678C0+OOS0lIao8P41RfXwcPiCX/rnp5KW7qCjI4KSRJdx9+khuP2V4l9Emm82gLDeNg4qzKMtNU4gSkf3WHq0O8c4773DNNddw+OGHE4vFuO2225g6dSrLly8nPT0dgB/96Ee88sorPPfcc/h8Pq699lrOOOMMPvjgAwDi8TinnHIKxcXFzJ07l5qaGi688EKcTif33nvvnnw8ERGRLpZvauGWfy1h3ZY22sLxHgWoTk3erlPlZpUfzr3HXUpVXlnvOrmdI/r7yMv0kpvu4qKj+uN1OjTSJCLyBcOyrKRXtAYCAd555x2qq6uJRCJdjv3P//xPjzvT0NBAYWEh77zzDhMnTqSlpYWCggJmzJjBmWeeCcDKlSsZNmwY8+bNY9y4cbz22muceuqpbN68maKiIgAefvhhbr75ZhoaGnC5XDvcJxwOEw5vm0Pu9/spKyujpaWFrKysHvdfRETkqzw1bx3/b9YatgYimD2oJeGKRYk4upYrP3TTSu57/Y/8cvJlvDfwsBT1FFx28HmcHDYgl4P7ZmuNk4gcUPx+Pz6f7xuzQdIjUp9++iknn3wywWCQQCBAbm4uW7ZsSUyr602QamlpASA3NxeAhQsXEo1GOf744xPnHHTQQfTr1y8RpObNm8eoUaMSIQpg2rRpXH311SxbtoxDDz10h/vcd9993HnnnT3up4iISDLeXF7Lb2aupjUcTTpEGZbJd5bN5qZ3nuD6025kQb9RiWOflh7ESZf+Ecvo1kz9b+SyGwzI8+JLczOyj49LJgygb46m54mI7EzSf/P+6Ec/4rTTTqOpqQmv18v8+fNZv349Y8aM4Te/+U2PO2KaJj/84Q+ZMGECI0eOBKC2thaXy0V2dnaXc4uKiqitrU2cs32I6jzeeWxnbr31VlpaWhJfGzZs6HG/RUREdsY0LdZvDTBrZS0///dSWkLJh6gxG5fz7yd/zIOv/I7itkbuePtRbGbX9cipCFE2A/LSnBw7pIBBBVkMKcrk/HH96JeXrhAlIvIVkh6R+uyzz/jzn/+MzWbDbrcTDocZNGgQ999/PxdddBFnnHFGjzpyzTXXsHTpUt5///0evT8Zbrcbt9u9y+8jIiL7P9O02NTcTms4SlsoRrrTwYo6P68t2czSTa20tEcIxZJLUH1b6rhlzt84deV7XdprMvPJiLTj92T0ut82wO20YRiQ6XEytDCTTI+TisIMTeUTEemGpIOU0+nEZuv47VdhYSHV1dUMGzYMn8/X45Gda6+9lpdffpl3332Xvn37JtqLi4uJRCI0Nzd3GZWqq6ujuLg4cc6HH37Y5XqdVf06zxEREdkVKutbmbm0jk83NLF+a4CmYJS29iihHm6omx4OcvWC57niwxdxx7eVQ19RMIC7J1/O3AGHpKTfBpDlddDH52XcoDyOG1ZIQaZbRSRERJKQdJA69NBD+eijjxg8eDDHHnssP/vZz9iyZQtPPfVUYkped1mWxXXXXceLL77InDlzGDhwYJfjY8aMwel0MmvWLKZPnw7AqlWrqK6uZvz48QCMHz+eX/7yl9TX11NYWAjAm2++SVZWFsOHD0/28URERLqlsr6Vxz9Yx/qtAdZtCdDcHqUt3MO9FC2L7y55ixvffZLCQFOieUuaj98ecwHPjD4B02ZPSb8LM10cUpbDuUeWMSg/gzKtgRIR6ZFuB6l4PI7dbufee++ltbUVgF/+8pdceOGFXH311QwePJjHHnssqZtfc801zJgxg//85z9kZmYm1jT5fD68Xi8+n4/LLruMG264gdzcXLKysrjuuusYP34848aNA2Dq1KkMHz6cCy64gPvvv5/a2lpuv/12rrnmGk3fExGRXcI0LV5fUsuqGj9rt7bRHIzRw0GohNOXz06EqLDdweNjv83/jT+LVnd6CnrcMQqV5rIxdkAuN5wwRFP3RER6qdvlz4uLi7n44ou59NJLGTJkSGpubuz8N2CPP/44F198MdCxIe+Pf/xj/vGPfxAOh5k2bRp/+tOfukzbW79+PVdffTVz5swhPT2diy66iF/96lc4HN3Lid0tcSgiIgLw3poGfvHSMmpb2glEerMb1DYH1a/llb9dzxuDx3HfpEuozilJyXUBnDbITXeRl+Hh1pMP4pjBBSm7tojI/qa72aDbQeruu+/miSeeYO3atRx11FFcdtllnHXWWaSlpaWs03uKgpSIiHRXZX0rv31jFbNX1ROOWiQ7EJURDnLNvGeZ328U7wwa0+XYgMZNrMstTVlfXTYY0SeLocVZ1PhDHDEgl6snVWgqn4jI1+huNuh2zdQ77riDyspKZs2axaBBg7j22mspKSnhiiuuYMGCBSnptIiIyN7MNC1mLKjmk/XNhJIMUTYzztmLZjL7L1dy9YLnuWPWIzjisS7n9DZEGUCGy06G207fbA/fOayUQ/vn0hKK0TcnjWkjixWiRERSJOnNJyZNmsQTTzxBbW0tv/3tb1mxYgXjx49nxIgRPPjgg7uijyIiInuFd9fU89KiTdS1hpN63/j1i3n5iR/y69f/SEGwGYCyllpG16xJWd8MoCzHw5GDcjm0LIeDSrJoC8dpDkYZVdqxua7WRYmIpE63p/Z9nVdeeYULL7yQ5uZm4vEeVizagzS1T0REOpmmxcamIKvrW6mqbyMYiRGJWjS1h3llcS2tSVTm69+0mdtmP8a0NfO7tL8ydAL3TbqEjdmp2abDAEb2yeK64wczrDiLkiwPNf4QgUhMJc1FRJLU3WyQdPnzTsFgkGeffZbHH3+c999/n/Lycm688caeXk5ERGSPq6xvZcaCat5cVkutP0S0h3UkMsMBrp37DJd8/BIuc9v0vSVF5dw95Qo+LEtuu5CvYzOg1OfhppO6FpEoy9331zCLiOzNkg5Sc+fO5bHHHuO5554jFotx5plncvfddzNx4sRd0T8REZHdorK+ld+/tYb5VVtoCkZ7Vc78zjcf5oxlsxOv69NzuP/Yi3hh5GQsI+lZ9TuwAXYH2DAYlJ/OqaP7MKE8v9fXFRGR7ut2kLr//vt5/PHHWb16NWPHjuWBBx7g3HPPJTNT861FRGTfZpoWry+tZeXmFvztvQtRAH886hxOW/EucZudRw7/Dg+NO5Ogy5uSvtoAt9NGhtsOGAwpzlIRCRGRPaDbQeqBBx7ge9/7Hs899xwjR6ZuSoKIiMietrEpyPzPt1LbEiLZbaEGNm4iL9jMx31HJNrW5pZy48k/5KO+I9jkK0xJH+0G2G0GLruNLK8dyzIYXJTJNceVq4hED5mmxabmdq0lE5Ee6XaQ2rx5M06nc1f2RUREZJfa2Qfnz7e0cd+rK5hftZVYEiNRWaE2/ueDf3DRJy9Tm5nP8Zc/RNjhShz/94jjUtZvmwEep53yggxKfB4CkRh5GW6umVTBkCKFqJ6orG9l5tI6qhraCMXieBwd399pI4sUTEWkW7odpBSiRERkX7azD87ZaU4Wb2jmk+pmujsQZTfjnPvZ69zw/tPktvsBKGup43ufvspfDz89pX22GVCQ4aJPtpc0lwOf14HH6eDgsmymjtAH/p6qrG/l8Q/W0RiIUOLzkObyEozEWLq5hc0t7SoVLyLd0uOqfSIiIvuKzg/OW9siZHkcZHmcxE2T15bUUOPv/p5QEz9fyO1v/5UhW6sTbe0ON38+8gxmHHxiSvqam+7E57HT0h4jP9PD7acM46hB+SpnniKmaTFzaR2NgQiDCzMwjI7vY6bHSYbbwZr6Nt5YVseg/Ax9j0XkaylIiYjIfqlzGl9rOMqLCzeyus5POGqyPBjFxMIfjOLv5p5Q5Vs38NO3/8rkzz/u0v7i8Encf+xF1GQVfMU7u6fz43qm206m20E4ZtEvN53rpgxm4pCONVYqZ54am5rbqWpoo8TnSYSoToZhUOLzUFnfxqbmdn3PReRrKUiJiMg+7avWPXVO46tuDLB0s59I1MSiI7QkU0/iO0vf5oFXf4/D2vauT0uGcteUK/i09KBe9z/NacMC3A47g4syyPI4KC/M4MzDyhhSrOllqRaIxAjF4qR9RRVFr8tO3RejfyIiX6dbQcrv93f7gl+3+6+IiEgqbb/uqT0ax7QsvE47zcEI7dE4TYEIVQ2BLuXMk61s/mHZSGJ2B45YhM2Z+fxq0sW8NOxYMHo/7csOpLns9Mn2cv64/hxclq2pe7tYusuBx2EnGImR6dlx/Xd7JI7bYSfdpd81i8jX69bfEtnZ2TsMf3+VeLx70yRERER6Y/uCAV6njaZAhPrWEJub24nELSwr+dCEZVEQaKIhIzfRtMlXyP876hwcZpy/HPEdQk5PSvpvA8oLMzjuoEKmjyllSJF+Ebk7lGZ7KS/IYOnmFjLcji6fbyzLoqYlxKhSH6XZqdn3S0T2X90KUrNnb9udfd26ddxyyy1cfPHFjB8/HoB58+bxxBNPcN999+2aXoqIiGxn+4IBeelOPtvQQmsoSigaJxKzkpq612lww3pun/1XhtWvZdKVf+myge6fxp+Vsr67bJCf6aYsN40fTx3K2P65Gn3ajWw2g2kji9jc0s6a+o61Ul6XnfZInJqWELnpLqaOKNJ/ExH5RoZlWUn9wm7KlClcfvnlnHvuuV3aZ8yYwV/+8hfmzJmTyv7tFn6/H5/PR0tLi6YmiojsAzY0Bvndm6vxeZwsWLuVTc3tWJaJP5x8hMoJtvDDD2Zw/qevJdZB/XH82fx24gUp668dcDttpLkdTKzIIxi1GN3Xx1XHlusD+x6y/bTQcKxjOl9FYYbKyotIt7NB0hOA582bx8MPP7xD+9ixY7n88suTvZyIiEjSApEYDW1hFm1oYt3WYJc1UN3ljEe54JNXuf6DGfjCgUT7xqwClhcOTGFvIdPrINPjpDDLTTBqkpfh1qjHHlZRmMmgSRk7FCrRfxMR6a6kg1RZWRmPPPII999/f5f2Rx99lLKyspR1TEREZGdM02L2ynoWrmskGO3BJD7LYnLVR/x09l8pb9yUaA44Pfxp3Hd59PDTCTvdKeuv0wYuhw3DgJw0F6P7ajPdvYXNZqjEuYj0WNJB6ne/+x3Tp0/ntdde48gjjwTgww8/ZM2aNbzwwgsp76CIiEinyvpWnp6/nhkLqgn3YBiqb3Mt9878Pyau+7RL+3Mjj+eBiRdQn5mXqq4m9Mn2MnVEEYcPzGNYcZZGPURE9hNJB6mTTz6Z1atX89BDD7Fy5UoATjvtNK666iqNSImISMp17hO1osbPy4treG9NfY9CFEDI6ebQzSsTrz/sO5y7plzJ0uKKVHU3wWWDPjlp3PXtERxdUaDwJCKyn0m62MT+SMUmRET2vK/bWLeyvpVlm/3UtYZoae/dRqlXzX+e8z97jXsnXcJrQyekZD8o6NjoF8BmgwyXgwH56fzPlMFMGVaUkuuLiMju0d1s0KMg9d577/HnP/+Zzz//nOeee47S0lKeeuopBg4cyNFHH92rju8JClIiInvW9hXUQrE4Hocdn9fB+sYgkZgJWCxc30R7tJv/ZFkWU9fM5+r5z3PRWXfi92QkDrliUQwswg5Xr/pckuUiL8NDTXMQl8OOaVm4HDb6+Lwc0i9He0OJiOyjdlnVvhdeeIELLriA888/n08++YRwOAxAS0sL9957L6+++mrPey0iIgec7TfWLfF5SHN52djYxouf1tMeiWFgEUpir/dh9Z9zx6xHOap6MQDXf/AP7p5yReJ4xOHsVX+9Thsuu40jB+URippMqMjnW6P7EIjGyPA4yHQ7tQ5KROQAkHSQuueee3j44Ye58MIL+ec//5lonzBhAvfcc09KOyciIvu37TfWHVyYgWEYrN3SxtyqRvzt0aQ21s0PNHHDe3/nnEVvYGPbyNXgLdUYloll2HrdX5fdwOOw0SfbSyhqkZfh5rtj+6oCn4jIASjpILVq1SomTpy4Q7vP56O5uTkVfRIRkQPEpuZ2qhraKM5y0xqKUd8aYl7VVpqD3Q9RrliUSxb+h2vnPkNmpD3Rvj67mHuPu5SZg8f3eh2UHfC4bHgcdtLcDkqyvYzu61MZcxGRA1jSQaq4uJjKykoGDBjQpf39999n0KBBqeqXiIjspzqLSrS0R3hvTQMfrdtKNGYSjZu0hmNEujuNz7KYtnoet815jP7NtYlmvyuNPx51Dk+MOa3H0/gcBpiADbAZkOl1cnBfH4OLshjTP4dhJSpjLiJyoEs6SF1xxRVcf/31PPbYYxiGwebNm5k3bx4/+clPuOOOO3ZFH0VEZD/RWVTi/coGlm5qoTWcxOKnL8mMBPnV638kJ9QKQNyw8c+Dp/Lg0d9ja3p2j6+bm+Yg3e3AYTPISXOTl+li+pi+jCjxKTyJiEhC0kHqlltuwTRNpkyZQjAYZOLEibjdbn7yk59w3XXX7Yo+iojIfqCzqMTKWj/LNvkJxZJZAbWjVnc6vzv6PO5668+83/9g7pl8OSsLB/bqmh4HuB120lwOynLTOKxfjqbviYjITvV4H6lIJEJlZSVtbW0MHz6cjIyMb37TXkrlz0VEdi3TtHhoThWLNzbz8bpGtgajSb3fHYtwyccv8fyoKWxJz0m0O+IxJqxfxDsDD+vVOiibAYPy05gwuICTRhaT5XGS6VH1PRGRA1F3s0HSJYwuvfRSWltbcblcDB8+nCOOOIKMjAwCgQCXXnpprzotIiL7PtO02NAYZGWtnw2NwcSaqKqGNoKhaHIhyrI4ZcV7zHrkKm5552/c8N7fuxyO2R28M2hMr0KU0wZZHgcjSrO5YFx/xg3KZ3gfH2W5aQpRIiLylZIekbLb7dTU1FBYWNilfcuWLRQXFxOL9W7H+T1BI1IiIqnx5Y113XYbBZluinwe/vPpRqoa2ghEuvfPzqiaNfxs1iMcvml5oi1iczDh6sdoyMhNSX/dDsAyOLgsm3tOH8WQYk3hExE50KV8Q16/349lWViWRWtrKx6PJ3EsHo/z6quv7hCuRETkwBCLmby0eDP/+mQj/lCULI+DUNRkS1uYlvYYwXCMcLx7AaqodQs3vfsk05e+3aX93QGHcs/ky3odomx0DGB5nHayvQ4sDC47ZqBClIiIJKXbQSo7OxvDMDAMgyFDhuxw3DAM7rzzzpR2TkRE9m6mafHcwg38c0E1q+pbCUZ6XkDCEw1xxYcvcvWC50mLhhPtVbml3DP5cmYPGtvr/aA6322zGeSkOSnyechJczG8xNer64qIyIGn20Fq9uzZWJbF5MmTeeGFF8jN3fYbQZfLRf/+/enTp88u6aSIiOx9Kutb+b/Zlby5vI5Q1CRm9qh2UQfL4h//+CmH1qxKNDV7MvjDhHN56tBTiNmTLjK7A6cBHpedTI+DIUWZDMhLp9YfZnTfjrLmIiIiyej2v0zHHnssAGvXrqVfv34YvfytoIiI7Hs6C0esqPXz3882M7dqC7G4CT0rALuNYTDjkBM5tGYVMcPGU4edwh8mnEuzt/frVj1Og4OKszAwKMl2MyA3g1AsTk1LiLwMF1NHFKmohIiIJC3pX/G9/fbbZGRk8N3vfrdL+3PPPUcwGOSiiy5KWedERGTv0VlIorK+lWU1LdS3RvAHoxgGdHP5U0KxfwumYVCfmZdoe37UFIbVr+XpQ06iKr+s1/01AI/Txjljyzj3yP68ubyjCMb6xgBuh51RpT7tESUiIj2WdJC67777+POf/7xDe2FhIVdeeaWClIjIfqhzM93GQATTNKn3R2hpj2IBJBGivJEQ3//wBb6/4F+8MXgc13/rxsQxy7Bx1/FXpqS/Ljt4HHYO7Z/D+eP7U1GYSUVhBpua2wlEYqS7HNojSkREeiXpIFVdXc3AgTvuHN+/f3+qq6tT0ikREdlzOqfvdQaOkiwPry+tZUNjgGjcZMlGP22ReFLXNCyTby9/h5vn/I2Stq0AfHvFOzxx2Kl80ndYyvrutHUUPyrO8jBlWCHnj+ufGHGy2QzKctNSdi8RETmwJR2kCgsLWbx4MQMGDOjSvmjRIvLy8nb+JhER2Sd8eR8oj8OO3YB31zTQFIjQk6J8h21awc9mPcIhNasTbVGbnScPO5XKFEzhg44AdWg/Hz6vm0AkxvVTBnP4gDyNOImIyC6TdJA699xz+Z//+R8yMzOZOHEiAO+88w7XX38955xzTso7KCIiu8f20/dKfB7SXF42Nwd5bVk9beHkN1vv46/n5jlP8O0V73Rpf6v8cO497jI+z+vb6z47bJDmcnDKyGIKsjysqW/j6IoChSgREdnlkg5Sd999N+vWrWPKlCk4HB1vN02TCy+8kHvvvTflHRQRkV3PNC1eX1LLxqYgpdleLAsMLKrq2wj2IERduPC/3DbncTyxSKJtVX4/7pl8Oe8NPCwlfXbYINvr4shBuXjdDtbUt5Gbrip8IiKyeyQdpFwuF8888wx33303ixYtwuv1MmrUKPr3778r+iciIrvBB1VbeHVpLaFojLUNbcRNi5hpsaU1Qk+22N2SnpMIUY3eLB485nv84+BpxG32XvfVBuSkOxmYn47P6wSgORhVFT4REdmterzD4ZAhQxgyZEgq+yIiIntAZX0rT89fx8amIKZl0R6JJ13O3BmPErU7E69fHTqBD/qPZllhOf971Nn4PRkp6avdgLwMF8cOKeSyYwaQ7nKqCp+IiOwRhmV98y6KN9xwA3fffTfp6enccMMNX3vugw8+mLLO7S5+vx+fz0dLSwtZWb3f/FFEZF9hmhY/efYz3lxRT2sPpvD1banjljl/wx2LcMX0O7ocMywTy7ClpJ8G4HXZOkqa98vG5bCTm+7ikgkDNAIlIiIp1d1s0K0RqU8//ZRoNJr481cxDP0mUERkb7d9efO3V9Tx2rIaQtHkhqDSw0GuXvA8V3z4Iu54x78PR637jLkDDkmc05sQ5bJ3/JtimRZel52+OWmYX/S9X246mZ6ONVFvLKtjUH6GRqJERGS361aQmj179k7/LCIi+5bty5vXtQT5cF0T0SQWQdnMONOXzuLGd5+iMNCUaN+S5iMzHExJH71OG0WZbtI9DgLhGNlpLlx2G42BCIVZHjI9DgzDoMTnobK+jU3N7dofSkREdrser5ESEZF9S2d5861tYVqCYT5e10wyA1FHVi/hjrcfZWRdVaItbHfw+Nhv83/jz6LVnd6r/nXsBZWDx2nHMCDb62Tp5hZMCxoDEbwuB+UFGYnZD16XnTp/iEAk+SmJIiIivdWtIHXGGWd0+4L/+te/etwZERHZNUzTYubSOqq3BqluDLC+sb3b7+3bXMttsx/j5NVzu7S/NuQo7pt0CdU5JSnp46Shhdx80kEAzFxax+JNzYSiJhCjKMtDeUEGuemuxPntkThuh510l34nKCIiu1+3JrD7fL7EV1ZWFrNmzeLjjz9OHF+4cCGzZs3C5/MldfN3332X0047jT59+mAYBv/+97+7HL/44osxDKPL14knntjlnMbGRs4//3yysrLIzs7msssuo62tLal+iIjsr0zTonprgOc/2cDLizfzaXVTUiEKoGLrhi4halnhIM45916u/s5tKQlRdgOOKs/lofPHUFGYSUVhJldPKuenJw/jhGHF9M3xMqZfdpcQZVkWNS0hKgozKM329roPIiIiyerWr/Eef/zxxJ9vvvlmzjrrLB5++GHs9o79QOLxOD/4wQ+SrngXCAQ4+OCDufTSS79y1OvEE0/scn+3293l+Pnnn09NTQ1vvvkm0WiUSy65hCuvvJIZM2Yk1RcRkf1NZX0rMxZU886qBjY2BQknW9P8C3MGjeXdAYcyrGEtDxxzIc+PmoLZy/2gHAbY7QZep4ODy3zccepwHI5tv9uz2Qz65aXzvfH9ePyDdVQ2BCjxefC67LRH4tS0hLT5roiI7FHdKn++vYKCAt5//32GDh3apX3VqlUcddRRbN26tWcdMQxefPFFTj/99ETbxRdfTHNz8w4jVZ1WrFjB8OHD+eijjxg7diwAr7/+OieffDIbN26kT58+O31fOBwmHA4nXvv9fsrKylT+XET2G6trW/nV6ytYvKGF5mCEWDf/ph+/fhEnrp7Lz4+/CrarxFrs30KbO402d++LOhRmuijNSSPT7eDwAbmcNKr4a0uYb18gIxzrmM5XUZihzXdFRGSXSGn58+3FYjFWrly5Q5BauXIlpplE6adumjNnDoWFheTk5DB58mTuuece8vLyAJg3bx7Z2dmJEAVw/PHHY7PZWLBgAd/5znd2es377ruPO++8M+V9FRHZG6yu83PXy8tZtKGZtnCc7mSoAY2buG3O40xdMx+A9wYcxluDj0wcr83K73W/HDbI9rr40fFDOLR/Trc30a0ozGTQpIxEyXZtvisiInuDpIPUJZdcwmWXXUZVVRVHHHEEAAsWLOBXv/oVl1xySUo7d+KJJ3LGGWcwcOBAqqqquO222zjppJOYN28edrud2tpaCgsLu7zH4XCQm5tLbW3tV1731ltv7bKxcOeIlIjI3mT7/Z66Ex5M02L2qjrue2UlG5qDRGPWN4aorFAb1859hosX/heXua363enL53QJUr1hAFkeB6U5Xvpkezl6cEHS5cptNkMlzkVEZK+SdJD6zW9+Q3FxMb/97W+pqakBoKSkhBtvvJEf//jHKe3cOeeck/jzqFGjGD16NOXl5cyZM4cpU6b0+Lput3uHtVYiInuT7aezhWJxPA475QUZTBu58+lslfWt3P7iEj5c20R35gbYzTjnLJrJDe/9nbx2f6K9LiOX+ydexL9GHtfrZ7AZkOa0UZabxuEDcqlvjTC6r0/FIUREZL+QdJCy2WzcdNNN3HTTTfj9Hf/47q51RYMGDSI/P5/KykqmTJlCcXEx9fX1Xc6JxWI0NjZSXFy8W/okIpJqnfs9NQYilPg8pLm8BCMxlm5uYXNLO5dMGEBFYWZixGpFjZ/7X19BZUP3NsQ9eu2n3PH2IwzdUp1oCzlc/OXw7/DwuDMJunoXdDrHzJx2gyKfl2ElWTS0RcjLUHEIERHZf/Ro841YLMacOXOoqqrivPPOA2Dz5s1kZWWRkZGR0g5ub+PGjWzdupWSko5yu+PHj6e5uZmFCxcyZswYAN5++21M0+TII1MzJUVEZHfq3O+pMRBhcOG2zWczPU4y3A7W1Lcxc2ktm/u28/bKemqaQ3y8vpGtgWi3rn9Q/Vr+/uwdXdpeGjaRXx97MZt8hV/xru6zAXYbpLkcFGS66ZPtBQxGlfpUHEJERPYrSQep9evXc+KJJ1JdXU04HOaEE04gMzOTX//614TDYR5++OFuX6utrY3KysrE67Vr1/LZZ5+Rm5tLbm4ud955J9OnT6e4uJiqqipuuukmKioqmDZtGgDDhg3jxBNP5IorruDhhx8mGo1y7bXXcs4553xlxT4Rkb3ZpuZ2qhraKPF5EiGqk2EYeJ02/vXJJv7x0QZicZNgJIY/FO/29VcWDuS1IUdx0uq5fFYyhLsmX8EnfYcl3U+DjsBkWeC02yjKcjG4MIvDB+ZQUZjBoIIM7IZBMBpXcQgREdkvJR2krr/+esaOHcuiRYsS1fMAvvOd73DFFVckda2PP/6Y447bNg+/swDERRddxEMPPcTixYt54oknaG5upk+fPkydOpW77767y/qmp59+mmuvvZYpU6Zgs9mYPn06/7+9+w6PqsrfAP7eOz2ZzEzqpBISQqgBaYaIIiVSdFkVbIgKiLi6sj8b7uquih11d11XV9e1AbprV6yriKFJkd5rEhIS0vuUzGTKvb8/3AxESmYCSSbJ+3mePGvOLXOGw4S8e879npdeeinQt0VEFBTsLg+cHi9CTrO8rtbuwsFSC0oaHFArBHi9EuzuM5eTUEheTD28AV/3v6RFKfPF4+ZiRXoWvhh4KWTBr33ZW1AKgFIhQhSBMI0KCeFaDIgz+pYcEhER9QQBB6kff/wRGzduhFqtbtHeu3dvlJSUBHSvcePG4WzbWK1YsaLVe0RERHDzXSLqNkLVSmgUIiotTqiUItQKEWHan39UbymoRm6FHRIAZysr+cYe3Y6HV72F9JoiiLKMLwde6jtWFB6HovC4gPum14hICtchOVKPOrsbgigjNkyL9FgDl+0REVGPE3CQkiQJXu+py0iOHz+OsDD+I0pEdC4cbg+qbS7kV9mgU4tQiiJC1UqU1TtQZm1q9fo+NcX406q3MOHoNl/b79cuxX/7jYFH0abHYgEABo0CE/pHQxQVuDu7L0RB4J5ORETUowX8r+qkSZPw4osv4vXXXwfw85p9m82GRYsW4fLLLz/vHSQi6inyKq1YtvEYZFmGViWizu5Co8sLp6f1LXWNDivu2fAebt7xDZTyiQLoO+P64YmJ888pROmUAsb3j0GTV0ZGrB5J4SEMTkRE1OO1aR+pKVOmYODAgXA6nbjxxhuRm5uLqKgovP/+++3RRyKibqe5dLnV6YatyQOtSsT7m4txqNwCh8uLoupGeFq/DZReD27a+V/cs+E9mJw2X3tpWBSeHTcHXw0Y26bnoJqFqkUYdSrU2F1Ijgxl+XIiIqL/CThIJSUlYffu3fjwww+xe/du2Gw2zJs3D7NmzYJOx00WiYha07zZ7s7iOhTVNMLidMPp9sLW5IHHn910/0frduKrZfeib02xr61RpcFrmdfg9QuvhlOlPad+KgRApxKhEEUMijfi2pGJfA6KiIjofwIKUm63G/3798fXX3+NWbNmYdasWe3VLyKibql5s93CahuKahvR2OSF3eWFM5AE9T9OlRZ74vr6gtSngyfg+bG3oCIs6pz7qVYIiAhVIzFch+HJ4XhgUj8olW2f2SIiIupuAgpSKpUKTqezvfpCRNTtNC/hs7s80KkU+HZvOXYW1+FolR1Od2DhyeSwwKIJhSQqfG3Pj70F0bY6/GXszdgTl37O/RUAhKgEqJQKhGlVSDeH4bqRSQxRREREvyDIZ6s/fhrPPPMMjhw5gjfffBNKZdsfXg4mFosFRqMRDQ0NMBgMnd0dIuommpfw5VfZ4PR4UW93YXtRLZr8efjpJCqvG7fs+AZ3b3gfz4ybiw8umHLe+yoAUIqAQiFAwM+zUVMGxWJmZi8u5yMioh7F32wQcBLaunUrcnJy8P333yMjIwOhoaEtjn/22WeB95aIqJtpXsJXa3chzqhFeYMXG4/WBnYTWcbE/C3406q3kFpXCgC4/8d/4+sBY2HThJzX/mpVIsI0ShhD1BgUb8CMEYkY0yeKhSWIiIjOIOAgZTKZMGPGjPboCxFRt+DxSPho63EUVtsRa9DicHkDNuTXBXSPflWFeCTnDVx8bLevTYKA1X1GQikFOKV1BjqViHRzGMI0Clx5QQKiDVqkRoUikeXNiYiIWhVwkFqyZEl79IOIqFvIq7Tiw63F+HxnCRxuL7a4vQjkUahIez3uW/9v3LD7eyhO2g9qc+IgPDFxPvbHpp2XfmqUAib0i4EEICPBiBkjkhieiIiIAuB3kJIkCX/+85/x5ZdfwuVyYeLEiVi0aBFLnhMR/U9epRUv/pCLHYW1qLa5ENADqABu3foF7ln/Hxhcjb62YqMZT4+/Fd+lXwQI5x50RAA6tYDRKVGQAESEqrk3FBERURv4HaSefvppPPbYY8jOzoZOp8Pf//53VFZW4u23327P/hERBbXmqnwNThdeXZWPzQU1aGh0BxyiACClrsQXomxqHf6RdT2WjPw1mpTq89JXpSjAoFUiNVoPY4gaaTF6TBpkZjEJIiKiNvC7al/fvn2xcOFC/OY3vwEA/PDDD7jiiivgcDggil27LC6r9hFRWzRX5dtRVIvDFRaU1jUh8N2gTohobMCqN36Db9MvwguX3IwqfXjA99AoALcXkHCiEp8pRIWMhHBcMSQWI3qFw+mVEKpWIsGk40wUERHRL/ibDfwOUhqNBnl5eUhKSvK1abVa5OXlITEx8dx73IkYpIgoUM1V+Q6WNiC/ygab0wuvn9dG2etw/7p3cSgmBctGTGtxzOC0waLVB9yfmDA17r0sHRmJRhytsqPO7oLTLaFPTCjSY8JYQIKIiMhP5738ucfjgVarbdGmUqngdrvb3ksioi7i5I11tQoRH24pwo5jtcitsMHj5zo+jceFudu+xF2bPkSYy4EGTSi+GHgp6nUnfki3JUSZw9R46uoMXDYwFgAwON4U8D2IiIgoMH4HKVmWMWfOHGg0Gl+b0+nEHXfc0WIvKe4jRUTdiSTJ2JBfjZyDFShrcKLR5UF5fRNK6xth97ccnyxjypGN+OPqt9GrocLXLMgyBlYcxcbeF7S5fwkmLQbHG5BbYcPE/jJnnYiIiDqI30Fq9uzZp7TddNNN57UzRETBJK/Sivd+KsLqw5VwuL1QKQQ0uSW4vJLfIWpQeR4eXfUmMov3+dq8gogPhk7CCxffhJpQU5v6phSAhPAQjE2PhkohIK/ShpJ6B5Iizu9GvURERHR6fgcp7h9FRD1JXqUVb68vwLZjdfBKEnQqEeUNTjg9sl8V+aJttVi47l1cu/cHiCddsT55KJ6acBsOxaS0uW8qERgcb8TgRBMiQtXwSBIqLE7YXedno14iIiJqXcAb8hIRdXeSJGPFvgocr3Og1taEukY3vAHWM79125e4fu9K3/cF4XF4evxt+CHtwjbvByUA0CpF9I4OxcV9o3wVUx0uLzRKBULV/JFORETUUfivLhHRLxTV2vHDwXIcqbDA7mrLjlDAP0dfg+v2fA+V5MXfL7oB74z4FdwKVZv7JAJQKwUkhOswMjnCF6JkWUZZgxMZCUYkmLhBOhERUUdhkCIi+h9JkvHx9mK88P1hVFhdfl+XUZaL1Nrj+GLQeF+bRavHnVf/EXmRSagNMbapPyoRUIiAXqNCYngIJFmGUaeGSiHAI0lwuLwoa3AiIlSNSYPMLDRBRETUgRikiKhHkyQZxXWN2JBXjS93lWBbQR38fdLIbK3G79e9gxn7VsGu0mJTryGoDIv0Hd+SNLhNfRIBDEowIDUqFGajFiN7R2BArAEOtwcr91civ8qGCosTGqUCGQlGTBpkRlpMWJtei4iIiNqGQYqIeoyT94IKUSlQUGPHJ9uKsTGvBrWNbr+KSACA1u3E/C3LcefmTxDibgIAhLqduHX7l3h23Nxz6qMAIDFch5kX9sIlfaORYNK1mGlKiw7zvYdQtfKU40RERNQxGKSIqEfIq7Rixb4K5FfZUGVrwrEaO0rrHfD4uRUUAECW8euD6/CHNUuRYK3yNddr9fj7mJl4d9gV59RHAT8/ByWKAvaVNODClIhTQpIoCixxTkREFAQYpIio28urtGLJhkLU2l3weCXsO16POkdgpcIvKD2MR3Nex/DSw742jyDi3eFX4O9jZqJeZ2hz/0QAoggoRQFqpQKD4g2oa3Tj+/0VSI3Sc8aJiIgoCDFIEVG35vFI+HBrMQ6XW6DXKLCtsA42VyDTUMCUwxvw2ueLW7StTh2Bp8bfhvyopDb1qzkaCQIgCoBCFKHXKBGmUyImTAtBADfZJSIiCmIMUkTUbeVVWvHamnys2F8Op9sLd2D5yWdN6giUhkUh3lqN3MgkPDXhNqxNHdHmfgkAlApAkoAQtQIhGiVMWhU8kgSzUYcwrRJeWeYmu0REREGMQYqIuqUj5Vb8afke7DpeD7fX/+sEWcKAykIcMKf62pwqLZ6YOB/R9jq8P3QKPIq2/egUAYTplNAoFdAoRbi8EsJDVNAoFbA3eRCiUaFPtB6CIMDR5OEmu0REREGM/0ITUbdwckW+CosTiz7fh8JaR0D3GF5yEI/mvIEBlQWYeNs/cdwU6zv2Xb8x59S/eKMWc8b0xpjUKNQ6XNhVVI9v95Wh1u6CSQfEGLToE61HRKiam+wSERF1AQxSRNTl5VVa8d3ecuwtaUC1rQkHyy1oDOA5qHhLJf6wZhmuPLjW1/bgmqVYcNWD59w3AUCkXo0nrhyM7IFmX/uYPlEY1suE97YUwd7kQWpUKEI0Slidbm6yS0RE1AUwSBFRl5ZXacXfVh7B/lILPF4JNbYmODz+7QgV4nLgjp8+we1bl0PrcfnaD0f1wodDJ51Tv0T8XMo83hSChy7v3yJEAT+XMb+4bzRijVpfWfZKaxM32SUiIuoiGKSIqMuSJBmvrsrDj7nVcHsluDwSvH5kKEGWMH3favx+3TKYbbW+9hqdAS9cchM+GDoZXlERcH80SsCkU8GgUyEqVIOMRBOuGZmIdPOZS6OnxYQhdZyem+wSERF1MQxSRNQleTwS3t5wFF/vKYNL8m8GCvh5Gd9ry5/BkPI8X5tLVGLpiGn4x0XXw6LVB9wXUQDiDFo8PX0wUqL0cLi9AQUibrJLRETU9TBIEVGXIkkyPthWhDfXHcXR6saAr68OCYfBafd9/33f0Xhm3FwURiS0qT+CAIRplbhjXB+M62du/QIiIiLqFhikiCgoSZKM43WNyKuyocbmQnioCnV2F97ddAx7Six+30fp9bQoV+5SqrB4/Fzcs/49PDFxPjYlD21T/wQAoWoF+sboEapVwur0QJJkLskjIiLqIRikiCjo5FVa8d7mIqw9XIkqaxOavBK8kgxPABvqipIX1+zNwT0b3sPN1z2J/Kgk37EVfbOwMi0TUhuegxIAqBSAXqvC2L7R6BURAluTB3mVNpTUO7hEj4iIqIdgkCKioHKkwoJnvz2E3cX1cLi9gCxDkhBQiMos2otHc97AoMqjAIA/rX4Lt1772IkTBAGSEHiIEgEoFQLCQ9TITI1AcmQoAECnVqDC4oTd5Qn4nkRERNQ1MUgRUdA4Um7FE18fwK6iOjR5JEgyIMuAvxmqV10ZHlqzBFOPbGzR7lSqofG40KRUt6lfKgGQAWhUInpFhmJELxMi9VrfcYfLC41SgVA1f6QSERH1FPxXn4iCQl6lFf9YnYtDZVZI8s9V+CT55wDTGn1TIxZs+hBzt30BjffErND+mFQ8MXE+NvfKaHO/IkOUGJZkQq3DA6UoIDMlAqIo+o7LsoyyBicyEoxIMOna/DpERETUtTBIEVGnkiQZxXWN+MeqPGw/Vgd7k9vvDXVFyYvr9qzE/T/+G9GN9b72qlATnh97Cz4dPLFNz0GJAFRKEUMSDJh/aR8MiDXA4fJi2aZC5FXZEWfUQqdWwOHyoqzBiYhQNSYNMrPQBBERUQ/CIEVEHU6SZJTUO3CgrAGrDlRga2EdiuoaIUuAN4D7CABu3falL0Q1KVR4c9RVeHX0tbBr2lb0IUqvgkYhwqBT4e7sdFzcN9p3bO6Y3lixrwL5VTZUWJzQKBXISDBi0iAz0mLC2vR6RERE1DUxSBFRh8qrtGLFvgr8mFuJnUV1aAokOf2CV1TgyYm34d2PHsXX/S/Bs+Pm4LixbXs5GbVK9InRo39cGJSCiGpbE6LCNC3OSYsJQ+o4PUrqHbC7PAFtuktERETdC4MUEXWYvEorlmwoxMHSBuwpaQioEp/BacOCjR/ii4GXYn9smq/9x5ThmHzrP3A4uneb+qQQgHCdCnHhOgyKNyAiVAOr0w2t6vTFI0RRYIlzIiIiYpAioo4hSTJW7KvAwbIG7A0gRCkkL27YvQL3/fhvRDosGFqei+tnLgaEE7NAbQ1RWqWARJMWMcYQ9IkORUSohsUjiIiIyC8MUkTUbpqfhbK7PLA43FhzpAK7ihr8Lmd+ccFOPLzqTfSvPuZrG1p2BGk1xciL6tWmPmmUAkb2MiGzTxQOlVthb/IgNSoUIRolrE43i0cQERGRXxikiKhdHCm34pPtxcirtKGm0YWCKhssTv8eiEqpLcEfV7+Fy/K2tGj/csBYPHfpHJQYY9rUp4HxYbjt4lT8ekg8lErR97xWfpUNldYmFo8gIiIivzFIEVGbnDzbdHLRBUmS8dH2Yry9vgBl9Q40urzw+lfNHAanDf+34X3M3vE1VNKJ0LUrri+emHA7diQOaHN/+0SH4sXrL0C62eBrY/EIIiIiaisGKSIK2MkzOU6PF1qlAn2i9UiP1WPF3nJ8u68MdncAlST+5+Uvn8elBTt835fpI/HcuDn4YuClkAXxLFeeXT+zHi/PHI5086mzTCweQURERG3R9t9MzoN169Zh2rRpiI+PhyAI+Pzzz1scl2UZjz76KOLi4qDT6ZCdnY3c3NwW59TW1mLWrFkwGAwwmUyYN28ebDZbB74Lop4lr9KKt9cXYEthDbySBI1ChNXpwvKdxbj/w134YndJm0IUALx00Q0AAIdSgxfHzMSE+f/C54PGtylEKQUgRCUiTKPA7It6Iz2WS/WIiIjo/OnUGSm73Y6hQ4fi1ltvxfTp0085/vzzz+Oll17CsmXLkJKSgkceeQSTJ0/GgQMHoNVqAQCzZs1CWVkZVq5cCbfbjblz5+L222/He++919Fvh6jbkyQZ//npGDbmV8Ph8sLq9MDtlSDJ8Hv5XrM+1cVQS24cjEn1tW1PHIhHLrsDP6RloswQfZarz0ylAFQKEXEGLZxuCQadCmPSotp0LyIiIqIzEWRZDvDXn/YhCAKWL1+Oq666CsDPs1Hx8fG4//77sXDhQgBAQ0MDzGYzli5dihtuuAEHDx7EwIEDsXXrVowcORIA8N133+Hyyy/H8ePHER8f79drWywWGI1GNDQ0wGAwtH4BUQ/1/pZjePrrg3C4/X/u6ZdMDgvu3vA+bt7xDfab++CqW/56Tsv2TqZRCAjVKCHJgFH38/9OGmjGn64YyOeeiIiIyC/+ZoNOXdp3NgUFBSgvL0d2dravzWg0IjMzE5s2bQIAbNq0CSaTyReiACA7OxuiKGLz5s1nvHdTUxMsFkuLLyI6u5UHyvHMNwdhC6B4xMmUXg/mbPsSa16/HXO3fwWlLGFoeS6mHVx3XvoXohKgVSnQ5PFCFAC1UoGhSSbMzOzFEEVERETnXdAWmygvLwcAmM3mFu1ms9l3rLy8HDExLcsgK5VKRERE+M45ncWLF+Pxxx8/zz0m6r6OlFvx9Nf7YW3yr3x5C7KM8Ue34eFVb6FP7XFfc6NKg39mXoPv+44+p74ZtUoMTTLB5nTjeL0DOuHnwhcX9YnE5MGxLGNORERE7SJog1R7euihh3Dffff5vrdYLEhKSurEHhEFn+by5lanGy/nHMGxWmfA9+hbdQyPrHoTYwt3tmj/dPAEPD/2FlSEBfbskgAgVK2ARilCp1bCFKKC2aCBVqVAZKgao1IiMSI5HAPiDCxjTkRERO0qaINUbGwsAKCiogJxcXG+9oqKClxwwQW+cyorK1tc5/F4UFtb67v+dDQaDTQazfnvNFE3cXJ586JaO3YW1SPQ1Xy3bP8Ki3LegEI+UcFva8JAPDnxNuyJSw/oXgoBGJpowO8mpkMQfg5HqVGhiDfqUGZxcg8oIiIi6nBBG6RSUlIQGxuLnJwcX3CyWCzYvHkz7rzzTgBAVlYW6uvrsX37dowYMQIAsGrVKkiShMzMzM7qOlGXlldpxZINhai1u+Bye7GrqL5Nz0RtTxwI4X+1bI4bYrB43Fx80/9iQAgs6OiUIrLSIvHg1P4tNtNtxj2giIiIqDN0apCy2WzIy8vzfV9QUIBdu3YhIiICvXr1wj333IOnnnoKffv29ZU/j4+P91X2GzBgAKZMmYL58+fjtddeg9vtxoIFC3DDDTf4XbGPiE7weCR8tLUYx2rscHslbC+og8efC2UZJqcV9boTQWe/uQ+WjfgVqkLD8dbIK9GkCnwWWCEAvxoSi9+MS+OzTkRERBRUOrX8+Zo1azB+/PhT2mfPno2lS5dClmUsWrQIr7/+Ourr63HxxRfj1VdfRXr6iWVBtbW1WLBgAb766iuIoogZM2bgpZdegl6v97sfLH9O9PNM1Idbi/H1nlJ4vDKqbS6/lvP1qyrEIzlvINpeh8vnvgyvqDgv/dGpBFw+JA7PXT0USmXQFhglIiKibsbfbBA0+0h1JgYp6umOVFjw7LeHcLDUgrrGJjj9mIaKtNfjvvX/xg27v/c9B/XwpN/i38MuP6e+iAIQolJgRO9wPPKrgZyJIiIiog7lbzYI2mekiOj8aq7CZ3d5oFMpIMsyCqrt2Hu8AR9sKUKltQky0OrzUGqPG7O3f4XfbfwABlejr73IaEZpgFX4mokAFCKgUoiI1mswYUAMZo1OZogiIiKioMUgRdQDnFyFr9rWhJI6B2obXbA3eeDyt5KELGNy7iY8tHoJeteX+Zqtah3+cdH1WDri12hSqgPqlwLAJelRyB5ohkapQKRejbRoPRLDQ1h9j4iIiIIagxRRN5dXacXb6wtwvK4Rbq+Mwmo7qu1NcAewt26fmmI89f2ryCra62uTIOCDoZPwwiU3oTo0POB+KQD8elg87hrPQhJERETU9TBIEXVjkiTjP5uOYe2RKticbjQ4A0hPJ5OBUcX7fd9u6pWBJyfMxwFzaptupwSwIDsN/zchnTNPRERE1CUxSBF1Yx9tL8anO47D2uQNeEPdk+VHJeHd4VdgfP42PDP+Vnzfd3TA+0EBgACgX0wI+scZMWN4EkMUERERdVmsKUzUDUmSjHVHKvHP1XmwBBKiZBlTD63Hux88DLXH3eLQXy65GZPmvYrv07MCDlEhKhHRejWSI0NgNoUgPdaABJMuoHsQERERBRPOSBF1M3mVVny7twyf7ijBsVqH39cNKs/DozlvIPP4z0v45mz/Eq9nzvAdt2tC2tSf8BAlEkw6WBweqJUiEkw6TBpk5mwUERERdWkMUkTdQHNp84NlFry/5RiOlNtQ3uD069poWy0eWPcOrtmbA/GkuathpYfPqU9aJSBJgFqpQLXNBZ1KiUvSojAzsxeLSxAREVGXxyBF1MU1lzbPq7Ric0EtKqxOeKXWr9O4m3Db1s/x258+Rqj7ROg6Gh6PpyfMQ06fC9vUHxGAXquEUhSgFAX0M4chNToUEweYMaZPFGeiiIiIqFtgkCLqAk7eTDdU/fNSOVEUcKTcildW56HG3gR7kwel/sxCyTJ+dehHPLhmCRItVb5miyYUfx8zE+8MvwJuhSrgPqpEQKMUkRAegsze4SisdaBPtB5zx/TmvlBERETU7TBIEQW5kzfTdbi9kGQZZoMWsQYNvt9fjuI6B5rcHthc/pWUiLXW4K/fvACN1wMA8Agi/jNsKl4ccyPqQoxt6qNGARhD1IjSa9A/NgxVdjeSIkIwa3Qv9IoMbdM9iYiIiIIZgxRREMurtGLJhkLU2l3QqUTU2JwoqGlEvd0Fj4Q2lTQvN0ThrVFX4bc/fYJ1vYfhyQm3ITc6uU39U4qATqVATJgGGpUSUXo1AAEZCUZMGmTms1BERETUbTFIEQUpSZKxYl8Fau0uRIaq8GNuDcoaHHB5/Y9PWrcTt+z4Bu8OuwIOtdbX/uro67AlcRDWpI4MuJS5CCBUo0BieAhCNQoMTjBizkW9IQgCHG5vi6WHRERERN0VgxRRkCqpdyC/yoZYgxabjlajpN4Bj+RniJJl/PrgOvxhzVIkWKsQ4nbixYtn+Q7bNCFY02dUwH3SKAVk9o5AjEELW5MHkXoNbhqdjN5R+oDvRURERNSVMUgRBSm7ywOnxwudR0RBld3vEHVB6WE8mvM6hp9UvvzWrV/gjVFXt2kvKAGAUhSgVgoIUStRYW1CpF6DIYkmLt8jIiKiHotBiqiT/bIin1mvwa6Sehwqt6C4thFb6h1o8mM5X5ylCr9fuwxXH1jTon1V6kg8PX5ewCFKFACNQoRCFBCqVeLC3uHQqhSotbsxM7MXRiZHcPkeERER9VgMUkSd6OSKfE6PF3V2F0rrnbC7PLA53XB6Wg9QOpcTv9nyKX6z+TPoPE2+9tzIJDw14TasTR0RcL/0ahFGnQoqpQIRoWoMjAtDpF4LjySh0eWFQadiiCIiIqIejUGKqJPkVVrx9voClNQ7EB6iRqPLg73H6+FwS/C3noQoefH1snvQp/a4r61WZ8DfLr4R710wFV5R4Xd/BAChahGJ4SHISDBCrVJArRARplVC+F9BCofLC41SgVA1f3QQERFRz8bfhog6gSTJeO+nImw7VgcBwIHSBlTb3AGXM5dEBT4bNB4P/Pgu3KICy4b/Ci+NmQmL1v/iD3q1AiNTwhGiVkAlKmA2aFFc14i+Jp0vQAGALMsoa3AiI8GIBJMuwJ4SERERdS8MUkSdYEN+NVYdqoC1yQt7k39L+AAgoaESFm0orJoTm9y+OeoqJDVU4F+ZM1AQkRBQP8JDVBgQZ0BGvBF5VXb0iw1D9sAYLNt4DLmVNsQZtdCpFXC4vChrcCIiVI1Jg8xc1kdEREQ9ntjZHSDqSSRJRmG1Da+sysXxegdq7C6/QlSIy4H7172LnDfvwIKNH7Y41qTS4MGp/xdwiFIrBESEqhFr0CCvyu4LSelmA+aO6Y3B8UbUN7pRWG1HfaMbGQlGzB3Tm1X6iIiIiMAZKaJ211yV72CZBd/vL8eaQ5WobnT7da0gS5ixbxUeWPcOzLZaAMDcbV/ivQum4Fh4fJv6oxSBELUCAgREhqoBCMhIMLYoZZ4WE4bUcfoW1QS5yS4RERHRCQxSRO2ouSrfzuI67CquR43N5fdzUKOK9+GRVW9iSHmer80lKrF0xDTU6QwB90UEEGfSYmiiEbYmL/rHhuGqYQkI06pOG5JEUUBSROD7ThERERH1BAxSRO0kr9KKJRsKUWNzoaDKhmqby6/rEuvL8eCapfjV4fUt2lf0HY1nxt/appkotUJASlQoBsUb4HBLSIoIwXWjkrhMj4iIiKiNGKSI2oEkyVixrwK1dhfUCgFHqxv9uu63mz7C3Rveh8Z7YunfwejeeGLifGxKHhpwPzQKICkyBDF6LUwhKpxuGR8RERERBY5Biug8an4eKr/Khj0l9QhRKbBif7nfy/mcSo0vRFWFmPCXsTfj44xsSAHsB9UsyaTB09OH4KLUKJRZnHzWiYiIiOg8YpAiOg8kScb6vCp8saMUhTV2NLo9OF7XCGuTdNbrRMnbIiS9O/xyXLt3JdakjsQrWdfBpgn8GSW1QkBiuA6v3jgC/eN/fpaKzzoRERERnV8MUkRt5KvGV27Bp9uOY1N+NexuLyQJrc5AJdWX46HVb6M2xIiHJ9/la3crVPjVnL/D24YZKJUCMOlUiDPqcHd2ui9EEREREdH5xyBF1AZ5lVZ8t7ccm47W4FCZBXUONyQ/1u/pmxqxYNOHmLvtC2i8HngFEe8OvwKHo3v7zgkkRKlEQKkQEapWIC0mDEOTTJgxIgHpZoYoIiIiovbEIEUUoLxKK178IReHyy0ob3DC1uRtdQZKlLy4bs9K3P/jvxHdWO9rrw0xINZa0yJI+SPBqEZKdBhC1Ur0igzBqJQIDIg18PknIiIiog7CIEUUAEmS8d5PRdhdXI/GJjesTd5Wr8k6thuP5ryBAVWFvrYmhQpvXHg1/pl5DewBPAcVqlbgmhGJuPXiFDjcXhaPICIiIuokDFJEfpAkGcV1jdiQX4Wvdh1HdaOn1Vmo3rUl+OOaJZiU+1OL9q/7X4Jnx83BcaM5oD7EGTSY0N+Mm7OSkRwZGuA7ICIiIqLziUGK6Cw8Hgmf7y7Bp9uLcbDMinqHx+9rRxftbRGi9sSm4YmJ87EtcVBAfRAAjOodjnH9Yrj/ExEREVGQYJAiOoOcgxX4y4pDOFxuw9mLmJ/eR0Muw+wdXyPCYcHzY2fjs8HjIQtiQPcwh6lx57g0TBxg5hI+IiIioiDCIEV0GjkHK/Dw53tR1tDk1/kXF+zEyJIDePHiWb42SVTgzqseQqU+Ao1qXUCvb9QIuHZkMq67MIkV+IiIiIiCEIMU0UkkSUZhtQ1Pf7PfrxCVWnMcf1z9FrLztwIAVqeOxO74fr7jhREJAb1+VKgSA+KM+M2lfXBRnyjOQBEREREFKQYp6tGaN9W1uzyotDjx+a4S5ByoQIPz7NX4jA4r7t7wPm7e+Q1U0olzr937Q4sg5S+lAAxOMOKygWZMHhzL56CIiIiIghyDFPVIkiRjQ341fjhQjqNVdpRZHDhW3Qh3Kw9DKb0e3LjrW9y7/j2EO62+9jJ9JJ4bNwdfDLw04L7EGdS4Y1waJvTnc1BEREREXQWDFPU4RyoseH3tUaw+VAlrkwdeSYa3tVrmAC49uh0Pr3oTfWuKfW0OpQavZc7A6xdOh0OtDagfCgBXDY/Hc9OHQqkMrAgFEREREXUuBinqUXIOVuC5bw+ioNre6uzTyS4q3IVlHy9q0fbZoPF4fuxslBuiAu6HSgRuykzGI9MGcQaKiIiIqAtikKIe40i5Fc9/dyjgEAUAG5OHYkd8PwwvPYwd8f3wxMTbsasNz0KpFQI0ShFJESGod7hRUu9AUkRIwPchIiIios7FIEXdliTJOF7XiKPVdsiQ8d/dpcivtMHTyjI+pdeDSwu2Iyct80SjIGBR9h1IqSvFlwPGAkJgs0iiAChFATqVAjEGLS5IMqHB4Ybd5f8Gv0REREQUPBikqFs6Um7FGz8exfZjtWhwuNHk9sLmamUaSpYx/ug2PLzqLfSpPY4bZj6Dn3oN8R3eG9cXe+P6BtQPlQgoFSLUShEGrQpJ4SHoExMKlUKE0y0hVM2PIBEREVFXxN/iqNtoLmX+w8FyLFlfiLIGBzwS4EcdCfStOoZHVr2JsYU7fW1/WvUWps1+MeDZJwCIClFiYLwRXklGrFEHjUqERqlAmPbnj1xupQ0ZCUYkmALbqJeIiIiIggODFHULeZVWrNhXgR9zK7GzqB5N/pThAxDe2IB717+HWbu+hUI+MWO1NWEgnpg4v00hqle4Fq/fPApKpYAlGwpRa3fBGKKCTq2ArcmDsgYnIkLVmDTIzEITRERERF0UgxR1eXmVVizZUIijlVbsOFaH1lbwAYDK68YtO77B3Rveh6HJ7ms/bojB4nFz8U3/iwMKUSKAUI0CA+LC8NTVGUg3GwAAc8f0xop9FcivsqHC4oRGqUBGghGTBpm56S4RERFRF8YgRV2aJMlYsa8C2wtrcbjC5tcyvkh7PT7+z++RWlfqa7OpdXh19LV4a9RVaFKqA+qDWa9Cv1gjLkwJx5SMuBYBKS0mDKnj9Cipd8Du8iBUreSmu0RERETdAIMUdVmSJGNzQTXeWp+P2kb/q9/VhBhRaohGal0pJAj4OCMbfxl7M6r0EX7fI0QlIjkiBKEaBeaN7YPB8cYzBiRRFFjinIiIiKibETu7A2fz2GOPQRCEFl/9+/f3HXc6nbjrrrsQGRkJvV6PGTNmoKKiohN7TB1BkmSsOVyJa17bgFlvbGk1RBmcNkA+aa5KEPDUhNuwIXkIps15EX+4/G6/Q5QIIN6oxeRBsRjdJxK9IvUYHG9EUkQIZ5mIiIiIepCgDlIAMGjQIJSVlfm+1q9f7zt277334quvvsLHH3+MtWvXorS0FNOnT+/E3lJ7y6u04rZlWzB3yVbsKGrA2R6HUnvcuH3zp1j/z1sx7ui2FscOxaRg1g3PYL+5j9+vrVYKyEg0YuIAM5IiQlBuaUJajJ6V94iIiIh6oKBf2qdUKhEbG3tKe0NDA9566y289957mDBhAgBgyZIlGDBgAH766SeMHj26o7tK7exIuRW3vbMVRbWOs58oy5icuwl/XP02kuvLAQAPr3oL63sPg0cR+F95EYBeq8DolEikmfVwuiXkVtpYeY+IiIioBwv6IJWbm4v4+HhotVpkZWVh8eLF6NWrF7Zv3w63243s7Gzfuf3790evXr2wadOmswappqYmNDU1+b63WCzt+h6obZr3hbK7PCiqtWHhB3tgcXnPes2ginw8kvMGRhfvO3EfCNiSNAhajwu2AIJUiEpEvEmHjAQjwkPUqHe4caymkZX3iIiIiCi4g1RmZiaWLl2Kfv36oaysDI8//jguueQS7Nu3D+Xl5VCr1TCZTC2uMZvNKC8vP+t9Fy9ejMcff7wde07nKq/Siu/2lmNvSQN2Fdehwuo66/nRtjrc/+O7uG7PSogn1e7b2GsInppwGw6YUwN6/QXjUjAyJQqpUaFIDP+5UAQr7xERERFRs6AOUlOnTvX995AhQ5CZmYnk5GR89NFH0Ona/lzKQw89hPvuu8/3vcViQVJS0jn1lc4PSZKxPq8KL+fkoqiuEbVWF9xnqWkuyBLu2Pwp7tr0EfSuE0v+Ck1xeHrCPKxMywxoPyilADz8qwGYM+bU4MXKe0RERETULKiD1C+ZTCakp6cjLy8Pl112GVwuF+rr61vMSlVUVJz2maqTaTQaaDSadu4tBUKSZGzIr8bH244j52A57P7sqgtAFkQMLznkC1EWdQheGnMD3hk+DS6lyu/XFwFEhKrxfxPTcMtFKW15C0RERETUg3SpIGWz2ZCfn4+bb74ZI0aMgEqlQk5ODmbMmAEAOHz4MIqKipCVldXJPaVAHKmw4I21R7HmSBVq7C5I/uyqe5Knx9+KSwp34pPBE/HCJTehNsTo97UhKhED48PQ1xyG2Vkp6B9nCLD3RERERNQTBXWQWrhwIaZNm4bk5GSUlpZi0aJFUCgUmDlzJoxGI+bNm4f77rsPERERMBgM+N3vfoesrCxW7AtCJxeOOPkZo5yDFfj7D0dwoNQCTysBKtpWiwfWvYM1qSPx3/4X+9oLIxJw0Z1LAgpQwM/7Qf3m0lRM6G/mM09B5Ex/V4iIiIiCSVAHqePHj2PmzJmoqalBdHQ0Lr74Yvz000+Ijo4GAPztb3+DKIqYMWMGmpqaMHnyZLz66qud3Gv6pbxKK1bsq0B+lQ1OjxdapQK9I3SwON34YGsxbK0s49O4mzBv2xe4a9NHCHU7cdGxPcjpMwpNqhPLMwMJUUoBGJpkwm/Hp2HiAHOb3xedf6f7u9InWo/Jg1khkYiIiIKLIMtygAupuh+LxQKj0YiGhgYYDFzadT7lVVqxZEMhau0uxBo08ErA7uI67C21tL6ET5bxq0M/4sE1S5BoqfI1N2hCcct1T2B3fL+A+hKiFpHZOxLTLojHr4fEQ6kM+v2oe5ST/67EGbUIUSvR6PKgrMGJiFA15o7pzTBFRERE7c7fbBDUM1LUtUmSjBX7KlBrdyEyVI1D5TbkVjSg2u5p9dohZUfwSM6bGFVywNfmEUT8Z9hUvDjmRtQFuIxvbN8I3DW+L0b0imCACkIn/13pG6OH8L9Ki2FaFfQaJXIrbfh+fwVSo/Rc5kdERERBgUGK2k1xXSP2HK+HR5Kw+WgNSuvsaC1Dma3V+P26dzBj36oW7et6D8OTE25DbnSy36+vEACjVon0uDDotWp8uPU4thXWc5lYECqpdyC/yoY4o9YXopoJgoA4oxZ5lTaU1DtYhp6IiIiCAoMUtYu8Siv+/dMx7C6uRX2jG06vf9ctXPfvFiEqPyIRT06YhzWpI/3eDyrRpEV6bBgcLi+MWhXiw3W+ZWL7ShtQ2uDgMrEgY3d54PR4EaI+/f5wOrUCFRYn7K7WZzOJiIiIOgKDFJ13RyoseGV1PvYdr0elzR1QOfMXLpmFXx36EU1KFV4ccyP+PexyeBT+/TXtZw7F3RPSMTjRiC93lWJ/mYXLxLqIULUSWqUCjS4PwrSn7v/lcHmhUSoQquaPLCIiIgoO/K2EzhtJkrHmSCUWf3MQxXWNcLZSz3xYySGYnFas7jPK11ZmiMadVz2InfH90aDzb8ZIBHDvZWm4a3w6RFFAcW0jjlbbuUysC0kw6dAnWo99pQ3Qa5Qtxk2WZZQ1OJGRYESC6fQzVkREREQdjUGKzpnHI+GrPaV4e/1RHCi3wnv2auaIs1ThD2uX4qoDa1EZGo7x8/8Fu+ZEoFlzUrBqjVYpYsogsy9EAVwm1hWJooDJg80obXAgt/LnZ6V0agUcLq+vat+kQWbOIBIREVHQYJCiNmneNHXlgXK8s7EAhbXOVq/RuZy4Y/OnuH3LZ9B5mgAAMfY6zNz9Hd68cHpAry8AiAhRYXCiEQsm9m3xCzaXiXVNaTFhmDumt28fqQqLExqlAhkJRkwaxAIhREREFFz4myQFrHnT1C93l+Bwha3V8wVZwlX71+APa5ci1lbra6/VGfDCxbPw/gVTAnr9ELWIAXEGjE+PwZSM2FN+weYysa4rLSYMqeP0KKl3wO7yIFStRIJJx5koIiIiCjoMUhSQ5k1TD5Za/ApRw48fxKOrXscFZbm+NreowLLhv8JLY2bCotX7/doaEUiL1eN3E9MxKM54xl+wuUysaxNFgc+uERERUdBjkCK/uVxevLEuHxvza1Fc52j1/Ot3r8Bz373com1l2oV4Zvw8FEQk+P26SgGIM2kxrFc4FkxIQ7r5zDtMN+MyMSIiIiJqTwxSdFrNz0BZGt0oqLVhX0kDvtpVipKGJr/vkZN2IaxqHcJcDhyKSsZTE27D+pRhAfXDoFFgYLwBY9NjAg5AXCZGRERERO2FQYpO0fwM1Pq8KhypsMLicMPdSiU+QZaQWluC/MgkX1t1aDieGzcXMoAPhk6GV1T43YfUSB1uyEzGRWmRMGrVbQ5AXCZGRERERO2BQYpaaH4G6lCZBQfLLXC4JLS2n+6o4n14NOcNJDZU4tLfvNHiuad/D7s8oNePCFHi1jEpmJIRx+V3RERERBS0GKTIx+OR8NHWYuwvbcChMkurG+om1pfjwTVL8avD631td294H09OnB/wa6tEYPrwBCyYkM7ld0REREQU9BikCMDPM1Efbi3Gx9uKUe84+0a1+qZG/PanjzBv6xfQeN2+9gMxKfghLTPg176wlxGPXT0YA+NMAV9LRERERNQZGKQIRyoseOabA9iQV3PWZ6FEyYtr9ubggR/fQbS93tdeFWLCX8bejI8zsiEF8ByUAOCitEgsm3MhlEqx7W+AiIiIiKiDMUj1QM0V+RqcLmzMq8Eb6/JQZTv7LFSfmmK89OWfMajyqK+tSaHE2yOvwitZ18Gm8b+ggwAgRK3AiORwPDptIEMUEREREXU5DFI9TF6lFd/tLccPByuQW2mF3dVKOb7/qQoNR7ylyvf9N/3G4Nlxc1FsivX7tUUBSDRp0SsyFKNTIjElI5YFJYiIiIioS2KQ6kGOVFiw+L8HseVoNezus58ryBJk4cRMkUWrxwuXzML1e1biiYnzsSVpsN+vq1EKiDVoccelaRiWbOJ+TkRERETU5QmyLLdW3brbs1gsMBqNaGhogMFg6OzunHeSJGN9bjUe/2of8qsbz3quKHlx/Z6V+M3mT3HtrOdRpQ9vcUwWhBYB66z3AhATpkZ6rAGzL+qNiQPM5/I2iIiIiIjanb/ZgDNS3VxepRXvbS7CV7uOo8p+9uegso7txqM5b2BAVSEA4L4f38VDU//PdzyQQhJJ4Tr8YWo/xIRpMTwpnM9BEREREVG3wiDVjeVVWvHmuqP4cncJGt1nnnjsXVuCP65Zgkm5P7VoD3U7T1ni15rwECVGp0bh/knpfP6JiIiIiLotBqluRpJkFNc14lB5A57770EcrXGe8VyD04bfbfwAs7d/DbV0YrZqT2wanpg4H9sSB/n9uuE6BQYmmHBRahQmDzYzRBERERFRt8Yg1Y3kVVrxn03H8MXuEtQ2nnkZn0LyYubuFbj3x38j0mHxtVfoI/D82Nn4bPB4v2ehhsSH4sHLB8EUokaYVsUiEkRERETUIzBIdRNHyq344/Ld2HasodVzNR4XfrfxA1+IcirV+NeF0/GvzBloVOv8ej2VAFyREYsXbhjO4EREREREPQ6DVBcmSTKKauz4YncJXs3JQ5Of9Rcb1To8P3Y2/vrfv+GLAZfiuXGzUWqI8ft1I0NVGJ0aiQXZ6QxRRERERNQjMUh1UYfKLHj6m4PYlF8Nz1kCVPNzUEtG/rpFWPps8Hgcjk7Gvtg0v19TASAhXIvrRiZhSkYcn4MiIiIioh6LQaoLkCQZJfUO2F0ehKgU+HRHMV5bexRNZ0lQSq8HN+76Fveufw/hTitibHW4+9cP+I7Lguh3iFIrRCRHatE3JgwzM5Mxpk8UZ6KIiIiIqEdjkApyeZVWrNhXgfwqGyqtTuwqqoPNJZ31mkuPbsfDq95E35piX9tleT8h2laLKn2E368tADDolBgYZ8AlfaMxaRCr8RERERERAQxSQS2v0oolGwpRa3ehrN6BXcfPXkiiT3UxHl79JsYf3d6i/dNB4/HnsbMDClHj0qMwY0QiUqJDYdSqWY2PiIiIiOgkDFJBqHkvqH//dAzH6xphdbiw67jljOebHBbcs/493LTzv1DKJ2artsf3xxMT52N3fD+/XzvOoMbjV2Zg0qDYc3oPRERERETdGYNUkDlSbsUn24ux53gDDpQ2oNHlPWsxCcgy3v3wEWRU5PuaSsKi8ey4OfhqwFhAaH0WKVynxLQL4jB5YBwyUyKhVPq3hxQRERERUU/FIBVEcg5W4KWcXORXWlt9DspHEPDP0dfi1S+eRaNKg1dHX4s3Rl2NJpWm1UujQ5XIHhCLeWNT+ewTEREREVEAGKSCxJEKC/7+Qy72lzTAe5bz0qsK4VBpUWw6sfTuv/3G4Pmxt+CTwRNRGRbp1+ulRuowY0QvTB7MAhJERERERIFikAoCkiTjrysOY0/JmYtJRDQ24N71/8GNu77Dqj4jMX/GoycOCgJezbrOr9cK14oYnRaNWZnJuIhlzImIiIiI2oRBKgh8vL0YPxyoPO0xldeN2du/wv9t/BCGJjsA4LK8Lcg6tgebkof4/RoigEHxekzNSGAZcyIiIiKic8Qg1ck8HglL1h89dTmfLOOyvM344+q3kFJX5mu2qXV4Jes67Ejo79f9tSIwOMmEuRf3xpCEcJYxJyIiIiI6DxikOtm2olrkVdpbtPWvLMAjq97AmGN7fG0SBHw05DL89ZKbUaUP9+veISoRN2f1xrUjEzkDRURERER0HjFIdbJD5ZYW5c3v2vgh7lv/HyhO2g9qc9JgPDFxPvab+/h1T5UA9DHrMTY9Gg9M6sdy5kRERERE5xmDVCersDS1+H6/OdUXooqMZjw9fh5WpGf5tR8UAKRGhaBvTBiiwjS4bmQSQxQRERERUTtgkOpk0Xp1i+/XpI7E1/0uxt64NCwd8Ws0KdVnuLKleKMGqdF6xIRpkRajZ0EJIiIiIqJ2xCDVyYRfzjQJAhZc9aDf18eGKbH4mguQGqWHw+1FqFrJghJERERERO2MQaqTRek1UAiAV2793JMZNCLG94uBQqFAWnQYkiJC2qeDRERERER0Cj5A08nMBi3CQ1Twd/5IKQDj+kZi9kUpcElAWoweCSZdu/aRiIiIiIhaYpDqZMOTwjEgzgiDTgVlK2kqSq/C5MGxSI0JQ16VHRGhakwaZOYyPiIiIiKiDsalfZ1MqRQxZ0xvLP72EDQKAQpBRl2jG24v4AWgVgD9YsOQFB4CtUKEW5JR3+hGRoKRBSWIiIiIiDoJg1QQmDjADABYuqEQhTV2mEJFADIi9RpcNjAW04clIN6oQ5nFCbvLw4ISRERERESdTJBlOcAyB92PxWKB0WhEQ0MDDAZDp/XD45Gwo7gO+0obcKTcBqfbC5dXglapQJ9oPSYP5gwUEREREVF78jcbdJtnpF555RX07t0bWq0WmZmZ2LJlS2d3KWBKpYiIUDXyK+1ocLgREapGapQephAV9pU2YMmGQuRVWju7m0REREREPV63CFIffvgh7rvvPixatAg7duzA0KFDMXnyZFRWVnZ21wIiSTJW7KtArd2FvjF6hGlVUIgCwrQq9I3Ro9buwvf7KyBJPX4SkYiIiIioU3WLIPXCCy9g/vz5mDt3LgYOHIjXXnsNISEhePvttzu7awEpqXcgv8qGOKP2lI16BUFAnFGLvEobSuodndRDIiIiIiICukGQcrlc2L59O7Kzs31toigiOzsbmzZtOu01TU1NsFgsLb6Cgd3lgdPjRYj69DVAdGoFmjxe2F2eDu4ZERERERGdrMsHqerqani9XpjN5hbtZrMZ5eXlp71m8eLFMBqNvq+kpKSO6GqrQtVKaJUKNJ4hKDlcXmiUCoSeIWgREREREVHH6PJBqi0eeughNDQ0+L6Ki4s7u0sAgASTDn2i9ShrcOKXxRRlWUZZgxNpMXokmHSd1EMiIiIiIgK6wT5SUVFRUCgUqKioaNFeUVGB2NjY016j0Wig0Wg6onsBEUUBkwebUdrgQG7lz89K6dQKOFxelDU4ERGqxqRBZu4fRURERETUybr8jJRarcaIESOQk5Pja5MkCTk5OcjKyurEnrVNWkwY5o7pjcHxRtQ3ulFYbUd9oxsZCUbMHdOb+0gREREREQWBLj8jBQD33XcfZs+ejZEjR+LCCy/Eiy++CLvdjrlz53Z219okLSYMqeP0KKl3wO7yIFStRIJJx5koIiIiIqIg0S2C1PXXX4+qqio8+uijKC8vxwUXXIDvvvvulAIUXYkoCkiKCOnsbhARERER0WkI8i+rGvRAFosFRqMRDQ0NMBgMnd0dIiIiIiLqJP5mgy7/jBQREREREVFHY5AiIiIiIiIKEIMUERERERFRgBikiIiIiIiIAsQgRUREREREFCAGKSIiIiIiogAxSBEREREREQWIQYqIiIiIiChADFJEREREREQBYpAiIiIiIiIKEIMUERERERFRgBikiIiIiIiIAqTs7A4EA1mWAQAWi6WTe0JERERERJ2pORM0Z4QzYZACYLVaAQBJSUmd3BMiIiIiIgoGVqsVRqPxjMcFubWo1QNIkoTS0lKEhYVBEAS/r7NYLEhKSkJxcTEMBkM79pDaguMTvDg2wY3jE9w4PsGLYxPcOD7BK9jGRpZlWK1WxMfHQxTP/CQUZ6QAiKKIxMTENl9vMBiCYtDp9Dg+wYtjE9w4PsGN4xO8ODbBjeMTvIJpbM42E9WMxSaIiIiIiIgCxCBFREREREQUIAapc6DRaLBo0SJoNJrO7gqdBscneHFsghvHJ7hxfIIXxya4cXyCV1cdGxabICIiIiIiChBnpIiIiIiIiALEIEVERERERBQgBikiIiIiIqIAMUgREREREREFiEHqHLzyyivo3bs3tFotMjMzsWXLls7uUo/z2GOPQRCEFl/9+/f3HXc6nbjrrrsQGRkJvV6PGTNmoKKiohN73L2tW7cO06ZNQ3x8PARBwOeff97iuCzLePTRRxEXFwedTofs7Gzk5ua2OKe2thazZs2CwWCAyWTCvHnzYLPZOvBddE+tjc2cOXNO+SxNmTKlxTkcm/axePFijBo1CmFhYYiJicFVV12Fw4cPtzjHn59lRUVFuOKKKxASEoKYmBg88MAD8Hg8HflWuiV/xmfcuHGnfH7uuOOOFudwfNrHP//5TwwZMsS3kWtWVha+/fZb33F+djpPa2PTHT43DFJt9OGHH+K+++7DokWLsGPHDgwdOhSTJ09GZWVlZ3etxxk0aBDKysp8X+vXr/cdu/fee/HVV1/h448/xtq1a1FaWorp06d3Ym+7N7vdjqFDh+KVV1457fHnn38eL730El577TVs3rwZoaGhmDx5MpxOp++cWbNmYf/+/Vi5ciW+/vprrFu3DrfffntHvYVuq7WxAYApU6a0+Cy9//77LY5zbNrH2rVrcdddd+Gnn37CypUr4Xa7MWnSJNjtdt85rf0s83q9uOKKK+ByubBx40YsW7YMS5cuxaOPPtoZb6lb8Wd8AGD+/PktPj/PP/+87xjHp/0kJibi2Wefxfbt27Ft2zZMmDABV155Jfbv3w+An53O1NrYAN3gcyNTm1x44YXyXXfd5fve6/XK8fHx8uLFizuxVz3PokWL5KFDh572WH19vaxSqeSPP/7Y13bw4EEZgLxp06YO6mHPBUBevny573tJkuTY2Fj5z3/+s6+tvr5e1mg08vvvvy/LsiwfOHBABiBv3brVd863334rC4Igl5SUdFjfu7tfjo0sy/Ls2bPlK6+88ozXcGw6TmVlpQxAXrt2rSzL/v0s++9//yuLoiiXl5f7zvnnP/8pGwwGuampqWPfQDf3y/GRZVm+9NJL5bvvvvuM13B8OlZ4eLj85ptv8rMThJrHRpa7x+eGM1Jt4HK5sH37dmRnZ/vaRFFEdnY2Nm3a1Ik965lyc3MRHx+P1NRUzJo1C0VFRQCA7du3w+12txin/v37o1evXhynTlBQUIDy8vIW42E0GpGZmekbj02bNsFkMmHkyJG+c7KzsyGKIjZv3tzhfe5p1qxZg5iYGPTr1w933nknampqfMc4Nh2noaEBABAREQHAv59lmzZtQkZGBsxms++cyZMnw2KxtPh/f+nc/XJ8mv3nP/9BVFQUBg8ejIceegiNjY2+YxyfjuH1evHBBx/AbrcjKyuLn50g8suxadbVPzfKzu5AV1RdXQ2v19tiYAHAbDbj0KFDndSrnikzMxNLly5Fv379UFZWhscffxyXXHIJ9u3bh/LycqjVaphMphbXmM1mlJeXd06He7DmP/PTfW6aj5WXlyMmJqbFcaVSiYiICI5ZO5syZQqmT5+OlJQU5Ofn449//COmTp2KTZs2QaFQcGw6iCRJuOeeezBmzBgMHjwYAPz6WVZeXn7az1bzMTo/Tjc+AHDjjTciOTkZ8fHx2LNnD/7whz/g8OHD+OyzzwBwfNrb3r17kZWVBafTCb1ej+XLl2PgwIHYtWsXPzud7ExjA3SPzw2DFHVpU6dO9f33kCFDkJmZieTkZHz00UfQ6XSd2DOiruWGG27w/XdGRgaGDBmCPn36YM2aNZg4cWIn9qxnueuuu7Bv374Wz3pS8DjT+Jz8rGBGRgbi4uIwceJE5Ofno0+fPh3dzR6nX79+2LVrFxoaGvDJJ59g9uzZWLt2bWd3i3DmsRk4cGC3+NxwaV8bREVFQaFQnFL1paKiArGxsZ3UKwIAk8mE9PR05OXlITY2Fi6XC/X19S3O4Th1juY/87N9bmJjY08p2OLxeFBbW8sx62CpqamIiopCXl4eAI5NR1iwYAG+/vprrF69GomJib52f36WxcbGnvaz1XyMzt2Zxud0MjMzAaDF54fj037UajXS0tIwYsQILF68GEOHDsXf//53fnaCwJnG5nS64ueGQaoN1Go1RowYgZycHF+bJEnIyclpse6TOp7NZkN+fj7i4uIwYsQIqFSqFuN0+PBhFBUVcZw6QUpKCmJjY1uMh8ViwebNm33jkZWVhfr6emzfvt13zqpVqyBJku8HLHWM48ePo6amBnFxcQA4Nu1JlmUsWLAAy5cvx6pVq5CSktLiuD8/y7KysrB3794WYXflypUwGAy+ZTTUNq2Nz+ns2rULAFp8fjg+HUeSJDQ1NfGzE4Sax+Z0uuTnprOrXXRVH3zwgazRaOSlS5fKBw4ckG+//XbZZDK1qCxC7e/++++X16xZIxcUFMgbNmyQs7Oz5aioKLmyslKWZVm+44475F69esmrVq2St23bJmdlZclZWVmd3Ovuy2q1yjt37pR37twpA5BfeOEFeefOnfKxY8dkWZblZ599VjaZTPIXX3wh79mzR77yyivllJQU2eFw+O4xZcoUediwYfLmzZvl9evXy3379pVnzpzZWW+p2zjb2FitVnnhwoXypk2b5IKCAvmHH36Qhw8fLvft21d2Op2+e3Bs2sedd94pG41Gec2aNXJZWZnvq7Gx0XdOaz/LPB6PPHjwYHnSpEnyrl275O+++06Ojo6WH3rooc54S91Ka+OTl5cnP/HEE/K2bdvkgoIC+YsvvpBTU1PlsWPH+u7B8Wk/Dz74oLx27Vq5oKBA3rNnj/zggw/KgiDI33//vSzL/Ox0prONTXf53DBInYOXX35Z7tWrl6xWq+ULL7xQ/umnnzq7Sz3O9ddfL8fFxclqtVpOSEiQr7/+ejkvL8933OFwyL/97W/l8PBwOSQkRL766qvlsrKyTuxx97Z69WoZwClfs2fPlmX55xLojzzyiGw2m2WNRiNPnDhRPnz4cIt71NTUyDNnzpT1er1sMBjkuXPnylartRPeTfdytrFpbGyUJ02aJEdHR8sqlUpOTk6W58+ff8r/McSxaR+nGxcA8pIlS3zn+POzrLCwUJ46daqs0+nkqKgo+f7775fdbncHv5vup7XxKSoqkseOHStHRETIGo1GTktLkx944AG5oaGhxX04Pu3j1ltvlZOTk2W1Wi1HR0fLEydO9IUoWeZnpzOdbWy6y+dGkGVZ7rj5LyIiIiIioq6Pz0gREREREREFiEGKiIiIiIgoQAxSREREREREAWKQIiIiIiIiChCDFBERERERUYAYpIiIiIiIiALEIEVERERERBQgBikiIiIiIqIAMUgRERGdg969e+PFF1/s7G4QEVEHY5AiIqIOJQjCWb8ee+yxDulHRkYG7rjjjtMee/fdd6HRaFBdXd0hfSEioq6HQYqIiDpUWVmZ7+vFF1+EwWBo0bZw4ULfubIsw+PxtEs/5s2bhw8++AAOh+OUY0uWLMGvf/1rREVFtctrExFR18cgRUREHSo2Ntb3ZTQaIQiC7/tDhw4hLCwM3377LUaMGAGNRoP169djzpw5uOqqq1rc55577sG4ceN830uShMWLFyMlJQU6nQ5Dhw7FJ598csZ+3HTTTXA4HPj0009btBcUFGDNmjWYN28e8vPzceWVV8JsNkOv12PUqFH44YcfznjPwsJCCIKAXbt2+drq6+shCALWrFnja9u3bx+mTp0KvV4Ps9mMm2++ucXs1yeffIKMjAzodDpERkYiOzsbdrv97H+wRETUoRikiIgo6Dz44IN49tlncfDgQQwZMsSvaxYvXox33nkHr732Gvbv3497770XN910E9auXXva86OionDllVfi7bffbtG+dOlSJCYmYtKkSbDZbLj88suRk5ODnTt3YsqUKZg2bRqKiora/N7q6+sxYcIEDBs2DNu2bcN3332HiooKXHfddQB+nrGbOXMmbr31Vhw8eBBr1qzB9OnTIctym1+TiIjOP2Vnd4CIiOiXnnjiCVx22WV+n9/U1IRnnnkGP/zwA7KysgAAqampWL9+Pf71r3/h0ksvPe118+bNw9SpU1FQUICUlBTIsoxly5Zh9uzZEEURQ4cOxdChQ33nP/nkk1i+fDm+/PJLLFiwoE3v7R//+AeGDRuGZ555xtf29ttvIykpCUeOHIHNZoPH48H06dORnJwM4OfnuYiIKLhwRoqIiILOyJEjAzo/Ly8PjY2NuOyyy6DX631f77zzDvLz88943WWXXYbExEQsWbIEAJCTk4OioiLMnTsXAGCz2bBw4UIMGDAAJpMJer0eBw8ePKcZqd27d2P16tUt+tm/f38AQH5+PoYOHYqJEyciIyMD1157Ld544w3U1dW1+fWIiKh9cEaKiIiCTmhoaIvvRVE8ZWmb2+32/bfNZgMAfPPNN0hISGhxnkajOePriKKIOXPmYNmyZXjsscewZMkSjB8/HqmpqQCAhQsXYuXKlfjLX/6CtLQ06HQ6XHPNNXC5XGe8H4AWfT25n819nTZtGp577rlTro+Li4NCocDKlSuxceNGfP/993j55Zfxpz/9CZs3b0ZKSsoZ3wsREXUszkgREVHQi46ORllZWYu2kws6DBw4EBqNBkVFRUhLS2vxlZSUdNZ7z507F8XFxfjss8+wfPlyzJs3z3dsw4YNmDNnDq6++mpkZGQgNjYWhYWFZ+0ngBZ9PbmfADB8+HDs378fvXv3PqWvzQFSEASMGTMGjz/+OHbu3Am1Wo3ly5ef9X0QEVHHYpAiIqKgN2HCBGzbtg3vvPMOcnNzsWjRIuzbt893PCwsDAsXLsS9996LZcuWIT8/Hzt27MDLL7+MZcuWnfXeKSkpmDBhAm6//XZoNBpMnz7dd6xv37747LPPsGvXLuzevRs33ngjJEk64710Oh1Gjx7tK5Sxdu1aPPzwwy3Oueuuu1BbW4uZM2di69atyM/Px4oVKzB37lx4vV5s3rwZzzzzDLZt24aioiJ89tlnqKqqwoABA9r4p0dERO2BQYqIiILe5MmT8cgjj+D3v/89Ro0aBavViltuuaXFOU8++SQeeeQRLF68GAMGDMCUKVPwzTff+LUcbt68eairq8ONN94IrVbra3/hhRcQHh6Oiy66CNOmTcPkyZMxfPjws97r7bffhsfjwYgRI3DPPffgqaeeanE8Pj4eGzZsgNfrxaRJk5CRkYF77rkHJpMJoijCYDBg3bp1uPzyy5Geno6HH34Yf/3rXzF16tQA/sSIiKi9CTLrqRIREREREQWEM1JEREREREQBYpAiIiIiIiIKEIMUERERERFRgBikiIiIiIiIAsQgRUREREREFCAGKSIiIiIiogAxSBEREREREQWIQYqIiIiIiChADFJEREREREQBYpAiIiIiIiIKEIMUERERERFRgP4foCwuO1jx8NcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'trained_model.pth'  # Replace with your actual model path\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define a prediction function\n",
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            predictions.append(out.cpu().numpy())\n",
    "            true_values.append(data.y.cpu().numpy())\n",
    "    return np.concatenate(predictions), np.concatenate(true_values)\n",
    "\n",
    "# Create DataLoader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Get predictions and true values on the test dataset\n",
    "test_predictions, test_true_values = predict(model, test_loader)\n",
    "\n",
    "# Plot true values vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(test_true_values, test_predictions, alpha=0.5)\n",
    "plt.plot([test_true_values.min(), test_true_values.max()], [test_true_values.min(), test_true_values.max()], 'r--', lw=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.data import DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "\n",
    "def log_cosh_loss(output, target):\n",
    "    return torch.mean(torch.log(torch.cosh(output - target)))\n",
    "\n",
    "# Replace 'file.csv' with your file path\n",
    "df = pd.read_csv('../hgcal_electron_data.csv')\n",
    "df = df[50000:100000]\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "#print(df.head())\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "#print(column_names)\n",
    "\n",
    "#columns_to_drop = ['nhits_total','xMean_layer0', 'xMean_layer1', 'xMean_layer2', 'xMean_layer3', 'xMean_layer4', 'xMean_layer5', 'xMean_layer6', 'xMean_layer7', 'xMean_layer8', 'xMean_layer9', 'xMean_layer10', 'xMean_layer11', 'xMean_layer12', 'xMean_layer13', 'xMean_layer14', 'xMean_layer15', 'xMean_layer16', 'xMean_layer17', 'xMean_layer18', 'xMean_layer19', 'xMean_layer20', 'xMean_layer21', 'xMean_layer22', 'xMean_layer23', 'xMean_layer24', 'xMean_layer25', 'xMean_layer26', 'xMean_layer27', 'xStd_layer0', 'xStd_layer1', 'xStd_layer2', 'xStd_layer3', 'xStd_layer4', 'xStd_layer5', 'xStd_layer6', 'xStd_layer7', 'xStd_layer8', 'xStd_layer9', 'xStd_layer10', 'xStd_layer11', 'xStd_layer12', 'xStd_layer13', 'xStd_layer14', 'xStd_layer15', 'xStd_layer16', 'xStd_layer17', 'xStd_layer18', 'xStd_layer19', 'xStd_layer20', 'xStd_layer21', 'xStd_layer22', 'xStd_layer23', 'xStd_layer24', 'xStd_layer25', 'xStd_layer26', 'xStd_layer27', 'yMean_layer0', 'yMean_layer1', 'yMean_layer2', 'yMean_layer3', 'yMean_layer4', 'yMean_layer5', 'yMean_layer6', 'yMean_layer7', 'yMean_layer8', 'yMean_layer9', 'yMean_layer10', 'yMean_layer11', 'yMean_layer12', 'yMean_layer13', 'yMean_layer14', 'yMean_layer15', 'yMean_layer16', 'yMean_layer17', 'yMean_layer18', 'yMean_layer19', 'yMean_layer20', 'yMean_layer21', 'yMean_layer22', 'yMean_layer23', 'yMean_layer24', 'yMean_layer25', 'yMean_layer26', 'yMean_layer27', 'yStd_layer0', 'yStd_layer1', 'yStd_layer2', 'yStd_layer3', 'yStd_layer4', 'yStd_layer5', 'yStd_layer6', 'yStd_layer7', 'yStd_layer8', 'yStd_layer9', 'yStd_layer10', 'yStd_layer11', 'yStd_layer12', 'yStd_layer13', 'yStd_layer14', 'yStd_layer15', 'yStd_layer16', 'yStd_layer17', 'yStd_layer18', 'yStd_layer19', 'yStd_layer20', 'yStd_layer21', 'yStd_layer22', 'yStd_layer23', 'yStd_layer24', 'yStd_layer25', 'yStd_layer26', 'yStd_layer27']\n",
    "#df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "#print(\"After dropping\")\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "labels = df['target_energy'].values  # Assuming there's a 'label' column for graph labels\n",
    "\n",
    "# Drop the label column to get the feature data\n",
    "feature_data = df.drop(columns=['target_energy']).values\n",
    "\n",
    "# Number of graphs\n",
    "num_graphs = feature_data.shape[0]\n",
    "\n",
    "# Number of nodes\n",
    "num_nodes = 28\n",
    "\n",
    "# Number of features per node\n",
    "num_features_per_node = 4  # nhits, rMean, rStd, energySum, etc.\n",
    "\n",
    "# Reshape the data to (num_graphs, num_nodes, num_features_per_node)\n",
    "energySum_data = df[[f'energySum_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rMean_data = df[[f'rMean_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rStd_data = df[[f'rStd_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "nhits_data = df[[f'nhits_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "\n",
    "# Concatenate features along the last dimension\n",
    "feature_data = np.concatenate([energySum_data, rMean_data, rStd_data, nhits_data], axis=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_indices, test_indices = train_test_split(np.arange(num_graphs), test_size=0.2, random_state=42)\n",
    "\n",
    "train_features = feature_data[train_indices]\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "test_features = feature_data[test_indices]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'trained_model.pth'  # Replace with your actual model path\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define a prediction function\n",
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            predictions.append(out.cpu().numpy())\n",
    "            true_values.append(data.y.cpu().numpy())\n",
    "    return np.concatenate(predictions), np.concatenate(true_values)\n",
    "\n",
    "# Create DataLoader for the labeled dataset\n",
    "labeled_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Get predictions and true values\n",
    "predicted_values, true_values = predict(model, labeled_loader)\n",
    "\n",
    "# Save the results to a pandas DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'True Values': true_values,\n",
    "    'Predicted Values': predicted_values\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "results_df.to_csv('predictions.csv', index=False)\n",
    "print(\"Predictions saved to predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1000 Epochs and print every 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "\n",
    "# Replace 'file.csv' with your file path\n",
    "df = pd.read_csv('hgcal_electron_data_50000.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "#print(df.head())\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "#print(column_names)\n",
    "\n",
    "columns_to_drop = ['nhits_total','xMean_layer0', 'xMean_layer1', 'xMean_layer2', 'xMean_layer3', 'xMean_layer4', 'xMean_layer5', 'xMean_layer6', 'xMean_layer7', 'xMean_layer8', 'xMean_layer9', 'xMean_layer10', 'xMean_layer11', 'xMean_layer12', 'xMean_layer13', 'xMean_layer14', 'xMean_layer15', 'xMean_layer16', 'xMean_layer17', 'xMean_layer18', 'xMean_layer19', 'xMean_layer20', 'xMean_layer21', 'xMean_layer22', 'xMean_layer23', 'xMean_layer24', 'xMean_layer25', 'xMean_layer26', 'xMean_layer27', 'xStd_layer0', 'xStd_layer1', 'xStd_layer2', 'xStd_layer3', 'xStd_layer4', 'xStd_layer5', 'xStd_layer6', 'xStd_layer7', 'xStd_layer8', 'xStd_layer9', 'xStd_layer10', 'xStd_layer11', 'xStd_layer12', 'xStd_layer13', 'xStd_layer14', 'xStd_layer15', 'xStd_layer16', 'xStd_layer17', 'xStd_layer18', 'xStd_layer19', 'xStd_layer20', 'xStd_layer21', 'xStd_layer22', 'xStd_layer23', 'xStd_layer24', 'xStd_layer25', 'xStd_layer26', 'xStd_layer27', 'yMean_layer0', 'yMean_layer1', 'yMean_layer2', 'yMean_layer3', 'yMean_layer4', 'yMean_layer5', 'yMean_layer6', 'yMean_layer7', 'yMean_layer8', 'yMean_layer9', 'yMean_layer10', 'yMean_layer11', 'yMean_layer12', 'yMean_layer13', 'yMean_layer14', 'yMean_layer15', 'yMean_layer16', 'yMean_layer17', 'yMean_layer18', 'yMean_layer19', 'yMean_layer20', 'yMean_layer21', 'yMean_layer22', 'yMean_layer23', 'yMean_layer24', 'yMean_layer25', 'yMean_layer26', 'yMean_layer27', 'yStd_layer0', 'yStd_layer1', 'yStd_layer2', 'yStd_layer3', 'yStd_layer4', 'yStd_layer5', 'yStd_layer6', 'yStd_layer7', 'yStd_layer8', 'yStd_layer9', 'yStd_layer10', 'yStd_layer11', 'yStd_layer12', 'yStd_layer13', 'yStd_layer14', 'yStd_layer15', 'yStd_layer16', 'yStd_layer17', 'yStd_layer18', 'yStd_layer19', 'yStd_layer20', 'yStd_layer21', 'yStd_layer22', 'yStd_layer23', 'yStd_layer24', 'yStd_layer25', 'yStd_layer26', 'yStd_layer27']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "#print(\"After dropping\")\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "labels = df['target_energy'].values  # Assuming there's a 'label' column for graph labels\n",
    "\n",
    "# Drop the label column to get the feature data\n",
    "feature_data = df.drop(columns=['target_energy']).values\n",
    "\n",
    "\n",
    "# Number of graphs\n",
    "num_graphs = feature_data.shape[0]\n",
    "\n",
    "# Number of nodes\n",
    "num_nodes = 28\n",
    "\n",
    "# Number of features per node\n",
    "num_features_per_node = 4  # nhits, rMean, rStd, energySum, etc.\n",
    "\n",
    "# Reshape the data to (num_graphs, num_nodes, num_features_per_node)\n",
    "energySum_data = df[[f'energySum_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rMean_data = df[[f'rMean_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "rStd_data = df[[f'rStd_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "nhits_data = df[[f'nhits_layer{i}' for i in range(num_nodes)]].values.reshape((num_graphs, num_nodes, 1))\n",
    "\n",
    "# Concatenate features along the last dimension\n",
    "feature_data = np.concatenate([energySum_data, rMean_data, rStd_data, nhits_data], axis=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_indices, test_indices = train_test_split(np.arange(num_graphs), test_size=0.2, random_state=42)\n",
    "\n",
    "train_features = feature_data[train_indices]\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "test_features = feature_data[test_indices]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "# Create directed edge index for each node i connected to all nodes j where j > i\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "\n",
    "for i in range(num_nodes - 1):\n",
    "    for j in range(i + 1, num_nodes):\n",
    "        source_nodes.append(i)\n",
    "        target_nodes.append(j)\n",
    "\n",
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Verify the edge index\n",
    "print(edge_index)\n",
    "\n",
    "def create_data_list(features, labels, edge_index):\n",
    "    data_list = []\n",
    "    for i in range(features.shape[0]):\n",
    "        x = torch.tensor(features[i], dtype=torch.float)\n",
    "        y = torch.tensor([labels[i]], dtype=torch.float)  # Ensure labels are float for regression\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "train_data_list = create_data_list(train_features, train_labels, edge_index)\n",
    "test_data_list = create_data_list(test_features, test_labels, edge_index)\n",
    "\n",
    "class GraphDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        super(GraphDataset, self).__init__('.', transform)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "# Instantiate the datasets\n",
    "train_dataset = GraphDataset(train_data_list)\n",
    "test_dataset = GraphDataset(test_data_list)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "        self.conv3 = GCNConv(16, 2)\n",
    "        self.regressor = Linear(2, 1)  # Single output for regression\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.relu()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply global pooling to aggregate node features\n",
    "        h = global_mean_pool(h, batch)  # Aggregated features for each graph\n",
    "        \n",
    "        # Apply a final (linear) regressor.\n",
    "        out = self.regressor(h).squeeze()  # Ensure output is [batch_size]\n",
    "\n",
    "        return out\n",
    "\n",
    "num_features = feature_data.shape[2]  # Number of features per node\n",
    "\n",
    "model = GCN(num_features=num_features)\n",
    "print(model)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = F.mse_loss(out, data.y.squeeze())  # Ensure target is [batch_size]\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "# Training for 1000 epochs and print loss every 100 epochs\n",
    "for epoch in range(1000):\n",
    "    train_loss = train()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        test_loss = test(test_loader)\n",
    "        print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
